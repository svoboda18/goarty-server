[
    {
        "id": 14,
        "title": "Numerical computing in engineering mathematics",
        "body": "I. INTRODUCTION\nThe 4th Industrial Revolution has had a dramatic impact on the engineering profession. The modern technologies such as artificial intelligence, the internet of things, and advanced robotics have altered engineering systems and processes. Today's engineers are expected to be able to leverage these resources to produce their products. To meet the new professional requirements, engineering educational institutions have revised their curricula. The changes in the curricula include both updating the existing programs as well as introducing completely new programs. Given the rapid technological progress, universities and colleges around the world are continuously adapting to the ever-changing environment. While a significant progress in modernizing the engineering curriculum has been achieved, there still remains room for improvement.\nCatalyzed by the exponential increase in computational power and interconnectedness, the modern industrial revolution has reshaped the skills and competencies required of the engineers. The changes in engineering curricula in response to Industry 4.0 have been threefold: i) modernizing the existing programs, ii) introduction of new programs, and iii) revising the pedagogical approach. Modernizing the existing programs involves introduction of new courses in the study plan related to emerging technologies. In addition, existing courses can be updated with new content. Fresh new programs in emerging Â© 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works technologies are also introduced by universities and colleges. Many institutions now offer degrees in artificial intelligence and mechatronics which were not there 20 years ago. Finally, universities have revised their approaches to course delivery. Student-centered learning, project-based learning, and applied learning have become popular in the new engineering educational paradigm.\nWhile significant effort has been made to revise the core engineering courses, the auxiliary courses in mathematics and sciences received little consideration. The mathematics and sciences courses play a key role in the engineering curriculum. Given their importance, the curriculum updates must also be extended to the auxiliary courses. By implementing a comprehensive update of the engineering curriculum that includes both the core and auxiliary courses, a more effective outcome can be achieved.\nThe goal of this paper is to propose a modernized engineering mathematics curriculum in line with the broader efforts to update engineering education to adapt to Industry 4.0. The key feature of the new curriculum is the introduction numerical computing in the existing mathematics courses. The latest industrial revolution has been driven largely by the dramatic increase in computational power. Therefore, today's engineers must be well-equipped to leverage the computing power in their work.\nSince mathematics courses are usually taken at the beginning of the study plan, it offers a natural avenue for introducing numerical computing to students. Furthermore, many problems in mathematics can be solved numerically making it natural to integrate numerical computing in mathematics courses. By studying numerical computing in mathematics courses, students will acquire the necessary theoretical and practical skills to apply in their downstream, specialized engineering courses.\nThis paper is structured as follows. Section 2 provides an overview of the existing efforts to update the engineering curriculum in response to Industry 4.0. Section 3 discusses the current approaches to integrate scientific computing in mathematics courses. In Section 4, we present our proposal for modernizing the mathematics curriculum to integrate numerical computing. Section 5 concludes the paper with final remarks.\nII. ENGINEERING EDUCATION AND INDUSTRY 4.0\nEngineering departments in colleges and universities have made significant changes in their curricula in response to the new environment created by the recent, rapid advances in technology. In particular, the existing programs have been updated to include courses that target emerging technologies. Completely new programs related to AI and mechatronics have also been adopted by universities. Innovations in the field of engineering education continue to take place with new developments on the horizon.\nThere exist several studies investigating the modern engineering curricula and evaluating their effectiveness. It is argued in[6]that engineering educators must prepare their students to face three key challenges: sustainability, the 4th Industrial Revolution, and employability. The authors find that colleges and universities are responding to these challenges by emphasizing student-centered learning, integration of theory and practice, digital and online learning, and the definition of professional competencies. In particular, response to the needs of Industry 4.0 require interdisciplinary collaboration across several programs and disciplines. Interaction and integration of technologies plays a key role in this process[10],[12]. Interdisciplinary engineering education requires sound pedagogy and teaming experiences to encourage student in collaborative and interdisciplinary practice[23].\nDigital and online learning have become an important part of modern education including in the field of engineering. Information technologies play a vital role in delivering digital learning to students. Colleges and universities have made significant investments to improve their information and communication technology (ICT) capacities[7].\nIn response to the needs of Industry 4.0, some universities have adopted the framework of Education 4.0[15],[19]. The new education framework consists of four main components: i) competencies, ii) learning methods, iii) ICT, and iv) infrastructure. Students competencies are based on technological knowledge and skills for successful workplace performance, while the learning methods are based on problem solving and challenge-based learning. In particular, active and project-based learning plays an important role in Education 4.0[4],[8]. Other innovative approaches to learning such as virtual-reality based engineering education can help improve the learning process related to Industry 4.0[20].\nIn addition to technological progress, socio-cultural shifts must be taken into account in revising engineering curriculum. The new generation of students has its unique worldview which needs to be considered by the educators. In particular, the new generation is significantly affected by mobile devices and digital media. Educational content must be tailored to the new student preferences to achieve effective learning outcomes[16]. Innovative approaches such gamification may help improve the learning process[13],[17].\nMany universities have also introduced nontechnical updates to their engineering curriculum. The most significant nontechnical update has been the introduction of entrepreneurship courses and experiences for students. A lot of attention has recently been given to equipping students with entrepreneurial skills. Students learn about entrepreneurship in their courses as well as through university incubators.\nIII. UNIVERSITY MATHEMATICS CURRICULUM\nThe mathematics curriculum changed very little in the current century. It remains a largely analytic domain, where solutions are mainly obtained manually. The current mathematics curriculum emphasizes theory over practical approaches. For instance, when finding the extreme values of a function, derivative-based approach is preferred over the gradient decent. There are two key reasons for why analytical approaches are favored over numerical methods. First, analytical solutions are reliable and elegant. An analytical solution is guaranteed to be exact. Second, mathematics courses are usually taught by pure mathematicians who have an inherent preference for analytical solutions. Pure mathematics which is based on theorem proving is not amenable to numerical methods.\nDespite the popularity of analytical approaches to problem solving in mathematics, there has been a growing push to integrate computer algebra systems as part of the learning process. Computer algebra systems such as Matlab and Mathematica are now routinely used in many mathematics courses. The study by Cretchley et al.[5]found that engineering students were positive about the use of technology as a learning tool in mathematics courses. The increased use of technology in class helped improve student focus and interest in lectures. Student evaluations also indicated that they had a greater level of enjoyment towards the lectures due to the use of technology. It is noteworthy that students chose not to rely too heavily on technology during the examinations despite the freedom to do so. The students found it extremely important to be competent with analytical mathematical skills as opposed to purely computational skills. Some revealed that they learn the subjects equally well without the help of scientific packages, although the perception towards the use of computer is in general highly positive. Almost all students responded positively to Matlab as an effective tool for computation and graphing. Many used Matlab for non-examination purposes. For example, they utilized it to check their handwritten mathematical steps in assignments and practice problems; and others used it for exploration beyond the standard syllabus and curriculum.\nThe influence of computer technology on students' academic performance and learning experience has been investigated by several authors. Abdul Majid et al.[1],[2]used Matlab as an aid to teach calculus to engineering students. The software package was used for various course learning outcomes such as graphical display of mathematical functions, exploration, identifying and predicting structural patterns in evaluating a series of complex indefinite integrals, and numerical approximations in applied mathematics. The study showed a positive impact on students' academic performance in the final examinations. The study concluded that the integration of scientific packages into engineering mathematics courses could be effective under certain conditions. Similarly, other studies[18],[21]also found a positive impact from the use of scientific software packages on students' motivation in learning mathematics.\nIn a separate study by Brake[3], the authors investigated the use of Matlab in engineering mathematics courses to increase student confidence level and mathematical abilities. Matlab was used to solve concrete engineering problems which require a deep understanding of underlying mathematical principles. The study found generally positive student response to the use of software in their mathematics courses. However, the results of the study must be considered carefully given the small sample size of the subjects.\nAlthough the majority of the studies were based on the use of Matlab, several other studies considered alternative mathematics software packages. The study by Kilicman et al.[11]focused on the use of Maple to help students understand both the theoretical and computational aspects of linear algebra for engineering students. In particular, it was shown that the use of Maple facilitates the understanding of computational aspects of eigenvalues and eigenvectors. It allows students more time to focus on the theoretical aspects and the underlying mathematical principles.\nIn a recent study by Mezhennaya and Pugachev[14], the authors compared engineering students' perceptions regarding several mathematical software: Matlab, Mathematica and Excel. The study found that all the scientific packages considered can be used in education, under the condition that the policies for software usage are carefully implemented. The study found that many students lack hands-on experience on how to use the software. The students particularly struggled with Matlab and Mathematica finding them non user friendly. The study concluded that additional classes are required to prepare students to use software in their courses.\nIV. NUMERICAL COMPUTING IN MATHEMATICS\nCURRICULUM Mathematics lies at the foundation of science and engineering. The importance of mathematics courses in engineering education cannot be underestimated. These courses equip students with the fundamental skills and knowledge to study the more specialized engineering courses. Thus, student success in engineering studies depends directly on the mathematics and sciences courses. Given the significance of the mathematics courses in the engineering curriculum, it is paramount to ensure their currency with respect to the Industry 4.0.\nThe technological advances over the last decade have created demand for more computationally proficient experts. To meet this demand, numerical computing must become a core part of engineering studies. Mathematics courses offer a natural and convenient avenue for introducing numerical computing to engineering students. There are two main factors that make mathematics courses particularly amenable to numerical computing. First, in many cases mathematical problems have numerical solutions. For instance, finding the root of a polynomial or the minimum value of a function can be done numerically. Therefore, it is both logical and appropriate to apply numerical computing to mathematical problems. Second, mathematics courses are usually taken at the beginning of the study plan. Thus, students become acquainted with numerical computing at an early stage. The computing and programming skills acquired in this manner will have a positive effect in the more advanced, downstream engineering courses.\nThe key idea for the proposed curriculum update is the addition of computing tutorials (labs) to mathematics courses. In particular, we propose adding weekly computing tutorials (labs) related to the main lecture material. For instance, in the week in which students cover finding the extreme values of a function, there will be a computing tutorial where students learn and implement the gradient descent algorithm. The suggested length of each tutorial is 1 hour. It is enough time to implement most of the numerical algorithms at the undergraduate level. At the same time, 1 extra hour per week will not overburden the students.\nThe exact details of numerical computing content is left for individual universities and instructors. Depending on the syllabus and course learning outcomes, the numerical computing labs will be different for each university and instructor. Nevertheless, the general ideas will be broadly similar across different curricula. To illustrate the proposed numerical computing content, we will focus on the three main concept in calculus: limits, derivatives, and integrals.\nA. Limits\nLimit is a fundamental concept in calculus. Students are usually taught to calculate limits using analytical approaches. Although analytical approaches work well, there is no single universal rule for calculating limits. On the other hand, in most cases, limits can be calculated numerically using essentially the same approach. To illustrate, suppose we want to calculate lim xâa + f (x). Then we can loop for k = 0 to n and calculate f (a+ 10 -k ). As k increases, a+ 10 -k approaches a, so f (a+ 10 -k ) will, in most cases, approach the limit value. We can deduce the limit by observing the values of f (a + 10 -k ) or determine that the limit does not exist if there is no pattern of convergence. The value of n can be chosen manually or using a stopping criterion. For instance, the algorithm may continue to iterate until the difference between consecutive values of f (a + 10 -k ) is below a certain threshold. The value of the limit can also be deduced automatically based on the values of f (a + 10 -k ) using various heuristics.\nAnother common limit problem is lim xââ f (x). In this case, we can loop for k = 0 to n and calculate f (10 k ). As k increases, 10 k approaches â, so f (10 k ) will, in most cases, approach the limit value. Then the limit can be determined based on the values of f (10 k ). Various extensions and customizations of this basic approach can be made. For instance, to avoid issues with periodic functions f (10 k + Ç« k ), where Ç« k are randomly generated, can be used. Other values than 10 k can also be used as long as the sequence approaches infinity. A degree of automization can be introduced using different heuristics.\nB. Derivative\nDerivative is arguably the most important concept in calculus. There exist several rules such as the power rule, the product rule, the chain rule, and others to find the derivative of a function by hand. However, manual differentiation may be cumbersome when dealing with complex function. On the other hand, calculating the derivative at a point numerically is relatively straightforward. To illustrate, suppose that we want to calculate f â² (a). Recall that\nf â² (a) = lim xâa f (a + h) -f (a) h .(1)\nTherefore, to calculate f â² (a) numerically we use the same approach as with the limits. In particular, we can loop for k = 0 to n and calculate f (a+10 -k )-f (a) 10 -k\n. Then the limit, and by extension the derivative, can be deduced (approximated) based on the calculated values. The accuracy of the approximation depends in large part on the value of n.\nOne of the most important applications of the derivative is finding the extreme values of a function. Traditionally, this is done by first finding the critical points of the function and then applying the second derivative test. However, finding the critical points is not always possible, so numerical approaches can be used in such cases. The most popular numerical approach for finding the extreme values is based on the gradient descent (ascent) algorithm. In gradient descent, the optimal value of x is iteratively updated based on the gradient. In particular, for k = 0 to n, the updated optimal value of x is given by\nx k+1 = x k -Î±âf (x k ),(2)\nwhere âf (x) is the gradient and Î± is the step size. In the case of a single-variable function, the gradient equals simply to the derivative âf (x) = f â² (x). The step size Î± can be either fixed or dynamic. While a large value of Î± accelerates the convergence at the beginning, it may hurt the convergence in the region near the optimal value. There exist several extensions of the basic gradient descent algorithm. One such extension is gradient descent with momentum which uses the second derivative to anticipate the location of the next optimal point and thus accelerates the convergence.\nC. Integrals\nIntegration is an important concept in engineering mathematics. Although there exist a number of rules for finding the integral, it is significantly more challenging than differentiation. Moreover, in many cases, the indefinite integral does not even exist. Therefore, numerical approaches are particularly useful for integration.\nTo illustrate the application of numerical integration, suppose that we want to calculate\nThe Riemann sums can be quickly calculated on a computer providing a simple, yet effective approach to calculating integrals numerically. Other popular integral approximation methods include the trapezoid rule and the Simpson's rule.\nD. Additional considerations\nThe above discussion about numerical methods for calculating limits, derivatives, and integrals is easily extended to multivariate calculus. For instance, to find the partial derivative f x (a, b), we can loop for k = 0 to n and calculate\nf (a+10 -k ,b)-f (a,b) 10 -k\n. Many problems related to sequences and series can similarly be solved using numerical techniques. In particular, the convergence of a series can be deduced from its partial sums. By calculating the partial sums on the computer and observing the results, we can intuit the nature of the series.\nVectorization is an important aspect of numerical computing. Since the modern computer chips are optimized for matrix multiplication, it is more efficient to employ vector operations. In particular, some algorithms based on for-loops can be converted into vector operations resulting in higher efficiency and speed. For instance, the Riemann sum can be calculated with a single vector operation:\nÎ´ n k=1 f (x k ) = Î´S f (x) ,(4)\nwhere x = [x 1 , ..., x n ] is the vector of endpoints, f (x) is a vectorized function operation, and S is the vector function which returns the sum of all the coordinates. Similarly, limit calculations can be vectorized and made more efficient. Vectorization is also useful in multi-variate calculus, where operations can be performed on a vector of variables. The choice of the programming language for numerical computing requires careful consideration. There are several suitable candidates for this purpose including Python, Java, C++, Matlab, and others. Based on our experience with different programming languages, we recommend the use of Python. Python is currently the most popular programming language on the planet. It has a simple and intuitive syntax making it easy to learn and apply. Python has libraries to fit any purpose including an extensive collection of libraries related to numerical computing. The basic Python libraries related to computing are NumPy, SciPy, and SymPy. More advanced packages such as OR-Tools are also available for optimization tasks. Since Python is a universal programming language, it can be used for almost any task. Thus, students who learn Python in their mathematics courses can employ it in their other courses. In addition, numerical computing implemented in Python can be connected to other applications.\nV. CONCLUSION Although the classical approach to teaching mathematics is still relevant for certain student cohorts, it is outdated for engineering students. Modern engineering is increasingly reliant on computing[9],[22]. Therefore, universities must equip the student with appropriate computing skills. In particular, mathematics courses must be revised to include numerical computing content.\nGiven the efficiency of computer-based calculations, numerical computing provides a convenient approach to problem solving in engineering mathematics. It can be integrated into the existing curriculum with little hassle and cost. In this paper, we proposed a framework for integrating numerical computing into the existing mathematics curriculum. We demonstrated how numerical approaches can be used some of the most common problems encountered in calculus. The proposed framework can be customized by individual universities to fit their special needs.\n",
        "resume": "The rapid advances in technology over the last decade have significantly altered the nature of engineering knowledge and skills required in the modern industries. In response to the changing professional requirements, engineering institutions have updated their curriculum and pedagogical practices. However, most of the changes in the curriculum have been focused on the core engineering courses without much consideration for the auxiliary courses in mathematics and sciences. In this paper, we aim to propose a new, augmented mathematics curriculum aimed at meeting the requirements of the modern, technology-based engineering workplace. The proposed updates require minimal resources and can be seamlessly integrated into the existing curriculum.",
        "authors": [
            "Firuz Kamalov",
            "Ho-Hon Leung"
        ],
        "keywords": [
            "engineering mathematics",
            "numerical computing",
            "education",
            "Industry 4.0"
        ],
        "institutions": [
            "Canadian University Dubai Dubai Department of Electrical Engineering",
            "Emirates University Al Ain Department of Mathematical Sciences"
        ],
        "refrences": [
            "Abdul Majid, M Huneiti, Z Balachandran, W Al-Naafa. A study of the effects of using MATLAB as a pedagogical tool for engineering mathematics students 15th International Conference on Interactive Collaborative Learning (ICL) 2012.",
            "Abdul Majid, M Huneiti, Z A Balachandran, W Balarabe. MATLAB as a teaching and learning tool for Mathematics: A literature review International Journal of Arts and Sciences 2013, 6, 3, 23-44.",
            "M L Brake. MATLAB as a Tool to Increase the Math Self-Confidence and the Math Ability of First-Year Engineering Technology Students The Scholarship of Teaching and Learning at EMU 2007, 1.",
            "J Chen, A Kolmos, X Du. Forms of implementation and challenges of PBL in engineering education: a review of literature European Journal of Engineering Education 2021, 46, 1, 90-115.",
            "P Cretchley, C Harman, N Ellerton, G Fogarty. MATLAB in Early Undergraduate Mathematics: An investigation into the Effects of Scientific Software on Learning 2000, 12, 219-233.",
            "R G Hadgraft, A Kolmos. Emerging learning environments in engineering education Australasian Journal of Engineering Education 2020, 25, 1, 3-16.",
            "M Hernandez-De-Menendez, R Morales-Menendez. Technological innovations and practices in engineering education: a review International Journal on Interactive Design and Manufacturing (IJIDeM) 2019, 13, 2, 713-728.",
            "M HernÃ¡ndez-De-MenÃ©ndez, A V Guevara, J C T MartÃ­nez, D H AlcÃ¡ntara, R Morales-Menendez. Active learning in engineering education. A review of fundamentals, best practices and experiences International Journal on Interactive Design and Manufacturing (IJIDeM) 2019, 13, 3, 909-922.",
            "F Kamalov, S Moussa, R Zgheib, O Mashaal. Feature selection for intrusion detection systems 2020 13th International Symposium on Computational Intelligence and Design IEEE 2020, December, 265-269.",
            "F Kamalov, H Sulieman, D Santandreu Calonge. Machine learning based approach to exam cheating detection Plos one 2021, 16, 8.",
            "A Kilicman, M A Hassan, S K Said Husain. Teaching and Learning using Mathematics Software The New Challenge'. Procedia Social and Behavioral Sciences 2010, 8, 613-619.",
            "M Lorenz, M RÃ¼Ãmann, R Strack, K L Lueth, M Bolle. Man and machine in industry 4.0: How will technology transform the industrial workforce through 2025 The Boston Consulting Group 2015, 2.",
            "R D A MaurÃ­cio, L Veado, R T Moreira, E Figueiredo, H Costa. A systematic mapping study on game-related methods for software engineering education Information and software technology 2018, 95, 201-218.",
            "N M Mezhennaya, O V Pugachev. On perception of computer algebra systems and microsoft excel by engineering students. Problems on Education in the 21st Century 2019, 77, 379-395.",
            "J Miranda, C Navarrete, J Noguez, J M Molina-Espinosa, M S RamÃ­rez-Montoya, S A Navarro-Tuch, . . Molina. The core components of education 4.0 in higher education: Three case studies in engineering education Computers & Electrical Engineering 2021, 93.",
            "K Moore, R S Frazier. Engineering education for generation Z American Journal of Engineering Education (AJEE) 2017, 8, 2, 111-126.",
            "M Ortiz-Rojas, K Chiluiza, M Valcke. Gamification through leaderboards: An empirical study in engineering education Computer Applications in Engineering Education 2019, 27, 4, 777-788.",
            "R I Puhak. Teaching applied Calculus utilizing MATLAB Proceedings of the Twenty-Third Annual International Conference on Technology in Collegiate Mathematics Copyright (C) 2012 by Pearson Education, Inc 2011.",
            "R A Ramirez-Mendoza, R Morales-Menendez, H Iqbal, R Parra-Saldivar. Engineering Education 4.0:-proposal for a new Curricula IEEE Global Engineering Education Conference IEEE 2018, April. 2018, 1273-1282.",
            "B Salah, M H Abidi, S H Mian, M Krid, H Alkhalefah, A Abdo. Virtual reality-based engineering education to enhance manufacturing sustainability in industry 4.0. Sustainability 2019, 11.",
            "T L Strayhorn. College in the information age: Gains associated with students' use of technology Journal of Interactive Online Learning 2006, 5, 2, 143-155.",
            "F Thabtah, F Kamalov, K Rajab. A new computational intelligence approach to detect autistic features for autism screening International journal of medical informatics 2018, 117, 112-124.",
            "A Van Den Beemt, M Macleod, J Van Der Veen, A Van De Ven, S Van Baalen, R Klaassen, M Boon. Interdisciplinary engineering education: A review of vision, teaching, and support Journal of engineering education 2020, 109, 3, 508-555."
        ],
        "created_at": "2024-02-01T13:58:40.774268+00:00",
        "updated_at": "2024-02-01T13:58:51.818769+00:00"
    },
    {
        "id": 13,
        "title": "Fuzzy logic based MPPT control for a PV system using SEPIC converter",
        "body": "I. INTRODUCTION\nThe non-renewable energy sources are rapidly running out, while the electricity demand is increasing daily. To solve this problem, efficient and efficient electric power generation from renewable energy sources is required[1]. Renewable energy is one of the forms of energy that society can rely on because It is unpolluted, pure, and has no limits. One type of power generation that uses renewable energy is the photovoltaic (PV) system[2]. To utilize less conventional energy, the PV system must subsequently be linked to the grid, either directly or via a backup battery bank. Since the power produced by PV systems depends on radiation and temperature change, the PV framework has destitute productivity,[2].\nFor the control of the PV systems, there are different sorts of DC-DC converters such as Buck converters, Boost converters, and Buck-Boost converters. Due to its output pick-up adaptability, a single-ended primary-inductor converter (SEPIC) acts as a buck-boost DC/DC converter, where it changes its output voltage agreeing to its duty cycle. Unlike the customary buck-boost converter, the SEPIC converter includes a non-inverted output and it uses an arrangement capacitor to separate input from output[3]. The buck and buck-boost converters lose half of their input control due to input current arrangement exchange; for that reason, the two types of converters should be excluded from maximum power applications. The boost converter has a nonstop input current, but the output voltage is always bigger than the input, which may not accomplish maximum power exchange operation in a few cases, such as when the maximum voltage is less than the input[3]. This paper presents a fuzzy-based P&O strategy for an MPPT standalone PV system. The proposed MPPT can abuse the preferences of the P&O strategy and eliminate its drawbacks. Output has been separated into five fuzzy subsets. As the proposed strategy continuously exchanges maximum power from PV arrays, it optimizes the number of PV modules.\nII. MODELIGN OF PV SYSTEM\nPhotovoltaic is the technique and study connected to devices that directly convert sunlight into electricity utilizing photovoltaic semiconductors. Direct conversion of solar energy into DC electrical energy can be achieved by photovoltaic cells[4]. The photovoltaic panel is made up of numerous cells that are connected in series Ns or shunt Nsh. Where it may be mimicked by a current source coupled in parallel with a diode as described by and depicted in Figure1 [5]. The following equations provide the output current:\nI = I ph -I D(1)\nI = I ph -I 0 [exp ( q(V+R s I) AK B T ) -1] - V+R s I R sh\n(2)\nI ph â¶ Photo -current A â¶ Ideality factor K B â¶ Constant of Boltzmann T â¶ Cell temperature I D â¶ Current via a diode R s â¶ Series resistance I 0 â¶ Current of Saturation q â¶ Electronic charge R sh â¶ Shunt resistance V â¶ Cell voltage I â¶ Current of cell\nThe shunt resistance (R sh ) is typically orders of magnitude larger than the series resistance (R s )[6]. Therefore, it is common for the shunt and series resistances of a solar cell can be neglected to simplify the model. The resulting ideal voltagecurrent characteristic of the solar cell is given by equation (3).\nI = I ph -I 0 [e ( qV KT ) -1](3)\nIII. SEPIC CONVERTER\nPower electronics researchers are working hard to create DC-DC converters with simpler designs and greater efficiency[7]. To maintain a constant output voltage, the suggested DC-to-DC converter employs a single-ended primary-inductor converter (SEPIC) architecture. The SEPIC converter is made up of a duty cycle switch S, a diode, two inductors (L1 and L2), two capacitors (C1 and C2), and a load resistor. Figure2depicts the circuit diagram of a SEPIC converter. A SEPIC is a DC-DC converter[8]. SEPIC are DC-DC converters that can output voltages that are B, larger than, or equal to the input voltage. The duty cycle of the control transistor affects the SEPIC converter's output voltage. The SEPIC converter is two converters in one: a boost converter followed by a buck-boost converter. It has the advantages of having a non-inverted output (the output voltage has the same polarity as the input voltage) , using a series capacitor to couple energy from the input to the output (which makes it more responsive to short-circuits), and being able to shut down completely: when the switch \"S\" is turned off, the output voltage drops to 0 V, accompanied by a significant transient discharge of charge.   When the switch is turned on, the input inductor is charged from the source, and the second inductor is charged from the first capacitor. No energy is supplied to the load capacitor during this time. The inductor current and capacitor voltage polarities are marked in this Figure . When the power switch is turned off, the energy stored in the inductor is transferred. The energy stored is transferred through the diode and supplies the energy to the load[10], as shown in Figure3. b. The second inductor is also connected to the load during this time. The output capacitor sees a pulse of current during the off time, making it inherently noisier than a buck converter. The amount that the SEPIC converters increase or decrease the voltage depends primarily on the duty cycle and the parasitic elements in the circuit. The output of an ideal SEPIC converter is:\nV out = D 1-D V in(4)\nA SEPIC converter is to process the electricity from the PV system. This converter either increases or decreases the PV system voltage at the load. The proposed SEPIC converter operates in buck mode.\nIV. FUZZY LOGIC CONTROL\nIn the fuzzy logic maximum power point tracking (MPPT) algorithm, the voltage and current at each instant k are measured to calculate the active power. The active power is then compared with the power at the previous instant (k-1) to obtain the change in power (ÎP(k)). Similarly, the voltage at instant k is compared with the voltage at instant k-1 to obtain the voltage error (ÎV(k))[11]. The power error is then divided by the current error to obtain the error (E). The error is then compared with the previous error to calculate the change in error (ÎE(k)). The error (E(k)) and the change in error (ÎE(k)) are then used as the crisp inputs to the fuzzy logic controller. The flow chart for the fuzzy logic MPPT algorithm is shown in Figure4. In this work, the Mamdani inference technique, Atype membership functions, and a 25-element rule base were used for the fuzzy logic control. The Mamdani inference technique is efficient and straightforward in defining the fuzzy output sets, and it is more popular among researchers than other inference techniques[12]. The A-type or triangular membership function is used because it is simpler to split into low and high membership functions (MFs) than other membership functions. Additionally, it has been observed that the triangular membership function has a faster response and less overshoot than other functions[13]. A 25-element rule base was used because it has been shown to perform well[14][15]. The following are the fuzzy rules in Table1, which are used for the desired MPP of push-pull converter PWM. The membership for input variables (DPpv, DVpv) are shown in Figure5, and the membership for output variable (DVpv*) is shown in Figure6. All the functions are defined on a normalized interval [-1 1].\nV. SIMULATION RESULTS\nThe characteristics of the photovoltaic array that we use in this paper are given in Table2. Current at maximum power I max = 6.9 A Table3shows the SEPIC converter settings utilized in this study. The SEPIC converter is linked to the PV panel in the full model, and the duty cycle is regulated by the Fuzzy Logic Controller. The results are provided under standard test conditions; G=1000 W/m2; T=25Â°C and it is shown in figure7.   Overall, using MPPT and fuzzy logic to a SEPIC converter for a PV system result in considerable performance gains. Increased power output, higher efficiency, decreased ripple, enhanced transient response, and resilience are examples of these enhancements.\nTable. 2. Electrical data\nâ¥. CONCLUSIONS This paper presents the design of an off-grid photovoltaic system with a fuzzy logic MPPT-controlled push-pull boost converter. The proposed system was simulated in MATLAB/Simulink and tested under various weather conditions. The results showed that the fuzzy logic algorithm outperformed the conventional algorithms in terms of MPPT accuracy and minimization of fluctuations, regardless of rapid changes in irradiance.\n",
        "resume": "In this study, a novel single-ended primary inductor (SEPIC) converter-based fuzzy logic controller for maximum power point tracking is presented. By adding rules to the perturb and observing search strategy, the new controller enhances it while fuzzifying and removing its flaws. When compared to traditional maximum power point tracking techniques, fuzzy logic trackers enable an accurate and quick convergence to maximum power point under both steady-state and variable weather situations. The performance of the proposed maximum power point tracker is demonstrated in simulation.",
        "authors": [
            "Moulay Abdellah",
            "Alhachemi Mohammed Habbab",
            "Abdeldjebar Hazzab",
            "Mansour Becahr",
            "Hicham Gouabi"
        ],
        "keywords": [
            "Fuzzy logic controller (FLC)",
            "Maximum power point tracker (MPPT)",
            "Photovoltaic (PV)"
        ],
        "institutions": [
            "UniversitÃ© Tahri Mohamed",
            "UniversitÃ© Tahri Mohamed Laboratory of CAOSEE Ãcole de Technologie SupÃ©rieure",
            "UniversitÃ© Tahri Mohamed Laboratory of CAOSEE Laboratoire de CAOSEE Ãcole de Technologie SupÃ©rieure"
        ],
        "refrences": [
            "G Mahendran, K V Kandaswamy. Ant Colony Optimized Tuned DC-DC converter International Journal of Computer 2013, 45-50.",
            "J Dunia. Performance Comparison between ÄUK and SEPIC Converters for Maximum Power Point Tracking Using Incremental Conductance Technique in Solar Power Applications International Journal of Electrical, Computer, Energetic, Electronic and Communication Engineering 2013, 7, 2510-2517.",
            "M Cirrincione, M Pucci, G Vitale. Growing Neural Gas (GNG)-Based Maximum Power Point Tracking for High-Performance Wind Generator With an Induction Machine IEEE Transactions on Industry Applications 2011, 47, 861-872.",
            "M Abdulkadir, A S Samosir, Ahn Yatim. Modeling and Simulation of a Solar Photovoltaic System, Its Dynamics and Transient Characteristics in LABVIEW International Journal of Power Electronics and Drive System (IJPEDS) 2013, 3, 2, 185-192.",
            "H Bouzeria, C Fetha, T Bahi, I Abadlia, Z Layate, S Lekhchine. Fuzzy Logic Space Vector Direct Torque Control of PMSM for Photovoltaic Water Pumping System Energy Procedia 2015, 74, 760-771.",
            "Y M Chen, Y C Liu, S C Hung, C S Cheng. Multi-Input Inverter for Grid-Connected Hybrid PV/Wind Power System IEEE Transactions on Power Electronics 2007, 22, 3, 742-750.",
            "S Ganesh, J Janani, G B Angel. A Maximum Power Point Tracker for PV Panels Using SEPIC Converter International Journal of Electrical, Computer, Energetic, Electronic and Communication Engineering 2014, 8, 637-642.",
            "R Vijayabalan, S Ravivarman. Z Source Inverter for Photovoltaic System with Fuzzy Logic Controller International Journal of Power Electronics and Drive System (IJPEDS) 2012, 2, 4, 371-379.",
            "A Ramkumar, Svs Florence. Analysis of Single Phase AC-DC SEPIC Converter using Closed Loop Techniques International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering 2015, 4, 193-201.",
            "G Tadi, P Ramamurthyraju. Analysis of SEPIC for PV-Applications using PI Controller and Current Mode Control International Journal for Scientific Research & Development 2013, 1, 9, 175-180.",
            "J Li, H Wang. A novel stand-alone PV generation system based on variable step size INC MPPT and SVPWM control Proceedings of the 2009 IEEE 6th International Power Electronics and Motion Control Conference May 2009, 2155-2160.",
            "C Wang. A Study of Membership Functions on Mamdani-Type Fuzzy Inference System for Industrial Decision-Making 2015, Master's thesis.",
            "Ã Usta, Ä° H Akyazi, R K AltaÅ ; Mudi, N R Pal. Design and performance of solar tracking system with fuzzy logic controller used different membership functions Proceedings of the 2011 7th International Conference on Electrical and Electronics Engineering (ELECO) 1-4 December 2011. 1999, 7, A robust selftuning scheme for PI-and PD-type fuzzy controllers, 2-16.",
            "N R Mudi. A robust self-tuning scheme for PI-and PDtype fuzzy controllers IEEE Transactions on Fuzzy Systems 1999, 7, 1, 2-16.",
            "A Shehata, H Metered, Wah Oraby. Vibration control of active vehicle suspension system using fuzzy logic controller Vibration Engineering and Technology of Machinery , 389-399."
        ],
        "created_at": "2024-02-01T13:58:10.965782+00:00",
        "updated_at": "2024-02-01T13:58:18.782672+00:00"
    },
    {
        "id": 12,
        "title": "The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development",
        "body": "1 INTRODUCTION\nSoftware development is a highly skilled task that requires knowledge, focus, and creativity[27,28]. Many techniques have been developed to enhance the productivity of software engineers, such as advanced code repositories[86], knowledge repositories[39], Q&A sites[1], and pair programming practices[18]. Collaborative software engineering is especially promising, given that professional software development is rarely a solo activity and relevant knowledge and expertise are typically distributed widely within an organization[68]. Many efforts have focused on incorporating collaborative technologies into software development environments (e.g.[8,25,26,58,101]).\nThe pioneering work of Rich and Waters on The Programmer's Apprentice[70]presented a novel concept of a knowledgeable automated assistant -in effect, an artificial collaborative partner -that could help software engineers with writing code, designing software systems, and creating requirements specifications. At the time, AI technologies and computing resources were not sufficient to fully implement their vision. In the intervening years, an increase in computational power, the availability of large corpora of language and code data, and the development of deep neural networks have made new approaches to achieving their goals worth exploring.\nRecently, models leveraging the transformer architecture[96]have been developed to perform domain-specific software engineering tasks, such as translating code between languages[75], generating documentation for code[36,38,97,98], and generating unit tests for code[92](see Talamadupula[90]and Allamanis et al.[5]for surveys). Recently developed foundation models -large language models that can be adapted to multiple tasks and which exhibit emergent behaviors for which they have not been explicitly trained[14]-have also proven to be capable with source code.\nWhile the intent of training LLMs such as GPT-2[64]and GPT-3[17]was to give them mastery of natural language, it quickly became apparent that the presence of code in their training corpora had given them the ability to generate code based on natural language descriptions[49]. The Codex model[24]was then produced by finetuning GPT-3 on a large corpus of source code data, leading to the development of Copilot[32], a tool that helps software engineers by autocompleting code as it is being written. Experimentation with Copilot has shown its ability to perform additional tasks, such as explaining code, generating documentation, and translating code between languages[6].\nAlthough autocompletion interfaces are useful and valuable when the system can discern the developer's intent, there are many instances where that is insufficient. For example, the developer may have a good idea of what they want to do, but may be unclear on what functions, libraries, or even algorithms to employ. They may even have general programming questions that need to be answered before they are able to write any code.\nIn this paper, we seek to understand whether modern developments in code-fluent foundation models -large language models that have been fine-tuned on source code data -are sufficient to support a conversational agent that can act as an assistant in the software development process. We developed the Programmer's Assistant to explore the capabilities that conversational interaction could enable and the extent to which users would find conversational assistance with programming tasks desirable and useful.\nWe hypothesize that a conversational system may provide a flexible and natural means for interacting with a code-fluent LLM. Conversational interaction could enable users to pursue their questions in a multiple exchange dialog (as observed by Barke et al.[13]) that allows them to ask follow-up questions and refine their inquiries. A conversational programming assistant could ask the user clarifying or disambiguating questions to help it arrive at the best answer. It could also provide multiple types of assistance to the user beyond simply generating code snippets, such as engaging in general discussion of programming topics (e.g.[22,71]) or helping users improve their programming skills (as observed in other studies of automating technologies[99]).\nOur paper makes the following contributions to the IUI community:\nâ¢ We provide empirical evidence that a conversational programming assistant based on a state-of-the-art, code-fluent foundation model provides valuable assistance to software engineers in a myriad of ways: by answering general programming questions, by generating context-relevant code, by enabling the model to exhibit emergent behaviors, and by enabling users to ask follow-up questions that depend upon their conversational and code contexts. â¢ We show how different interaction models -conversation, direct manipulation, and search -provide complementary types of support to software engineers with tradeoffs between the user's focus and attention, the relevance of support to their code context, the provenance of that support, and their ability to ask follow-up questions.\nâ¢ We motivate the need to further understand how to design human-centered AI systems that enhance the joint performance of the human-AI collaboration.\n2 RELATED WORK\nWe discuss three areas of related work that have either motivated our study of conversational programming assistance or provided the technical foundations for it. We begin by briefly summarizing Rich and Waters' visionary work on the Programmer's Apprentice[70], followed by summarizing work on code-fluent foundation models and human-centered evaluations of how these models impact software engineers' work. Finally, we discuss conversational interaction and how it might be employed to provide more flexible and sophisticated assistance to software engineers.\n2.1 The Programmer's Apprentice\nOur work is inspired by the vision laid out by Rich and Waters[70], which describes an artificial agent that can act as an intelligent assistant for software engineers by providing advice, catching errors, and handling routine details throughout the software development process. The Programmer's Apprentice[70]relied on a knowledge base of \"clichÃ©s,\" which are formal, structured versions of what are known today as software design patterns[31]. It used a hybrid reasoning system capable of special-purpose reasoning based on frames and a plan calculus, along with general purpose logical reasoning. Although natural language interaction was envisioned, the original prototype implementation ultimately used a stylized command language. We view our work as a conceptual successor to the Programmer's Apprentice, as it enables the natural language interaction that the Programmer's Apprentice lacked.\n2.2 Code-fluent Foundation Models and Human-Centered Evaluations of Programming Assistance\nGenerative models based on the transformer architecture[96]have recently been applied to the domain of software engineering. Codefluent large language models are capable of generating code from natural language descriptions[105], translating code from one language to another[75], generating unit tests[92], and even generating documentation for code[36,38,97,98]. These models are probabilistic systems, and as such, do not always produce perfect results (e.g. code that is free of syntax or logical errors). Nonetheless, Weisz et al.[102]found that software engineers are still interested in using such models in their work, and that the imperfect outputs of these models can even help them produce higher-quality code via human-AI collaboration[103]. New tools based on code-fluent LLMs are actively being developed. GitHub Copilot1is described as \"Your AI pair programmer. \" It is optimized for the code autocompletion use case: given a starting snippet such as a method's documentation, signature, or partial implementation, Copilot completes the implementation. Copilot is based on the OpenAI Codex model[24], a 12 billion parameter version of GPT-3[17,49], fine-tuned on code samples from 54 million public software repositories on GitHub. Empirical evaluations of this model have shown that, although the quality of its outputs is quite good, those outputs may still be problematic[57]. Echoing the results from Weisz et al.[103], human-centered evaluations of Copilot have found that it increases users' feelings of productivity[109], and that almost a third (27%) of its proposed code completions were accepted by users. In a contrasting evaluation, Vaithilingam et al.[95]found that while most participants expressed a preference to use Copilot in their daily work, it did not necessarily improve their task completion times or success rates. Yet, in a study byKalliamvakou [40], developers working with Copilot were able to implement a web server in Javascript 55% faster than developers who did not use Copilot.\nA grounded theory analysis of how programmers interact with Copilot[13]found that their interactions varied depending upon whether they were accelerating tasks that they already knew how to do or if they were exploring solutions to problems that they were less sure about. Autocompletion was effective when developers were operating in \"acceleration mode\" and relied on the model to produce short completions that could be verified quickly. In \"exploration mode,\" however, the interaction was more awkward. Developers would communicate with Copilot by typing comments and seeing what Copilot generated in response. Then, they would modify their comments to explore other ways of prompting a response. Ultimately, the comments used to prompt the model would be deleted after the relevant code was generated, indicating that their value was largely in driving a back-and-forth, yet context free, dialog with the model to coerce it to produce the desired results through an iterative refinement process. In this paper, we fully commit to a context-aware conversational style of interaction with a code-fluent LLM and assess the value it provides to users.\n2.3 Conversational Interaction and Analysis\n2.3.1 Conversational Interaction.\nUsing natural language to interact with technology has had a long research history[2], starting in the 1960s with pattern-matching approaches like Eliza[104], and continuing to today with state-of-the-art large language modelbased conversational systems[107]such as Meena[3]and Blender-Bot[84]. These systems are intended to address the problem of open-domain dialog, with a goal of realistically engaging in conversation, but not particularly in a goal-directed or task-oriented manner.\nTask-oriented chatbots are typically built with frameworks such as the Microsoft Bot Framework2, Google DialogFlow3, and IBM Watson Assistant4. They operate using pre-defined dialogue trees and use natural language processing to detect conversational intents and extract contextual entities. This structure enables the creation of special purpose, but fairly limited and rigid, conversational agents.\nThere have been several recent attempts to investigate conversational programming assistance. Kuttal et al.[42]conducted a Wizard of Oz study in which a pair programmer was replaced with a conversational agent, and they found that \"agents can act as effective pair programming partners.\" The PACT system[106]is a chatbot that assists programmers adjusting to new programming environments. PACT is structured as a discrete question-answering system based on a neural machine translation approach, but it doesn't maintain a conversational context.\n2.3.2 Conversation Analysis.\nConversation is a form of interaction between people that enables robust communication. Conversation Analysis[76]is a method for understanding the natural structure of human conversational interaction. It catalogs different patterns of conversational acts and how they are utilized by interlocutors in order to attain a wide variety of goals. Recently, Conversation Analysis has been adapted to describe patterns of interactions between humans and artificial conversational agents in order to aid in the design of chatbots[50]. We apply techniques from Conversation Analysis in our study of conversational programming assistance.\n3 THE PROGRAMMER'S ASSISTANT\nIn order to explore conversational programming assistance, we created a functional prototype system called The Programmer's Assistant. Our prototype, shown in Figure1, combines a code editor with a chat interface. The code editor was implemented using the Microsoft Monaco Editor5embedded in a React wrapper6. The chat user interface was implemented using the React-Chatbot-Kit7framework. To drive the conversational interaction, we employed OpenAI's Codex model[24], accessed through its web API.\nWe developed our prototype as a lightweight coding environment in order to examine the user experience of interacting with a conversational assistant. Our work was exploratory in nature, and thus we did not have specific design goals for the prototype beyond integrating a code editor with a code-fluent LLM. We also did not attempt to target the prototype for a specific class of users (e.g. novices or experts) or use cases (e.g. writing code vs. learning a new programming language), as we wanted any value provided by conversational assistance to emerge from our user study. We also did not implement the ability to run or debug code in our prototype as we wanted to explore the nature of the conversational interaction rather than having users focus extensively on the production of working code.\nWhen designing how users would interact with the Programmer's Assistant, we decided that it should be available on demand and not monitor the user's work in progress or give unsolicited suggestions or advice, in keeping with the conversational agent interaction model proposed by Ross et al.[73,74]. This approach was supported by feedback from prospective users who were concerned about the assistant providing criticism of unfinished efforts in progress or distracting them while they worked. Instead, we force initiative onto the user and only have the assistant respond to their requests. In this way, the assistant can provide help when requested without undesirable interruptions that can distract or interfere with the user's flow.\nWhen a user interacts with the assistant, we keep track of their selection state in the code editor. If a user sends a message to the assistant without any code selected in the editor, then that message (along with the prior conversational context) is passed directly to the model. If a user sends a message to the assistant with new code selected in the editor (i.e. code that wasn't previously selected when they sent their last message), then that code is appended to the message before being communicated to the model.\nThe model may produce multiple types of responses to a user's message. We treat each type of response differently in the UI.\nâ¢ Responses that do not contain code are always rendered in the chat UI (Figure1E). â¢ Responses containing short code snippets (â¤ 10 lines) are rendered inline in the chat UI (Figure1G). â¢ Responses containing longer code snippets (> 10 lines) show the code in a pop-up window (Figure2A), with a proxy entry in the chat transcript (Figure2B) that allows users to redisplay the code window after it has been closed. Non-code text in the response remains in the chat transcript. The assistant never directly modifies the contents of the user's source code; rather, any code the user desires to transfer from the chat takes place via copy/paste.\nFigure1shows a screenshot of a real, sample conversation, in which the user asks a question that results in an inline response, then requests an explanation of some code in the editor, and then requests further elaboration. Figure2shows an example conversation that resulted in the generation of a longer code sample, shown in a popup window. This example shows how the assistant produced an incomplete solution, followed by criticism from the user regarding the missing code, and resulting in an apology and the generation of a complete solution.\n3.1 Supporting Conversational Interaction\nWe enabled Codex to conduct a conversational interaction by prompting it with a conversational transcript and a request to produce the next conversational turn. The prompt establishes a pattern of conversation between a user and a programming assistant named Socrates. It provides several examples of Socrates responding to general coding questions, generating code in response to a request, and accepting code as input. It establishes a convention for delimiting code in the conversation, making it easy to parse for display in the UI. It also establishes an interaction style for the assistant, directing it to be polite, eager, helpful, and humble, and to present its responses in a non-authoritative manner8. Because of the possibility that the model might produce erroneous answers or incorrect code (as discussed in Weisz et al.[102]), we felt it was important that the assistant convey a sense of uncertainty to encourage users to not accept its results uncritically to avoid over-reliance (e.g. as observed in Moroz et al.'s study of Copilot[51], and discussed more generally in Ashktorab et al.[9]) as well as automation bias[45,46,65]. We present the full text of the prompt used for the assistant in Appendix D.\n3.2 Architecture & UI Design\nThe Programmer's Assistant communicates with the Codex API via a proxy server that forwards requests from the React client. The proxy also rate-limits access to conform to the API's policy, and it logs UI events from the client (e.g. requests, responses, and UI interactions) in a back-end database. To address inconsistencies in the style or formatting of code generated by Codex, the proxy server reformats all code segments using the Black code formatter9before transmitting them to the client UI.\nThe client maintains the transcript of the ongoing conversation. Each time the user sends a message in the chat, the client constructs a new prompt for the model by concatenating the initial prompt, the chat transcript, and the user's new utterance, and makes a request for the model to complete the transcript. This completion request also specifies a stop sequence of tokens to prevent the model from generating both sides of the conversation (e.g. what the model thinks the user's next utterance might be after the assistant's response). Given the API's limitation on context length (4,096 tokens for both the prompt and model response), we silently \"forget\" older exchanges in the chat transcript when constructing the prompt to ensure that our completion request remains within bounds. Nonetheless, the entire conversational history remains visible to the user in the UI.\nThe client UI provides a loose coupling between the source code editor and the chat interface. Users can hide the chat pane when they wish to focus solely on their code, and re-engage with it when they desire assistance. Code selected in the editor is included in the conversation in order to couple the code context with the conversation. Easily-accessible buttons are provided in the UI to copy code responses from the assistant to the clipboard.\n3.3 Handling Model Limitations\nWhile developing the Programmer's Assistant, and in early pilot testing, we experienced some quirks and shortcomings of the model and our approach to using it for conversational interaction. One limitation stemmed from the fact that the model sometimes produced incorrect responses (e.g. code with syntax errors), incomplete responses (e.g. code that was missing functionality), irrelevant responses (e.g. responses not related to the user's question), or insubstantial responses (e.g. \"I don't know\"). Because of the probabilistic nature of model inference, re-prompting the model would sometimes produce a more correct or appropriate response. Thus, we added the ability for users to \"try again, \" either by asking in the chat or by clicking a button in the UI (Figure1C). This feature removes the assistant's last response from the context presented to the model and then re-invokes the model with an increased temperature10.\nAlthough it is possible for transformer models such as Codex to produce multiple possible responses to a single prompt, we only request a single response in order to speed up response time as well as to preserve the token budget for conversational context. Thus, the \"try again\" feature provides an alternate way to produce a wider variety of responses.\nDuring pilot testing, we noticed that the assistant sometimes happened to generate the same response to multiple, unrelated requests. In these cases, the assistant tended to get \"stuck\" in a pattern of repeating the same response and was unable to resume normal conversation. To avoid this problem, we automatically execute a The \"try again\" button (C) allows users to ask the assistant to generate an alternate response to the most recent question. The \"start over\" button (D) resets the conversational context for the assistant, but maintains the chat transcript in the UI. In this example, we show the assistant introduce itself to the user (E). Next, the user asks a general programming question (F), for which the assistant provides an inline code response (G). The user then asks a question about code selected in the editor (H), followed by a series of follow-up questions.\n\"try again\" operation in the background when we see identical consecutive responses from the assistant. Finally, we noticed that the accumulation of conversational context sometimes resulted in the assistant becoming fixated on some portion of the earlier conversation. For example, it might respond to a question with portions of the prompt or of earlier conversation, and become less responsive to newer requests. To address this issue, we introduced a \"start over\" feature, accessible via the chat or by clicking a button in the UI (Figure1D), that resets the context to the original prompt, forgetting the rest of the conversational history. We preserve the chat transcript in the UI, but delineate the break in the assistant's memory with an annotation in the chat transcript. These annotations are added both for \"try again\" and \"start over. \"\n3.4 Sample Conversation\nWe provide a real sample conversation with the Programmer's Assistant in Listing 1. This conversation begins with the assistant greeting the user (line 1). Next, the user asks a general Python programming question (line 4), to which the assistant responds with a non-authoritative remark (\"I think...\") and a code snippet (line 9). The user next asks a follow-up question that depends on their previous question and the assistant's response (line 11), to which the assistant provides another code snippet (line 15), satisfying the user's request.\nThe user then switches topics and asks the assistant to write a Fibonacci function (line 17), and the assistant again responds with a non-authoritative remark (\"I will give it a try, \" line 20) and a block of code. The user then asks how the function works (line 30) and the assistant provides an adequate description (line 32). Next, the user asks the assistant to re-implement the function in a different way (line 37), again leveraging the ability to ask follow-up questions. The assistant produces an alternative implementation that conforms to the user's request (line 41). The user follows up with a question that depends on multiple past utterances and responses in the chat transcript (line 47), and the assistant produces a relevant response (line 49). The conversation closes with the user thanking the assistant (line 53) and the assistant acknowledging their gratitude (line 55).\nListing 1: A conversation with the Programmer's Assistant. Code presented by the assistant is listed in bold face. To address our questions, we deployed the Programmer's Assistant within our organization -a global technology company -and invited people to try it out and give us feedback on their experience. We invited people with varying levels of programming skill in order to obtain a wide range of feedback on the kinds of use cases for which the tool could provide assistance.\n4.1 Tasks\nWe set up the Programmer's Assistant as a playground environment that participants could try out with a few sample programming problems. We created a tutorial to orient participants to the assistant, its capabilities, and how to interact with it. We also created four programming challenges focused on writing code, documenting code, and writing tests for code. We designed these challenges to expose participants to a broad range of the assistant's capabilities. For each of these challenges, we explicitly did not evaluate metrics such as the participant's productivity, the quality of their solutions, or the time taken to produce them, as the focus of our study was to understand the utility of conversational interaction. We selected Python as the language used for the tutorial and challenges because of its general popularity[21]and the fact that it was well-supported by our underlying LLM[24].\n4.1.1 Tutorial. All participants were first introduced to the Programmer's Assistant through a tutorial. The tutorial walked each participant through 10 sample interactions to give them a feeling for what the assistant could do and how to interact with it. The tutorial demonstrated how to ask questions, how to request code to be generated, and how to evaluate existing code. It did not specifically cover how to generate documentation or unit tests. Tutorial instructions were provided within the code editor. We include the specific text used for the tutorial in Appendix B.\n4.1.2 Programming Challenges. After completing the tutorial, participants unlocked four programming challenges. Two of the challenges involved coding problems (writing a queue class and writing code to create a scatterplot of data in a CSV file), one involved documenting a given function (an implementation of a graph search algorithm), and one involved writing unit tests for a given function (computing the greatest common divisor of two arguments). Although the Programmer's Assistant was visible and available for use, we provided no specific requirement that it actually be used to complete the challenges.\nAfter participants completed their solution to a challenge, they submitted it by clicking a button in the UI. The code editor used in the Programmer's Assistant was not a fully-functional IDE and did not provide syntax checking or the ability to run, test, or debug code. Due to these limitations, participants were asked to submit their solutions when they felt they had completed the challenge to their own satisfaction.\n4.2 Participants\nTo recruit participants for our study, we posted internal advertisements in various communications channels focused on software engineering. Our advertisements stated that we were evaluating a conversational programming assistant, but were kept deliberately vague in order to minimize the impact on peoples' expectations of the experience.\nOur advertisement yielded a pool of 140 potential participants. In order to recruit a diverse sample, we used a screening survey that asked about their job role, their familiarity with and recency of use of Python, and their availability to participate in our study. We accepted participants into the study on a rolling basis, selecting participants to capture a range of programming experiences and ensure balanced gender representation. We conducted periodic reviews to determine whether we were learning something new from each participant or if we had reached the point of saturation[7]. We stopped collecting data after running 42 participants as we were no longer observing any new behaviors or gleaning any new insights. The Programmer's Assistant implementation and configuration were held constant over the course of the study; no changes to the UI design or LLM prompt were made.\nOur participants had the following self-identified characteristics: â¢ Recency of Python Use: 29 participants had written Python code within the past month, 4 within the past year, 5 within the past 5 years, and 4 had not written Python code within the past 5 years.\nWe provide full demographic information for individual participants in Appendix E.\n4.3 Procedure\nParticipants completed the study on their own time, independently and without moderation. Each participant was provided with a web link to a pre-study survey that described the nature of the study and the tasks that they would be expected to perform. They were then directed to the Programmer's Assistant to complete the tutorial and the four programming challenges. When participants indicated they were finished with the challenges12, they were directed to a final post-study survey. Complete sessions generally required about an hour of effort, though some participants spread their effort across a longer period of time and across multiple sessions. Participants were compensated for their time at a rate equivalent to US $15/hr.\n4.4 Measures\nWe collected a variety of data in our study from three sources:\n(1) Surveys. We employed three surveys in the study: a prestudy survey to collect demographic information, a pre-task survey to gauge expectations of the conversational user experience, and a post-task survey to assess actual user experience. We describe these survey questions in the relevant context of our results, and we provide a complete listing of all survey instruments in Appendix A. (2) Event logs. The Programmer's Assistant was instrumented to collect data on participants' usage. The event logs provided timestamped records of interaction events, including conversational exchanges, hiding/showing the assistant, use of the \"try again\" and \"start over\" features, and use of copy/paste. (3) Conversation logs. From the event logs, we extracted conversational transcripts between each participant and the Programmer's Assistant.\n5 RESULTS\n5.1 Data & Analysis\nWe collected a wealth of data in our study: 126 survey responses from three surveys per participant, containing 296 written comments in open-ended survey questions, and 4,877 instances of 23 different types of UI events, including 1,699 conversational exchanges13in the event logs. We also compute, for each participant, counts or durations for 21 different metrics from the event logs.\nIn our analysis, we deliberately exclude the portion of our data collected during the tutorial exercise. We exclude this data because that activity was guided by the tutorial instructions, not by our participants' own initiative. Thus, our final sample consists of 3,172 events, including 968 conversational exchanges in the event logs; no survey data was excluded.\nOur primary analysis of this data is qualitative, as our participants provided us with a rich source of interesting feedback and thought-provoking insights in their comments. Where applicable, we supplement this data with quantitative data from the survey and the event logs, as well as chat transcript data from the conversation logs. In this way, we triangulate[47]across our three data sources, using the open-ended survey data as a foundation. When we quote participants, either from their qualitative survey responses or the conversational transcripts, we reproduce their words exactly as typed, including typos, misspellings, grammatical errors, capitalization, and potential trigger words, and we only make minor clarifying edits where needed, delineated by square brackets.\nIn order to set the context for our analysis, we first describe how we used reflexive thematic analysis to analyze participants' responses to the open-ended survey questions. We then describe our analysis of the conversation logs and our development of a coding guide based on Conversation Analysis[76], and specifically, Moore and Arar's Natural Conversation Framework[50].\n5.1.1 Thematic Analysis of Qualitative Survey\nResponses. We conducted a reflexive thematic analysis to analyze the responses to our seven open-ended survey questions. We followed the process described by Braun and Clarke[16]in which researchers immerse themselves in the data, generate codes for material that seems interesting, and then iteratively group and refine codes through collaborative discussion in order to identify higher-level themes. Initially, four authors performed open-coding on the open-ended survey responses. Through discussion, these codes were grouped and consolidated into a single set, which were then re-applied to the data by two authors. After another round of discussion, these authors identified a set of 12 higher-level themes. Some themes had clear parallels to quantitative survey questions or event log data, and thus represented clear instances where we were able to triangulate across data sources. Other themes surprised us. We structure our presentation of the results based on these 12 themes, grouped into three different aspects of the user experience: expectations and experience, utility of conversational assistance, and patterns of interaction and mental models.\n5.1.2 Conversation Analysis via the Natural Conversation Framework.\nIn order to understand the content and structure of the conversations that took place between our participants and the Programmer's Assistant, we turned to the Natural Conversation Framework[50](NCF). We developed a codebook for the event logs, beginning with 21 different categories of utterances from the NCF. Nine NCF categories -Acknowledgment, Apology, Confirmation, Expression of Gratitude, Farewell, Greeting, Self-Identification, Welfare Check, and Welfare Report -appeared twice in our codebook to distinguish cases in which the utterance was made by the human participant vs. the assistant. Other NCF categories were split to provide nuanced detail about the interaction; for example, we distinguished three different kinds of NCF requests, depending upon whether they were stated as Requests for Action (e.g. codes to identify meta-information such as utterances that included code, utterances that referenced selected code, utterances that implicitly or explicitly referenced earlier portions of the conversation, or non-verbal UI activities such as copies, pastes, and invocations of \"try again\" and \"start over. \" Finally, we classified a subset of the human-applied codes based on whether they represented a participant's task or social orientation toward the assistant. We list our codes in Table1, but note that not all of them ended up being relevant to our analysis. When coding conversational data, we applied individual codes at the level of each conversational utterance. We allowed multiple codes to be applied to each utterance to account for utterances that performed multiple functions (e.g. greeting and self-identification). In order to ensure consistency in how our codebook was applied, two authors coded a 10% sample of the 968 conversational exchanges, achieving a satisfactory level of inter-rater reliability (Krippendorf's ð¼ = 0.77, where agreement was conservatively defined as having all of the same codes applied to both utterances in a conversational exchange).\n5.2 Expectations and Experience\nPilot testing of the Programmer's Assistant suggested that software engineers would be skeptical of a conversational programming assistant and its ability to provide useful assistance. Our study revealed that, for most participants, their actual experience after using the tool was better than they had anticipated. Participants were surprised at the quality of the assistant's responses and they appreciated how its integration with the code editor reduced the amount of context switching they needed to do in the UI. Some participants struggled with the code selection feature, although others appreciated the ability to ask questions related to selected code.\n5.2.1 Usage.\nAll of our participants engaged with the Programmer's Assistant while working on the challenges, despite there being no requirement to do so. Forty-one participants submitted solutions to all four challenges, and one participant, P14, only submitted solutions for one of the four challenges. Participants spent an average of 68 minutes engaged with the assistant, as measured by the amount of time the Programmer's Assistant window was in focus.\nParticipants made an average of 23.0 utterances (SD = 15.1 utterances) to the assistant. On average, 6.2 of their utterances (SD = 4.3 utterances) contained a code selection. The average latency per request14was 6.7 seconds (SD = 3.1 seconds).\nWe saw a 66.3% rate of acceptance of generated code, where we considered code to be accepted if the participant performed a copy immediately after the code was generated. This acceptance rate is much higher than the 27% acceptance rate reported for Copilot[109]. We believe one reason we observed a higher acceptance rate is because Copilot's completion suggestions are generated proactively, whereas the Programmer's Assistant's suggestions are generated upon request. When copying generated code from the assistant, participants most often copied the entirety of the generated code, and only in 5.8% of cases did they copy a smaller portion of it.\n5.2.2 User Experience Expectations & Changed Attitudes.\nPrior to running our study, we had reason to believe that participants would be skeptical of a conversational programming assistant. Before developing the Programmer's Assistant, we showed potential users mockups of a program editor with an integrated chatbot feature. These prototypes elicited uniformly negative reactions. People told us about their frustrating experiences with conventional chatbots and raised doubts about the knowledge, capabilities, and value of a conversational programming assistant. This skepticism motivated us to develop the Programmer's Assistant in order to evaluate whether the conversational experience, as powered by a state-ofthe-art code-fluent LLM, would be better than people had anticipated. During pilot testing, we received feedback that the Programmer's Assistant provided a much better conversational experience compared to testers' previous experiences with chatbots. Thus, in designing our study, we felt it important to first gauge participants' expectations of a conversational interaction around code, and then measure their experience after the fact.\nWe developed a short inventory of six scale items to measure user experience of code work15. The scale was administered twice: once before participants were exposed to the Programmer's Assistant (but after they had been briefed that they would interact with an AI chatbot), and once after completing the programming challenges. The items were presented with the appropriate tense: Do you expect (Did you find that) the Programmer's Assistant: (a) will be (was) easy to use; (b) will understand (understood) your requests; (c) will provide (provided) high quality responses; (d) will help (helped) you to write better code; (e) will help (helped) you to write code more quickly; (f) will be (was) enjoyable to use. Each item was rated on a 4-point scale of extent: Not at all (1), A little (2), Somewhat (3), A great deal(4).\nA factor analysis revealed the items on this scale measured a single construct, which we identify as user experience (Cronbach's ð¼ = 0.87). Thus, we computed two scores of user experience (UX) for each participant: a pre-task UX score computed as the average of their six pre-task expectation scale responses, and a post-task UX score computed as the average of their six post-task experience scale responses.\nWe found that participants had lower initial expectations for their experience with a conversational programming assistant (pretask UX M (SD) = 3.0 (0.62) of 4) than their experience actually was (post-task UX M (SD) = 3.6 (0.32) of 4). A paired sample t-test shows that this difference was significant, ð¡ (41) = 5.94, ð < .001, Cohen's ð = 0.92 (large). Measured another way, 32 participants (76.2%) had post-task UX ratings that were higher than their pretask expectations, demonstrating a significant shift in attitudes toward conversational programming assistance.\nHowever, the UX ratings alone fail to capture participants' nuanced expectations of the assistant and the reasons for their shifted attitudes after using it. Participants expressed a variety of expectations of the assistant before using it, including that it would be easy to use (P30) and produce correct responses (P30), understand the problem and what is being asked of it (P8, P9, P11), not interfere with their flow state (P5), produce imperfect or questionable outputs (P6, P21), improve with feedback (P31), provide generic and unhelpful answers (P17) or only answer basic questions (P40), and produce responses quickly (P40).\nP17 expected \"to be frustrated very quickly and that what I'd think would be relatively common questions would be responded to with generic, unhelpful answers.\" P6 explained, \"I didn't have very good experiences with chatbots. I think I'll need to spend more time in reviewing and fixing the suggestions than in writing the code myself from scratch. \" P11 had a more balanced view, that \"It'll do some tasks really well, but others will not be as reliable. \"\nAfter interacting with the Programmer's Assistant, many participants commented on how the experience was better than they anticipated, because it \"seemed to be able to handle complex issues\" (P10) and \"was a great help\" (P8). P20 felt it was \"incredible!\" P6 and P17, who were both initially skeptical, reported having a positive experience. For P6, \"It absolutely exceeded all my expectations, in all aspects that I could have imagined and more!\" P17 provided a more quantitative assessment: \"Initial expectations: 3 Actual: 9.5.\" P38 was emphatic in their evaluation: \"I was blown away how well it allowing me to structure how I want the code to look and work and just giving me the thing I asked for. \"\nMany participants described a sense of surprise in their experiences. P9 was surprised by how well it understood their requests:\n\" Participants also reported experiencing this variability in the quality of the assistant's responses. Some participants described how the assistant provided \"detailed answers\" (P17) and \"high quality outputs\" (P18) that were \"surprisingly good\" (P2). P6 felt it was \"incredible to see the quality of the responses, \" and P3 even explored the assistant's capabilities outside the scope of the challenges and found that it could handle those as well:\n\"It was surprising the quality of the code and the ability to answer all my questions correctly. Although I think the challenges may be biased towards what the Assistant is able to do, it was a great experience because I asked many other things and it was able to answer correctly. \" (P3)\nOf course, the Programmer's Assistant wasn't perfect, and some participants did run into issues. For P35, \"The documentation generation did not perform very well. \" P16 questioned the accuracy of the knowledge encoded in the model: \"Does the model need to be updated? It said latest python version is 3.7 but google says it's 3.10. \" In some instances, participants needed to ask their question multiple times to get a good response: \"you need to ask many times if you want to get an answer and also a detailed explanation\" (P3). P27 felt, \"it was annoying when I asked it to try again and it would give me the same response. \" P22 struggled because, \"It didn't seem to handle multiple sentences well. \"\nP28 perhaps offered the most scathing criticism, that, \"It makes mistakes often enough to be not very practical.\" However, despite the production of poorer-quality responses, other participants felt that the assistant was still helpful. P36 reported that, \"Only minor tweaks were normally needed to correct any issues.\" Similarly, P38 described how the assistant wasn't able to completely solve their problem, but provided a useful start:\n\"There was only one hickup I noticed where when I asked it to memoize fibonacci it couldn't, but it dropped the building blocks on my lap for me to finish so that was fine, that was like minutes of effort on my part.\" (P38) 5.2.4 UI Design & Affordances. Participants made many comments on our specific UI design and the affordances provided (or not provided) in our chat-augmented editor. Overall, the integration between the chat pane and the code editor was \"very good\" (P23), with a \"nice interface between the code pane and the assistant pane\" (P17) that \"makes it really convenient\" (P35).\nPrior research by Brandt et al.[15]has shown how keeping developers focused in their IDE improves productivity, and our participants expressed similar sentiments. P40 remarked, \"It allows me to stay in one browser window/tab!\" and P12 hinted at how the interface might preserve their flow state by \"prevent[ing] me from getting distracted when looking into an issue in another tab. \" Some aspects of our user interface were confusing to participants, such as the mechanism for selecting code to be included in the conversational context. P7 remarked, \"It's was a little confusing doing the selection part for it to tell me what a function does, but... it gave me code that was insanely easy to copy and paste.\" Other participants appreciated the code selection mechanism, such as P11: \"I enjoyed the code selection feature, and found that very easy to use. \"\nIn the event logs, we identified 20 instances in which a participant unintentionally included selected code in the conversation when it wasn't needed (Includes Extraneous Selection), 12 instances in which a code selection was omitted when it was needed to provide context for the question (Missing Selection), and 16 instances in which a participant copy/pasted code directly into the chat rather than selecting it in the editor (Pasted Code in Chat). Although these cases represent a small fraction of the 227 instances in which a code selection was required and included in the conversation (Includes Selection), their presence does indicate that more attention is needed to the interaction design of code selection.\nAnother issue regarded the awareness of the \"try again\" and \"start over\" features. The \"try again\" feature was only used by 14 participants, who used it a total of 63 times over the course of the study. Some participants used it specifically when they got an answer which they saw as clearly wrong, while others used it to get a variety of possible answers before proceeding. The \"start over\" feature was used even less, by 5 participants who used it a total of 6 times. Despite our effort to surface these conversational features in the UI via shortcut buttons, they may not have been sufficiently noticeable or salient: \"The 'try again' button is not so reachable, often times I forgot it exists\" (P23). By contrast, at least one participant was successful with these features:\n\"at some point it had issue with challenge 3 and I had to start over. Just asking 'try again' was not enough and I was getting always the same (wrong and not related) answer. starting again solved the issue!\" (P20)\n5.3 Utility of Conversational Assistance\nOur next set of themes concerns the utility provided by conversational programming assistance. Participants felt the assistant was highly valuable and desired to use it in their own work. They felt it would be most helpful for smaller or narrowly-scoped tasks, but able to provide a wide variety of types of assistance. The fact that the interaction model was conversational and grounded in code were valuable aspects, as was the ability for the assistant to bolster users' learning about programming topics through that interaction. Participants did question whether they could trust and rely upon the assistant's responses, echoing a similar theme discussed in Weisz et al.[102].\n5.3.1 Value & Appropriate\nTasks. Participants rated the value of the Programmer's Assistant highly (M (SD) = 8.6 (1.4) of 10). Many participants asked questions such as, \"Can I have it in my editor please?\" (P15), or made comments that, \"I would enjoy using it in the future\" (P36), \"I would love to be able to... have access to it for my coding\" (P37), and \"I'd love to use this tool as part of my usual programming workflow if I could!\" (P39). Some of the reasons why participants found it valuable are because it \"help[s] me remember how to do things in certain languages that normally I would just Google\" (P9) and \"It helps me to avoid silly syntax errors and can when I cannot remember exact function/method names and required arguments\" (P40). We did not observe any differences in value ratings based on participants' familiarity with or recency of using Python.\nParticipants described a wide variety of tasks for which they felt the assistant would be useful. These tasks included \"ordinary\" (P23), \"simpler\" (P2), and \"small, repetitive\" (P4) tasks such as \"quick lookups\" (P25) for \"short chunks of code\" (P11) or for \"narrowed questions\" (P26). Participants also felt the assistant was useful for \"small containable novel algorithms\" (P38) and \"little coding problems\" (P4).\nSeveral kinds of task assistance were reported as being valuable, such as explaining code (P31), implementing business logic in a UI (P38), understanding what code does (P19, P37), and recalling language syntax, method names, and arguments (P12, P15, P20, P40, P42). P27 felt that the assistant was \"More helpful when recognizing a specific well known algorithm but not things you make yourself. \"\nParticipants also made recommendations for how to increase the value of the Programmer's Assistant. P38 suggested, \"What would blow me away though is if it's able to help with what I do most often which is to integrate, refactor and iterate on an existing system. \" P16, P26, and P38 all desired more information on the data sources used to produce the assistant's responses. P9 requested to \"Have the Programmer's Assistant examine your code and make proactive suggestions for improving it in the chat.\" P36 requested the same, but cautioned that, \"Care would need to be taken to avoid becoming an annoyance or disrupting the flow of a coding session. \"\nIn the post-task survey, we probed participants on how certain changes to the Programmer's Assistant would either decrease, increase, or result in no change to its value. Over 75% of participants felt that the assistant would be more valuable if it operated in a proactive manner, either by making improvement suggestions in the chat or as comments directly in the code. Similarly, 78.6% of participants felt that having more buttons in the UI for common features such as explaining or documenting code would make the tool more valuable.\n5.3.2 Conversational\nInteractions Grounded in Code. One of the challenges in interpreting participants' comments about the utility of the Programmer's Assistant was in disentangling the extent to which value was derived from the quality of the underlying model versus the integration of conversation in a code context. Indeed, participants felt that the chat interaction was valuable: 69.0% of participants felt that eliminating the conversational interaction and making the assistant behave more like web search would decrease its value. Further, our analysis of the conversation transcripts revealed that 42% of the 910 task-oriented utterances from participants required historical conversational context (Chat Context Required) in order to be correctly interpreted. Thus, we observe that behaviorally, participants did rely on conversational context in their interactions.\nIn the post-task survey, 83% of participants rated the importance of the ability to ask follow-up questions as being \"somewhat\" or \"a great deal. \" Several participants specifically commented on the value of this conversational context. P39 remarked, \"I absolutely loved how you can straight up ask follow-up questions to the Programmers' Assistant without having to reiterate the original topic/question. \" P15 expressed a similar sentiment, saying, \"I think the conversational context was someone helpful, just in communicating that it's a running conversation where my context is remembered. \" P9 provided a similar analysis:\n\"This tool was so helpful at answering questions I had about the code in the context of the code I am working on... I was also impressed with how well it was able to remember the context of our conversation, especially when I asked vague follow-up questions. \" (P9)\nIn addition, some participants identified how a conversational interaction grounded in code was useful, \"because I think to 'understand' the dev context could be VERY important\" (P31). In fact, 24.9% of task-oriented utterances included a relevant code selection (Includes Selection), showing that participants valued this ability.\nContrasting with these participants, P18 felt that interacting with the assistant conversationally was tedious, and they employed a more direct approach: \"I really like the PA. But, I didn't converse with it like a chat bot. I often told it what to do ('Document this code.') as opposed to asking it what to do ('How do I document this code?'). Talking to it the way that was suggested in the tutorial seemed overly verbose/tedious. \" (P18) Despite these individual differences in interaction preferences, P39 envisioned that both interaction styles could be supported in the tool:\n\"I think both options should exist: people should be able to input their queries like a search bar AND also give their question as if in conversation. \" (P39) 5.3.3 Learning Effects. One specific benefit of the Programmer's Assistant identified by participants is its ability to help people improve their programming skills and reinforce knowledge gaps. For example, it can help users \"remember how to do things in certain languages... such as, when I am using a language I haven't used in a while\" (P9). The assistant can also serve as an memory aid, such as when \"I use a lot of libraries that I don't always remember all of the functions\" (P15). Similarly, P31 said, \"No matter how good you're as a developer, you can't (humanly) remember all the API of hundreds of libs or new languages... I'd learn new dev lang and new lib/frameworks faster. \"\nP39 felt the assistant \"is perfect for programmers of all levels, \" and P1 felt it could help them rapidly improve their Python skills: \"I have wanted to learn python... The main concern how much time spent learning is needed before I could actually get some value out of learning python. I have a feeling this would cut that time down from weeks to a day or so. \" (P1) P39 also identified the fact that, because the interactions with the assistant are conversational, it forces people to learn how to communicate to others about their code: \"The conversation aspect promotes proper communication, which would really stand to benefit budding programmers if they want to learn how to explain concepts more fluently in the future to their colleagues.\" (P39) Conversely, P36 suggested that over-reliance on programming assistance might have a detrimental effect to one's learning: \"It's definitely a huge time saver, but over-reliance on it may cause new developers to skip learning the reference material themselves and discovering new things and sparking new ideas. \" (P36) 5.3.4 Trust. Many participants raised questions about whether they could trust the responses provided by the Programmer's Assistant. P21 asked this question most directly: \"will the code be correct, safe, efficient?\" Other participants raised similar questions, such as, \"I'm wondering how it validates it's answers, if it can be trusted to always give a working answer\" (P10), and \"Sometimes lack of source and context may raise doubts in the mind of the programmer\" (P16).\nThese issues of trust were exacerbated by the fact that the Programmer's Assistant did not allow participants to actually run their code. Because of this limitation, participants had to rely on their own knowledge to judge the correctness of the assistant's responses. P19 asserted, \"There is no way to evaluate if the Programmer's assistant is giving you the right advise or not other than your own knowledge, \" and P9 concurred: \"I had to trust that it was correct (and use my own prior knowledge). \"\nP18 described the potential consequences of allowing the assistant to write code for them:\n\"The only thing that made me nervous was that it could have introduced a bug that wasn't immediately apparent. And given I didn't write the code, I could have easily glossed over a mistake when reviewing it. Especially if it is also the one writing the test cases. \" (P18)\nDespite our efforts to make the Programmer's Assistant respond in non-authoritative ways, we did observe participants sometimes uncritically accept generated results that were clearly wrong or incomplete. Thus, we did find behavioral evidence for over-reliance.\nListing 2: Building trust through explanations and justifications One way to address trust issues is for the assistant to provide further explanations and justifications that can calibrate a user's confidence in the assistant's responses. Such explanations could be requested conversationally, though most participants did not attempt to do so. One participant (P9) did ask for such explanations, and we show a summary of their transcript in Listing 2. In this instance, P9 asked for a definition of a unit test (line 1), an explanation of the code being tested (line 25), and justifications of the quality of the unit test (lines 31& 37). Thus, we observe that the assistant is capable of producing explanations and justifications when asked.\n5.4 Patterns of Interaction and Mental Models\nParticipants interacted with the assistant in a variety of ways with two main patterns of usage standing out: (1) invoking the assistant to solve the entire programming challenge, and (2) breaking the challenge down into a set of smaller tasks and invoking the assistant's help for each. There were no clear differences in how participants with differing Python experience approached the tasks.\nParticipants' mental models of the assistant also varied. Although participants strongly saw the role of the assistant as being a tool, their behaviors revealed that in many cases, they actually treated it as a social agent. In addition, participants ascribed various mental capacities to the assistant, such as having the ability to understand, compute, and learn.\nParticipants felt the assistant changed the nature of their work process. For some participants, it enabled them to focus on the higher-level aspects of development because the assistant handled lower-level details or provided partial solutions for them to build upon. Many participants felt the assistant sped up their work and helped them remain focused on their tasks.\nFinally, participants drew comparisons between the Programmer's Assistant with other forms of programming support such as Copilot and web search. They felt that the conversational style of interaction enabled them to discover new, emergent behaviors from the model that were unavailable from Copilot's focus on code autocompletion. They also felt that the examples provided by the assistant were more readily usable within their own code compared to browsing for answers within search results, speeding up the coding process. However, some participants advocated for a balanced approach to the design of programming assistance tools by incorporating multiple modes of interaction rather than fixating on a single one.\n5.4.1 Interaction\nStyles and Assistant Role. We observed that participants interacted with the Programmer's Assistant in strikingly different ways. Some participants would present the entire challenge description to the assistant and then work with the results it produced. Other participants approached the programming challenges in a piecemeal fashion, breaking them apart into a set of smaller tasks, then invoking the assistant to aid with each one.\nExperience with Python was not a determinant of how participants approached the programming challenges, but it did seem to impact how participants interacted with the assistant. Less experienced participants tended to ask the assistant basic questions such as, \"What is a unit test\" (P29, not familiar with Python) and \"how do I document a function?\" (P27, < 1 year of experience). More experienced participants made detailed requests about specific Python libraries or algorithms, such as, \"given a pandas dataframe with two columns 'Date' and 'Sales' please use matplotlib to draw me a scatterplot\" (P38, 3+ years of experience) and \"implement a rungekutta algorithm for solving an ODE with adaptive time steps\" (P37, 3+ years of experience).\nAnother difference we observed in how people interacted with the assistant stemmed from their view on the role it played in their collaborative process. Some participants, such as P18, treated it more as a tool by issuing commands rather than asking questions. As quoted earlier, they said, \"I didn't converse with it like a chat bot. \" P5 described their interaction style similarly: \"I found myself wanting to type search queries into Socrates, not treating it as a person but as a search tool. \"\nIn anticipation that participants would have different orientations to the assistant and its role, we asked a question on the posttask survey about the different kinds of roles the assistant might take. These roles generally fell into one of two categories: a tool orientation (a tool, a reference guide, a content generator, a problem solver), and a social orientation (a collaborator, a colleague, a coach, an advisor, a reviewer). Participants rated the extent to which they viewed the Programmer's Assistant in each of these roles on a 4point scale of extent: Not at all (1), A little (2), Somewhat (3), or A great deal (4).  We show participants' ratings of the assistant's role in Figure3. Despite the fact that their attitudes toward the assistant overwhelmingly reflected a tool orientation, their behaviors reveal that many participants actually treated the assistant as a social agent. P6 described how \"I felt it like a partner,\" and P4 told the assistant, \"I could not have solved [the challenge] without your help,\" to which the assistant responded, \"I'm glad I could help. \"\nThe literature on Computers as Social Agents (CASA) helps us interpret this result as it demonstrates how computers are often treated like people[56,67]. LLM-based conversational agents can exacerbate this tendency; as they likely have been trained on examples of social interaction, they can also respond as social agents.\nIn the conversation logs, we identified participants who interacted with the assistant in a socially-oriented fashion (the social orientation codes in Table1). Twenty participants (47.6%) made at least one socially-oriented utterance. An extreme form of this interaction style can be seen in a snippet from P6's transcript (Listing 3).\nThe 20 participants with a behaviorally-demonstrated social orientation did not generally differ in their role ratings from other participants, except that they rated the assistant as more likely to be an advisor (Fisher's exact test, two-tailed ð = .02) or a reviewer (Fisher's exact test, two-tailed ð = .03). However, they did not differ in their overwhelmingly-strong ratings of the tool orientations. Thus, at least for some participants, there seems to be a dissonance in their view of the assistant's role orientation.\nListing 3: Excerpt from P6's interaction with the Programmer's Assistant, in which P6 offers their thanks and congratulations. Socrates : Goodbye .\n5.4.2 Mental\nCapacities. Participants made a number of inferences about the Programmer's Assistant and its capacities for thought.\nMany participants talked about how the assistant possessed a level of \"understanding\" (P6, P8, P11, P18, P32) of \"the context\" (P9, P21) as well as \"major concepts\" (P9) and \"knowledge\" (P33). P24 was amazed by the assistant's ability to \"take a plain english request and interpret it properly.\" P7 ascribed intelligence to the assistant, saying, \"It was a lot smarter and trained tha[n] I thought it was. \" One participant assumed that the assistant \"Keeps improving through (user) feedback\" (P31). Another felt that the assistant was capable of computation: \"It understands the problem... It can calculate the results of a function back\" (P8).\nHowever, not all participants were convinced of the assistant's ability to understand. P37 questioned the assistant's limitations: \"I wonder how far beyond boilerplate it can go and if it works for truly original problems. \"\n5.4.3 Impact of Conversational\nAssistance on Work Practices. Many participants discussed how the Programmer's Assistant shaped their work practices on the programming challenges. Overall, participants felt that the assistant \"saves time\" (P10), \"helps me code faster\" (P34), and would \"speed up my productivity\" (P19) because \"I could focus on validating and improving the code it generated instead of having to write it all from scratch\" (P18). P37 remarked that, \"It opens a whole new door for fast develpment. \" P4 discussed how the assistant \"was helpful in staying focused on the code, \" although for P14, \"it took [me] time to get into tempo with the tool. \"\nP31 pointed out how the assistant would change the nature of their work: \"My job could focus more on higher level aspects and therefore achieving better (quality) results, besides the time-to-value... Data science (and dev) becomes a more creative-higher level experience. \" (P31) Other participants discussed a work process in which the assistant provided incomplete solutions -the \"building blocks\" (P38) or \"initial draft of code\" (P11) -upon which they could build. P5 aptly described this process: \"It's nice to copy well formulated challenges in natural language and have the code generator take its best stab at it, then edit to our hearts content. \" (P5)\nParticipants felt that human review of the assistant's responses was necessary because \"The answers provided are generally not novel solutions, often look clunky and non-elegant. There may be some unnecessary code. Basically the code would need to be reviewed\" (P16). P35 also pointed out how \"The code generator was good but you still have to really check it. \" P19 discussed how they would turn to the assistant as a first source for support, and only if it wasn't able to help would they then turn to other support tools:\n\"The way I will use it is, I will first us[e] the Programmer's assistant for most of my cases. Only in certain cases where Programmer's assistant cant answer things I will turn up to official documentation or stack overflow. \"\nHowever, latency was a factor for interactive use of the assistant and participants noticed when the assistant took a long time to respond. P19 remarked, \"Sometimes it took lot of time, like more than 5 seconds. \" P40 also felt \"the response [was] a little slow sometimes... in chat mode I expect faster responses. \" As discussed in Section 5.2.1, the assistant took an average of 6.7 seconds (SD = 3.1 seconds) to respond to a request, and participants did appreciate when the assistant produced rapid responses: \"I loved how quick it was able to pull up answers to questions I had\" (P38).\n5.4.4 Conversational Interaction vs. Other Interaction Models.\nAlthough our study was not intended to make comparative evaluations with the Copilot tool, we nonetheless asked participants whether they were familiar with Copilot, and if so, to comment on how the two tools compared. We also asked a similar question to compare the assistant with another popular form of programming assistance, searching the web (via a search engine like Google, or a Q&A site like Stack Overflow). In discussing the differences between these three tools, we note that the primary differentiator is their interaction model.\nThe interaction model for the Programmer's Assistant is clearly conversational: users ask questions in natural language and are provided with a response in natural language and/or code. The interaction model of Copilot is reminiscent of direct manipulation interfaces[37], in which the user's actions in the user interface directly manipulate an object on the screen. Copilot automatically makes autocompletion suggestions as the user types. This autocompleted code is directly placed in the source editor; thus, the user's work is contained entirely within the scope of the object on which they are working (i.e. the source code), which is how direct manipulation interfaces operate. In web search, users enter a separate search context (e.g. a search engine accessed within a web browser), type in a natural language query, and then forage amongst search results to identify relevant items of interest[12,62].\nWhen a desirable item is found, users must translate it into their code environment (e.g. via copy/paste) and possibly edit it to fit their existing code.\nWe also note that the Programmer's Assistant and Copilot both utilize the same underlying AI model, Codex[24], which means that the only difference between these tools is the user experience. The extent to which Codex was trained on data from programmingrelated Q&A web sites is less clear, but for the purposes of our analysis, we focus our discussion solely on the differences in their interaction models16.\nParticipants reported various benefits and drawbacks of a conversational interaction over a direct manipulation interaction. Foremost, conversation \"felt very natural\" (P21) and \"feels much more natural using Natural Language with the AI\" (P39). In addition, P39 felt that \"the use cases of Programmers' Assistant seem more openended. \" Many participants were surprised at the variety of tasks the assistant was capable of performing, from writing unit tests (P19, P36, P37) and documentation (P12, P19, P36, P37) to explaining what code did (P31, P38) and even answering general-knowledge questions (P31). Again, we note that the Programmer's Assistant utilizes the same underlying model as Copilot, yet the conversational interface was able to expose a wider variety of emergent behaviors from the model. Multiple participants explored the limits of the assistant's knowledge and abilities beyond our programming challenges. For example, P37 asked it questions about physics and ordinary differential equations (\"ODe\" as written by P37), and was surprised by the \"versatility of what it could answer. \" \"I asked it some physics and ODe question and the answers, though not complete, included the key parts needed to write that code. \" (P37) P31 probed the assistant on its knowledge of geography and was surprised when the assistant produced a correct answer.\n\"I asked something out of SW engineering domain (geography) and it replied correctly, also by correctly answering on my nationality. \" (P31) For some participants, the ability to assess the assistant's response before committing to it (i.e. by inserting assistant-generated code into their editor) was a boon. P15 described how the copy/paste boundary provided them with \"a bit more control to ask specific questions about what I wanted and to assess before putting it in my code.\" Other participants felt that the copy/paste boundary was more inefficient: \"I think the main difference is the ability of Copilot to suggest code while you type, what make it faster and easier to use. While using the Programmer's Assistant, you need to go to the chat, ask the question, copy the code (or rephrase the question if it was not understood by the agent), and edit it to match your code. \" (P3) A large number of participants felt that the conversational interaction was faster than web search (P1, P6, P7, P10, P11, P12, P16, P17, P18, P20, P24, P29, P30, P33, P36, P37, P42) because of its ability to provide \"real-time responses\" (P32) that can be \"applied exactly to your code\" (P33) without having to \"parse through lots of text... to get what you need\" (P15). In addition, the assistant provided \"MUCH faster, better responses\" (P17) that were \"much more relevant to the problems\" (P34) and \"simple[and]succinct\" (P9), without having to \"sort through answers on your own or read documentation\" (P9) or \"look at many posts before finding the relevant one\" (P18).\nDespite these benefits, some participants felt that the assistant might not work well for \"more specific and difficult problems on a bigger scale\" as compared to web search. P9 felt that \"the data [of the Programmer's Assistant] wasn't as rich\" as the web. Other participants felt that the assistant lacked the \"multiple answers\" (P9) and \"rich social commentary\" (P19) that accompanies answers on Q&A sites: \"I like to see the different versions proposed on stack overflow and the commentary of what makes one solution better than another in a given situation. \" (P27) Some participants promoted a more balanced view that there isn't a single mode of interaction superior to all others. P19 felt that web search would be a fallback when the assistant failed to answer a question. P39 described how search could be integrated with the conversational interaction:\n\"I think both options should exist: people should be able to input their queries like a search bar AND also give their question as if in conversation. \" (P39)\n6 DISCUSSION\n6.1 Value of Conversational Interaction\nWe began our research by asking the question of whether contemporary developments in code-fluent LLMs could sufficiently support a conversational programming assistant. We believe that our work has demonstrated that they can. Clearly, the Programmer's Assistant was viewed by our participants as a useful tool that provided real value -so much so that many participants explicitly requested or expressed the desire to use it in their own work. However, how much of this value was derived from the model itself and its ability to produce high-quality responses to programming questions, versus from participants' ability to conduct extended conversational interactions grounded in their actual source code?\nWe believe that both of these constituent aspects were valuable. Indeed, many participants commented on their surprise and satisfaction with the quality of the assistant's responses (Section 5.2.3). However, participants also valued the conversational interactions that they had with the assistant. In the event logs, we saw evidence that participants were leveraging conversational context to ask follow-up questions as well as leveraging code context by asking about their code selections (Section 5.3.2). Many participants reported that they would find the tool less valuable if the conversational interaction were removed (Section 5.3.2). Further, conversation seemed to provide unique value beyond other interaction models (direct manipulation and search) because of its embeddedness in the UI and its ability to surface emergent behaviors of the model (Section 5.4.4).\nWe do not believe that these different interaction models are in competition and we agree with P39's assessment that assistive tools can be built using a plethora of different interaction models. For use cases in which a model is known to produce high-quality results (e.g. code autocompletion for Codex), a direct manipulation interface seems wholly appropriate as it would provide a discoverable and predictable way of invoking the model to produce a known type of result. However, direct manipulation interfaces may be less ideal for surfacing the emergent behaviors of a foundation model[14], and thus natural language interaction may be more suitable. Many popular text-to-image models, such as DALL-E 2[66]and Stable Diffusion[72], operate in a one-shot fashion, in which the user specifies a prompt, clicks a button, and gets results. Our study demonstrates how the additional contextual layers of conversational history and the artifact-under-development provide additional value to the co-creative process.\n6.2 Toward Human-AI Synergy\nThe aim of human-centered AI is to \"enable[] people to see, think, create, and act in extraordinary ways, by combining potent user experiences with embedded AI methods to support services that users want\"[82]. Building upon this definition, Rezwana and Maher[69]posit that, \"In a creative collaboration, interaction dynamics, such as turn-taking, contribution type, and communication, are the driving forces of the co-creative process. Therefore the interaction model is a critical and essential component for effective co-creative systems.\"[69]. They go on to note that, \"There is relatively little research about interaction design in the co-creativity field, which is reflected in a lack of focus on interaction design in many existing co-creative systems. \"\nOur study begins to address this gap. While many co-creative systems examine casual tasks or experimental activities (e.g., Spoto and Oleynik[87]), our focus was on the co-creative practice of programming. Our goal was to understand peoples' attitudes toward a conversational programming assistant, akin to Wang et al.'s examination of data scientists' attitudes toward automated data science technologies[99]. We found that, despite an initial level of skepticism, participants felt that a conversational assistant would provide value by improving their productivity (Section 5.4.3). However, further work is needed to assess the extent to which this type of assistance provides measurable productivity increases.\nCampero et al.[19]conducted a survey of papers published in 2021 that examined human-AI synergy, the notion that a human-AI team can accomplish more by working together than either party could accomplish working alone. They found mixed results, with no clear consensus emerging on how to design human-centered AI systems that can guarantee positive synergy. Summarizing from their discussion, \"Perhaps achieving substantial synergies among people and computers is harder than many people think. Perhaps it requires... new ways of configuring groups that include people and computers. And perhaps it needs more systematic, focused attention from researchers than it has, so far, received. \"[19, p.9]We believe such evaluations of human-AI synergy should go beyond one-shot performance measures. As implied by many of the uses cases listed by Seeber et al.[80], human-centered AI systems are often deployed in socio-organizational contexts that require longitudinal use[20,41,43], such as product design[93], game design[4], and engineering[20,Section 3.2.2]. Thus, we would expect that over time and through interaction with each other, human-AI teams would improve their performance through a mutual learning process.\nEvidence for this process surfaced in our study when participants described how they could improve their programming skills by interacting with the assistant (Section 5.3.3). We assert that the learning should operate in both directions: not only should people improve their programming skills, but the model itself can also improve based on peoples' interactions with it. For example, when the assistant provides a code example to the user, and the user takes that example and edits it, those edits constitute feedback that can be used to further fine-tune the model. In addition, through longitudinal use, we believe that human and AI partners can create reciprocal representations of one another -i.e., the human is likely to create a mental model of the AI, and the AI may be engineered to develop a user model for each of its human users[30,48,79]. Such a pair of models is often described as Mutual Theory of Mind[29,100]. This type of capability raises the possibility of personalizing and adapting an assistant to the strengths and needs of individual users.\nWith such models, an assistant that knows a user is learning a programming language could provide natural language explanations alongside code outputs, whereas an assistant that knows a user is strongly skilled in a programming language might shorten or omit those explanations. Similarly, users are likely to update their mental models of the AI with more experience. We believe the space for exploring how these reciprocal models impact human-AI synergy is rich, and we encourage additional work in this area.\nHuman-centered AI systems that are designed to combine and synergize the distinct skills of humans and AI models cannot succeed if they diminish the human skills upon which they depend. Well-designed human-centered AI systems develop new and complementary skills for both the human and AI constituents[82,83], and we believe that mutual learning may address concerns that the wide deployment and use of AI systems will result in a de-skilling of the workforce[77,108].\nUltimately, the design decisions that go into an interactive AI system have ethical implications. Our design attempts to augment the user's knowledge and skills by presenting help on demand, couched in non-authoritative suggestions, which leaves the user firmly in control and ultimately responsible for the work product.\n6.3 Opportunities for Future Research\nOur work highlights many interesting avenues for future enhancements that could be made to LLM-based conversational assistants such as our Programmer's Assistant, as well as future humancentered research on LLM-based conversational assistance.\nOur work employed a code-fluent model that was not specifically designed to handle conversational interaction. Fine-tuning the underlying LLM for conversational interaction, such as what has been done with Lamda[91], is one opportunity to improve the assistant's performance. Another opportunity is to align the language model to follow the desiderata proposed by Askell et al.[11]and described by Ouyang et al. as, \"helpful (they should help the user solve their task), honest (they shouldn't fabricate information or mislead the user), and harmless (they should not cause physical, psychological, or social harm to people or the environment)\" [61, p.2]. Glaese et al.[33]propose a slightly different desiderata of \"correct\" instead of \"honest, \" which may be more applicable to the software engineering domain, as the ability to produce correct code and correct answers about code are both important properties of a conversational programming assistant.\nCombining LLMs with search-based approaches to establish additional context for the model, such as AlphaCode[44]has done, may also result in more capable systems. These \"searches\" need not be limited to textual sources, but could be conducted over appropriate semantic stores (e.g. a knowledge graph) and take advantage of explicit semantic reasoning services, resulting in an integration of symbolic and neural approaches. Further, allowing for \"internal deliberation\" of the type shown in Nye et al.[59]could result in better-reasoned results, as well as better explanations and justifications.\nAnother avenue for improvement involves the prompt used to configure the assistant (Appendix D). Just as the prompt for each successive interaction is modified by the growth of the conversational transcript, there is no requirement that the initial prompt be static. It too can be specialized to incorporate aspects of a user model, enabling the realization of a Mutual Theory of Mind[29,100]. Providing better UX affordances for visualizing and manipulating the active contexts -code and conversation -could provide users with more control over which information contributes to the generation of the assistant's response.\nOur participants clearly indicated that they were interested in having an assistant that behaved more proactively, in contrast to our deliberate design of an assistant that never takes conversational initiative. A more proactive assistant would be able to interrupt or remind a user when necessary[23], yet this characteristic raises many challenging issues. How can we calibrate the threshold for such interruptions? How can users tune the assistant to deliver only those interruptions that the they would find useful (e.g.,[28,81])? How can we help users to regain their prior context after dealing with an interruption (e.g.[89])? Should an assistant be used to persuade or nudge the user (e.g.[35])? Who should determine the topic, frequency, and insistence of such persuasion attempts (e.g.[52,85])? Should users have the ability to moderate or defeat attempted persuasions, or should those decisions be left to the organization?\nFinally, we explored the different kinds of role orientations our participants had toward the assistant and found that participants varied in their views of it as a tool versus a social agent (e.g. collaborator or colleague). We posit that peoples' effectiveness in working with an AI system may be influenced by their role orientation, and we encourage future research in this area.\n7 CONCLUSION\nWe developed a prototype system, the Programmer's Assistant, in order to assess the utility of a conversational assistant in a software engineering context. The assistant was implemented using a stateof-the-art code-fluent large language model, Codex[24], and was capable of generating both code and natural language responses to user inquiries. We further used the prompting mechanism of the model to set up a conversational interaction in which the model uses the conversational history, plus the user's current utterance, in order to generate a response. In this way, users are able to ask follow-up questions in the chat that reference prior utterances and responses. We incorporated the conversational assistant into a code editing environment, enabling the conversation to be grounded in the context of the user's source code.\nWe evaluated this system with 42 participants with varied levels of programming skill, and their quantitative and qualitative feedback, coupled with their usage of the system, demonstrated the varied, and sometimes emergent, types of assistance it was able to provide. Many participants noted the high quality of the conversational responses, including the assistant's ability to produce code, explain code, answer general programming questions, and even answer general knowledge questions. Participants felt this type of assistance would aid their productivity, and they drew meaningful contrasts between the conversational style of interaction with other tools that employ a direct manipulation or search-based interaction model.\nOur study motivates the use of conversational styles of interaction with large language models by showing how they enable emergent behaviors in a co-creative context. The Programmer's Assistant did not always generate perfect code or correct answers; nonetheless, participants in our study had an overall positive experience working with it on a variety of programming challenges. We believe that our work takes us one step closer to realizing the vision of human-centered AI: learning how to design systems that maximize the synergy in human-AI collaborations. â¢ Add buttons in the chat UI for common queries, such as \"what does this code do?\" or \"document this code. \"\nâ¢ Have the Programmer's Assistant examine your code and make proactive suggestions for improving it in the chat.\nâ¢ Have the Programmer's Assistant examine your code and make proactive suggestions for improvements in comments inserted directly into the code. 11. Do you have any other suggestions for how we could improve the experience of working with the Programmer's Assistant?\nOpen-ended response\nB THE PROGRAMMER'S ASSISTANT TUTORIAL\nThe tutorial provided to study participants, like all the challenges, was presented as pre-loaded text in the code editor. Participants were encouraged to modify the text to record their results and submit it at the completion of the tutorial.\nListing 4: The Programmer's Assistant study tutorial Did it do it correctly ? : 44 45 5) Select the code below and ask the system to 7) See if the assistant remembers your name For example \" What ' s my name ?\" Did it ? : 8) Click the \" try again \" button at the top of the chat . You should get a different answer .\nTry it a few times . Did it ever get your name right ?: If the assistant gives you an answer that is obviously wrong or it claims to not know an answer that you think it should know , or you just want to see an alternate answer , it is worth it to give \" try again \" a shot . 9) Click the \" start over \" button at the top of the chat , and then enter another command to see if it remembers your name . For example \" What ' s my name ?\" Did it ? : It should really have forgotten your name now , and no amount of \" trying again \" will get it right . You can \" start over \" if the assistant ever seems confused by , or stuck on , earlier parts of the conversation . 10) You can chat with the assistant on any topic you like to explore its functionality and capabilities further . See if you can stump it with a tough question ! Thanks ! When you are done , submit your results by clicking on the blue submit button and move on to the challenges !!! \"\"\"\nC CHALLENGES\nEach of the study challenges was presented as text in the code editor. Participants completed their work in the code editor and then submitted it when finished. The prototype did not provide any ability to run or debug code and participants were encouraged to make their best attempt at solving each challenge. The plot size should be 10 inches wide and 6 inches high . The csv file is not provided , but you can assume it will have 'Date ' and ' Sales ' columns . The Date column is the x -axis . The date string shown on the plot should be in the YYYY -MM -DD format . The Sales column is the y -axis . The graph should have the title \" Shampoo Sales Trend \". 14\n\"\"\"\nListing 7: Challenge 3: Creating documentation\nD PROGRAMMER'S ASSISTANT PROMPT\nListing 9 shows the initial prompt sent to Codex to configure it as a conversational agent. On subsequent exchanges, the prompt was augmented with a transcript of the user's requests and the assistant's responses. When the transcript length + initial prompt length + the new utterance length exceeded a threshold, we automatically deleted the earliest request-response pairs from the transcript until the sum fell below the threshold in order to leave room in the token allocation for a response.\n",
        "resume": "Large language models (LLMs) have recently been applied in software engineering to perform tasks such as translating code between programming languages, generating code from natural language, and autocompleting code as it is being written. When used within development tools, these systems typically treat each model invocation independently from all previous invocations, and only a specific limited functionality is exposed within the user interface. This approach to user interaction misses an opportunity for users to more deeply engage with the model by having the context of their previous interactions, as well as the context of their code, inform the model's responses. We developed a prototype system -the Programmer's Assistant -in order to explore the utility of conversational interactions grounded in code, as well as software engineers' receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM. Through an evaluation with 42 participants with varied levels of programming experience, we found that our system was capable of conducting extended, multi-turn discussions, and that it enabled additional knowledge and capabilities beyond code generation to emerge from the LLM. Despite skeptical initial expectations for conversational programming assistance, participants were impressed by the breadth of the assistant's capabilities, the quality of its responses, and its potential for improving their productivity. Our work demonstrates the unique potential of conversational interactions with LLMs for co-creative processes like software development.",
        "authors": [
            "Stephanie Houde",
            "Justin D 2023 Weisz",
            "Steven I Ross",
            "Fernando Martinez",
            "Michael Muller"
        ],
        "keywords": [
            "code-fluent large language models",
            "foundation models",
            "conversational interaction",
            "human-centered AI"
        ],
        "institutions": [
            "IBM Research AI Cambridge"
        ],
        "refrences": [
            "Rabe Abdalkareem, Emad Shihab, Juergen Rilling. What Do Developers Use the Crowd For? A Study Using Stack Overflow IEEE Software 2017. 2017, 34, 53-60.",
            "Eleni Adamopoulou, Lefteris Moussiades. Chatbots: History, technology, and applications Machine Learning with Applications 2020. 2020, 2.",
            "Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, V Quoc. Towards a Human-like Open-Domain Chatbot 2020.",
            "Safinah Ali, Nisha Elizabeth Devasia, Cynthia Breazeal. Escape! Bot: Social Robots as Creative Problem-Solving Partners Creativity and Cognition 2022, 275-283.",
            "Miltiadis Allamanis, T Earl, Premkumar Barr, Charles Devanbu. A survey of machine learning for big code and naturalness ACM Computing Surveys (CSUR) 2018. 2018, 51, 1-37.",
            "Irene Alvarado, Idan Gazit, Amelia Wattenberger. GitHub Next | GitHub Copilot Labs 2022.",
            "Hikari Ando, Rosanna Cousins, Carolyn Young. Achieving saturation in thematic analysis: Development and refinement of a codebook Comprehensive Psychology 2014. 2014, 3.",
            "Craig Anslow, Stuart Marshall, James Noble, Robert Biddle. Sourcevis: Collaborative software visualization for co-located environments 2013 First IEEE Working Conference on Software Visualization (VISSOFT) IEEE 2013, 1-10.",
            "Zahra Ashktorab, Michael Desmond, Josh Andres, Michael Muller, Narendra Nath Joshi, Michelle Brachman, Aabhas Sharma, Kristina Brimijoin, Qian Pan, Christine T Wolf. AI-Assisted Human Labeling: Batching for Efficiency without Overreliance Proceedings of the ACM on Human-Computer Interaction 2021. 2021, 5, CSCW, 1-27.",
            "Catherine A Ashworth. GUI Users have trouble using graphic conventions on novel tasks Conference Companion on Human Factors in Computing Systems 1996, 75-76.",
            "Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova Dassarma. A general language assistant as a laboratory for alignment 2021. 2021, arXiv preprint, arXiv:2112.00861.",
            "Leif Azzopardi, Paul Thomas, Nick Craswell. Measuring the utility of search engine result pages: an information foraging based measure The 41st International ACM SIGIR conference on research & development in information retrieval 2018, 605-614.",
            "Shraddha Barke, Michael B James, Nadia Polikarpova. Grounded Copilot: How Programmers Interact with Code-Generating Models 2022. 2022, arXiv preprint, arXiv:2206.15000.",
            "Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Jeannette Michael S Bernstein, Antoine Bohg, Emma Bosselut. On the opportunities and risks of foundation models 2021. 2021, arXiv preprint, arXiv:2108.07258.",
            "Joel Brandt, Mira Dontcheva, Marcos Weskamp, Scott R Klemmer. Example-centric programming: integrating web search into the development environment Proceedings of the SIGCHI Conference on Human Factors in Computing Systems 2010, 513-522.",
            "Virginia Braun, Victoria Clarke. Common challenges in Thematic Analysis and how to avoid them 2022, 11.",
            "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mccandlish, Alec Radford, Ilya Sutskever, Dario Amodei. Language Models are Few-Shot Learners Advances in Neural Information Processing Systems Curran Associates, Inc 2020, 33, c0d6bfcb4967418bfb8ac142f64a-Paper.pdf, 1877-1901.",
            "Sallyann Bryant, Pablo Romero, Benedict\" Du Boulay. The Collaborative Nature of Pair Programming Extreme Programming and Agile Processes in Software Engineering Springer 2006, 53-64.",
            "Andres Campero, Michelle Vaccaro, Jaeyoon Song, Haoran Wen, Abdullah Almaatouq, Thomas W Malone. A Test for Evaluating Performance in Human-Computer Systems 2022. 2022, arXiv preprint, arXiv:2206.12390.",
            "Gaetano Cascini, Yukari Nagai, V Georgi, Jader Georgiev, NiccolÃ² Zelaya, Jean-FranÃ§ois Becattini, Hernan Boujut, Nathan Casakin, Elies Crilly, John Dekoninck. Perspectives on design creativity and innovation research: 10 years later 2022, 30 pages.",
            "Stephen Cass. Top Programming Languages 2022 IEEE Spectrum 2022. 23 Aug 2022.",
            "Cristina Catalan Aguirre, Nuria Gonzalez Castro, Carlos Delgado Kloos, Carlos Alario-Hoyos, Pedro JosÃ©, MuÃ±oz Merino. Conversational agent for supporting learners on a MOOC on programming with Java 2021. 2021.",
            "Paula Chaves, Marco Aurelio. How should my chatbot interact? A survey on social characteristics in human-chatbot interaction design International Journal of Human-Computer Interaction 2021. 2021, 37, 729-758.",
            "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harrison Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, David W Cummings, Matthias Plappert, Fotios Chantzis, ; William, H Guss, Alex Nichol, Igor Babuschkin, S Arun Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew M Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob Mcgrew, Dario Amodei, Sam Mccandlish.  Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating a Large Language Models Trained on Code.",
            "Li-Te Cheng, R B De Souza, Susanne Hupfer, John Patterson, Steven Ross. Building Collaboration into IDEs: Edit>Compile>Run>Debug>Collaborate? Queue 2003. 2003, 1.",
            "Carl Cook, Warwick Irwin, Neville Churcher. A user evaluation of synchronous collaborative software engineering tools 12th Asia-Pacific Software Engineering Conference (APSEC'05) IEEE 2005.",
            "Claudio LeÃ³n De La Barra, Broderick Crawford, Ricardo Soto, Sanjay Misra, Eric Monfroy. Agile Software Development: It Is about Knowledge Management and Creativity Computational Science and Its Applications -ICCSA 2013, Beniamino Murgante, Sanjay Misra, Maurizio Carlini Springer 2013, 98-113.",
            "Uri Dekel, Steven Ross. Eclipse as a platform for research on interruption management in software development Proceedings of the 2004 OOPSLA workshop on Eclipse Technology eXchange ACM 2004, 12-16.",
            "Bobbie Eicher, Kathryn Cunningham, Sydni Peterson, Marissa Gonzales, Ashok Goel. Toward mutual theory of mind as a foundation for co-creation International Conference on Computational Creativity, Co-Creation Workshop 2017.",
            "Eduardo Stephen M Fiore, Janis A Salas. Group dynamics and shared mental model development. How people evaluate others in organizations 2001. 2001.",
            "Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides. Design patterns: elements of reusable object-oriented software Addison-Wesley 1995.",
            "GitHub copilot â¢ your AI pair programmer GitHub, Inc 2022, Retrieved August 5, 2022 from.",
            "Amelia Glaese, Nat Mcaleese, Maja TrÄbacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, SoÅa MokrÃ¡, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, Geoffrey Irving. Improving alignment of dialogue agents via targeted human judgements 2022.",
            "Stephanie Glen. ChatGPT writes code, but won't replace developers 2022. 14 12 2022. Jan-2023, 20, TechTarget.",
            "Samuel Holmes, Anne Moorhead, Raymond Bond, Huiru Zheng, Vivien Coates, Mike Mctear. WeightMentor: a new automated chatbot for weight loss maintenance Proceedings of the 32nd International BCS Human Computer Interaction Conference 2018, 32, 1-5.",
            "Xing Hu, Ge Li, Xin Xia, David Lo, Zhi Jin. Deep code comment generation with hybrid lexical and syntactical information Empirical Software Engineering 2020. 2020, 25, 2179-2217.",
            "L Edwin, James D Hutchins, Donald A Hollan. Direct manipulation interfaces Human-computer interaction 1985. 1985, 1, 311-338.",
            "Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Luke Zettlemoyer. Summarizing source code using a neural attention model Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics Long Papers 2016, 1, 2073-2083.",
            "Andreas Jedlitschka, Markus Nick. Software Engineering Knowledge Repositories Springer 2003, 55-80.",
            "Eirini Kalliamvakou. Research: Quantifying github copilot's impact on developer productivity and happiness 2022.",
            "Anna Kantosalo. Human-Computer Co-Creativity: Designing, Evaluating and Modelling Computational Collaborators for Poetry Writing 2019. 2019.",
            "Bali Sandeep Kaur Kuttal, Kate Ong, Peter Kwasny. Trade-Offs for Substituting a Human with an Agent in a Pair Programming Context: The Good, the Bad, and the Ugly Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI '21) Association for Computing Machinery 2021, Article 243, 20 pages.",
            "Lauramaria Laine. Exploring Advertising Creatives' Attitudes Towards Human-AI Collaboration 2021. 2021.",
            "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, RÃ©mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago. Competition-level code generation with AlphaCode 2022.",
            "Yaosheng Lou, Qi Sun. Over-reliance on database: A case study of using web of science Human Behavior and Emerging Technologies 2021. 2021, 3, 454-459.",
            "David Lyell, Enrico Coiera. Automation bias and verification complexity: a systematic review Journal of the American Medical Informatics Association 2017. 2017, 24, 423-431.",
            "Wendy E Mackay, Anne-Laure Fayard. HCI, natural science and design: a framework for triangulation across disciplines Proceedings of the 2nd conference on Designing interactive systems: processes, practices, methods, and techniques 1997, 223-234.",
            "John E Mathieu, Tonia S Heffner, Gerald F Goodwin, Eduardo Salas, Janis A Cannon-Bowers. The influence of shared mental models on team process and performance Journal of applied psychology 2000. 2000, 85.",
            "Cade Metz. Meet GPT-3. It Has Learned to Code (and Blog and Argue) 2022, Published 2020.",
            "Robert J Moore, Raphael Arar. Conversational UX Design: A Practitioner's Guide to the Natural Conversation Framework Association for Computing Machinery 2019.",
            "Ekaterina A Moroz, Vladimir O Grizkevich, Igor M Novozhilov. The Potential of Artificial Intelligence as a Method of Software Developer's Productivity Improvement 2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus) IEEE 2022, 386-390.",
            "Michael Muller, Stevean Ross, Stephanie Houde, Mayank Agarwal, Fernando Martinez, John Richards, Kartik Talamadupula, Justin D Weisz. Drinking Chai with Your (AI) Programming Partner: A Design Fiction about Generative AI for Software Engineering. HAI-GEN Workshop at IUI 2022: 3rd Workshop on Human-AI Co-Creation with Generative Models 2022. 2022.",
            "R Sandra, Alfredo Murillo. Empowering interfaces for system administrators: Keeping the command line in mind when designing GUIs Proceedings of the XV International Conference on Human Computer Interaction 2014, 1-4.",
            "D Elizabeth, Gerhard Mynatt. Nonvisual presentation of graphical user interfaces: contrasting two approaches Proceedings of the SIGCHI conference on Human factors in computing systems 1994, 166-172.",
            "Alok Mysore, Philip J Guo. Torta: Generating mixed-media gui and command-line app tutorials using operating-system-wide activity tracing Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology 2017, 703-714.",
            "C Nass, Y Moon. Machines and Mindlessness: Social Responses to Computers Journal of Social Issues 2000. 2000, 56, 81-103.",
            "Nhan Nguyen, Sarah Nadi. An Empirical Evaluation of GitHub Copilot's Code Suggestions 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR) IEEE 2022, 1-5.",
            "Martin Nordio, H Estler, Carlo A Furia, Bertrand Meyer. Collaborative software development on the web 2011. 2011, arXiv preprint, arXiv:1105.0768.",
            "Maxwell Nye, Anders Andreassen, Guy Gur-Ari, Witold Henryk, Jacob Michalewski, David Austin, David Bieber, Aitor Martin Dohan, Maarten Lewkowycz, David Paul Bosma, Charles Luan, Augustus Sutton. Show Your Work: Scratchpads for Intermediate Computation with Language Models 2021.",
            "ChatGPT: Optimizing Language Models for Dialogue OpenAI Blog 2022. 30 11 2022. Jan-2023, 20.",
            "Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe. Training language models to follow instructions with human feedback 2022.",
            "Peter Pirolli, Stuart Card. Information foraging Psychological review 1999. 1999, 106.",
            "Personal computing: Windows, DOS and the MAC Commun. ACM Larry Press 1990. 1990, 33, 19-26.",
            "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever. Language Models are Unsupervised Multitask Learners 2019.",
            "Alvin Rajkomar, Jeffrey Dean, Isaac Kohane. Machine learning in medicine New England Journal of Medicine 2019. 2019, 380, 1347-1358.",
            "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen. Hierarchical text-conditional image generation with clip latents 2022. 2022, arXiv preprint, arXiv:2204.06125.",
            "B Reeves, C I Nass. The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places CSLI Publications 1996.",
            "Mawarny Md Rejab, James Noble, George Allan. Distributing Expertise in Agile Software Development Projects 2014 Agile Conference 2014, 33-36.",
            "Jeba Rezwana, Mary Lou Maher. COFI: A Framework for Modeling Interaction in Human-AI Co-Creative Systems ICCC 2021, 444-448.",
            "Charles H Rich, Richard C Waters. The Programmer's Apprentice Addison-Wesley Publishing Company 1990.",
            "Peter Robe, Sandeep Kaur. Designing PairBuddy-A Conversational Agent for Pair Programming ACM Transactions on Computer-Human Interaction (TOCHI) 2022. 2022, 29, 1-44.",
            "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, BjÃ¶rn Ommer. High-resolution image synthesis with latent diffusion models Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022, 10684-10695.",
            "Steven Ross, Elizabeth Brownholtz, Robert Armes. A Multiple-Application Conversational Agent Proceedings of the 9th International Conference on Intelligent User Interfaces Association for Computing Machinery 2004, IUI '04, 319-321.",
            "Steven Ross, Elizabeth Brownholtz, Robert Armes. Voice User Interface Principles for a Conversational Agent Proceedings of the 9th International Conference on Intelligent User Interfaces Association for Computing Machinery 2004, IUI '04, 364-365.",
            "Marie-Anne Baptiste Roziere, Lowik Lachaux, Guillaume Chanussot. Unsupervised Translation of Programming Languages Advances in Neural Information Processing Systems Curran Associates, Inc 2020, 33, 20601-20611.",
            "Harvey Sacks. Notes on methodology Structures of Social Action: Studies in Conversation Analysis Cambridge University Press 1984, 2-27.",
            "Nithya Sambasivan, Rajesh Veeraraghavan. The Deskilling of Domain Expertise in AI Development CHI Conference on Human Factors in Computing Systems 2022, 1-14.",
            "Harini Sampath, Alice Merrick, Andrew Macvean. Accessibility of command line interfaces Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems 2021, 1-10.",
            "Matthias Scheutz, Scott A Deloach, Julie A Adams. A framework for developing and using shared mental models in human-agent teams Journal of Cognitive Engineering and Decision Making 2017. 2017, 11, 203-224.",
            "Isabella Seeber, Eva Bittner, Robert O Briggs, Triparna De Vreede, Gert-Jan De Vreede, Aaron Elkins, Ronald Maier, Alexander B Merz, Sarah Oeste-ReiÃ, Nils Randrup. Machines as teammates: A research agenda on AI in team collaboration 2020. 2020, 57.",
            "Shilad Sen, Werner Geyer, Michael Muller, Marty Moore, Beth Brownholtz, Eric Wilcox, David R Millen. FeedMe: a collaborative alert filtering system Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work 2006, 89-98.",
            "Ben Shneiderman. Human-centered artificial intelligence: Three fresh ideas AIS Transactions on Human-Computer Interaction 2020. 2020, 12, 109-124.",
            "Ben Shneiderman. Human-Centered AI Oxford University Press 2022.",
            "Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane. BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage 2022. 2022, arXiv preprint, arXiv:2208.03188.",
            "Michael Skirpan, Casey Fiesler. Ad empathy: A design fiction Proceedings of the 2018 ACM Conference on Supporting Groupwork 2018, 267-273.",
            "Diomidis Spinellis. Git. IEEE Software 2012. 2012, 29, 100-101.",
            "Angie Spoto, Natalia Oleynik. Library of Mixed-Initiative Creative Interfaces. Retrieved 19-Jun-2021 from 2017.",
            "Ayushi Srivastava, Shivani Kapania, Anupriya Tuli, Pushpendra Singh. Actionable UI Design Guidelines for Smartphone Applications Inclusive of Low-Literate Users Proceedings of the ACM on Human-Computer Interaction 2021. 2021, 5, CSCW, 1-30.",
            "Margaret-Anne Storey, Alexey Zagalsky. Disrupting developer productivity one bot at a time Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering 2016, 928-931.",
            "Kartik Talamadupula. Applied AI matters: AI4Code: applying artificial intelligence to source code AI Matters 2021. 2021, 7, 18-20.",
            "Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Alicia Cheng, Taylor Jin, Leslie Bos, Yu Baker. LAMDA: Language models for dialog applications 2022.",
            "Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Neel Shao Kun Deng. Unit Test Case Generation with Transformers and Focal Context 2020. 2020, arXiv preprint, arXiv:2009.05617.",
            "Severi Uusitalo, Anna Kantosalo, Antti Salovaara, Tapio Takala, Christian Guckelsberger. Co-creative Product Design with Interactive Evolutionary Algorithms: A Practice-Based Reflection International Conference on Computational Intelligence in Music, Sound, Art and Design Springer 2022, 292-307.",
            "Priyan Vaithilingam, Philip J Guo. Bespoke: Interactively synthesizing custom GUIs from command-line applications by demonstration Proceedings of the 32nd annual ACM symposium on user interface software and technology 2019, 563-576.",
            "Priyan Vaithilingam, Tianyi Zhang, Elena L Glassman. Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems Association for Computing Machinery 2022, 332, CHI EA '22).",
            "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Å Ukasz Kaiser, Illia Polosukhin. Attention is All you Need Advances in Neural Information Processing Systems Curran Associates, Inc 2017, 30, f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.",
            "Zhou Yao Wan, Min Zhao, Guandong Yang, Haochao Xu, Jian Ying, Philip S Wu. Improving automatic source code summarization via deep reinforcement learning Proceedings of the 33rd ACM/IEEE international conference on automated software engineering 2018, 397-407.",
            "April Yi, Dakuo Wang, Jaimie Drozdal, Michael Muller, Soya Park, Justin D Weisz, Xuye Liu, Lingfei Wu, Casey Dugan. Documentation Matters: Human-Centered AI System to Assist Data Science Code Documentation in Computational Notebooks ACM Transactions on Computer-Human Interaction 2022. 2022, 29, 1-33.",
            "Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, Alexander Gray. Human-AI collaboration in data science: Exploring data scientists' perceptions of automated AI Proceedings of the ACM on Human-Computer Interaction 2019. 2019, 3, 1-24.",
            "Qiaosi Wang, Koustuv Saha, Eric Gregori, David Joyner, Ashok Goel. Towards mutual theory of mind in human-ai interaction: How language reflects what students perceive about a virtual teaching assistant Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems 2021, 1-14.",
            "Jeremy Warner, Philip J Guo. Codepilot: Scaffolding end-to-end collaborative software development for novice programmers Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems 2017, 1136-1141.",
            "Justin D Weisz, Michael Muller, Stephanie Houde, John Richards, Steven I Ross, Fernando Martinez, Mayank Agarwal, Kartik Talamadupula. Perfection Not Required? Human-AI Partnerships in Code Translation 26th International Conference on Intelligent User Interfaces 2021, 402-412.",
            "Justin D Weisz, Michael Muller, Steven I Ross, Fernando Martinez, Stephanie Houde, Mayank Agarwal, Kartik Talamadupula, John T Richards. Better together? an evaluation of ai-supported code translation 27th International Conference on Intelligent User Interfaces 2022, 369-391.",
            "Joseph Weizenbaum. ELIZA -a computer program for the study of natural language communication between man and machine Commun. ACM 1966. 1966, 9, 36-45.",
            "Bogdan Frank F Xu, Graham Vasilescu. In-ide code generation from natural language: Promise and challenges ACM Transactions on Software Engineering and Methodology (TOSEM) 2022. 2022, 31, 1-47.",
            "Aditya Ankur Yadav, Ishan Garg, Dr Pratistha Mathur. PACT -Programming Assistant ChaTbot 2019 2nd International Conference on Intelligent Communication and Computational Techniques (ICCT) 2019, 131-136.",
            "Munazza Zaib, Z Quan, W Sheng. A Short Survey of Pretrained Language Models for Conversational AI-A New Age in NLP. Proceedings of the Australasian Computer Science Week Multiconference 2020. 2020.",
            "Elaine Zibrowski, Lisa Shepherd, Kamran Sedig, Richard Booth, Candace Gibson. Easier and faster is not always better: grounded theory of the impact of large-scale system transformation on the clinical work of emergency medicine nurses and physicians JMIR Human Factors 2018. 2018, 5.",
            "Albert Ziegler, Eirini Kalliamvakou, X Alice Li, Andrew Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, Edward Aftandilian. Productivity Assessment of Neural Code Completion Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming Association for Computing Machinery 2022, MAPS 2022), 21-29."
        ],
        "created_at": "2024-02-01T13:56:21.365718+00:00",
        "updated_at": "2024-02-01T13:57:01.515993+00:00"
    },
    {
        "id": 10,
        "title": "Framing the News: From Human Perception to Large Language Model Inferences",
        "body": "1 INTRODUCTION\nIn recent years, there has been a proliferation in the use of concepts such as data journalism, computational journalism, and computerassisted reporting[15][29], which all share the vision of bridging journalism and technology. The progress made in NLP has been gradually integrated into the journalistic field[5][8][54]. More specifically, machine learning models based on transformers have been integrated in the media sector in different tasks[41]such as the creation of headlines with generative languages models[17], summarization of news articles[28][27], false news detection[49], and topic modeling and sentiment analysis[25]. The development of large language models such as GPT-3[9], BLOOM[51]or ChatGPT show a clear trend towards human-machine interaction becoming easier and more intuitive, opening up a wide range of research possibilities. At the same time, the use of these models is also associated with a lack of transparency regarding how these models work, but efforts are being made to bring some transparency to these models, and to analyze use cases where they can be useful and where they cannot[35]. Based on the premises that these models open up a wide range of research directions[7], and that at the same time (and needless to say) they are not the solution to all problems, we are interested in identifying use cases and tasks where they can be potentially useful, while acknowledging and systematically documenting their limitations[56]. More specifically, the aim of this work is to analyze the performance of GPT-3.5 for a specific use case, namely the analysis of frames in news, from an empirical point of view, with the objective of shedding light on a potential use of generative models in journalistic tasks.\nFrame analysis is a concept from journalism, which consists of studying the way in which news stories are presented on an issue, and what aspects are emphasized: Is a merely informative vision given in an article? Or is it intended to leave a moral lesson? Is a news article being presented from an economic point of view? Or from a more human, emotional angle? The examples above correspond to different frames with which an article can be written.\nThe concept of news framing has been studied in computing as a step beyond topic modeling and sentiment analysis, and for this purpose, in recent years, pre-trained language models have been used for fine-tuning the classification process of these frames[60][10], but the emergence of generative models opens the possibility of doing prompt-engineering of these classification tasks, instead of the fine-tuning approach investigated so far.\nOur work aims to address this research gap by posing the following research questions:\nRQ1: What are the main frames in the news headlines about the anti-vaccine movement, as reported in newspapers across 5 European countries? RQ2: Can prompt engineering be used for classification of headlines according to frames? By addressing the above research questions, our work makes the following contributions: Contribution 1. We implemented a process to do human annotation of the main frame of 1786 headlines of articles about the Covid-19 no-vax movement, as reported in 19 newspapers from 5 European countries (France, Italy, Spain, Switzerland and United Kingdom.) At the headline level, we found that the predominant frame was human interest, where this frame corresponds to a personification of an event, either through a statement by a person, or the explanation of a specific event that happened to a person. Furthermore, we found a large number of headlines annotated as containing no frame, as they simply present information without entering into evaluations. We also found that for all the countries involved, the distribution of frame types was very similar, i.e., human interest and no frame are the two predominant frames. Finally, the generated annotations allowed to subsequently study the performance of a large language model. Contribution 2. We studied the performance of GPT-3.5 on the task of frame classification of headlines. In addition to using the fine-tuning approach from previous literature, we propose an alternative approach for frame classification that requires no labeled data for training, namely prompt-engineering using GPT-3.5. The results show that fine-tuning with GPT-3.5 produces 72% accuracy (slightly higher than other smaller models), and that the promptengineering approach results in lower performance (49% accuracy.) Our analysis also shows that the subjectivity of the human labeling task has an effect on the obtained accufracy.\nThe paper is organized as follows. In Section 2, we discuss related work. In Section 3, we describe the news dataset. In Section 4, we describe the methodology for both human labeling and machine classification of news frames. We present and discuss results for RQ1 and RQ2 in Sections 5 and 6, respectively. Finally, we provide conclusions in Section 7.\n2 RELATED WORK\nFraming has been a concept widely studied in journalism, with a definition that is rooted in the study of this domain[23]: \"To frame is to select some aspects of a perceived reality and make them more salient in a communicating text, in such a way as to promote a particular problem definition, causal interpretation, moral evaluation, and/or treatment recommendation for the item described. \"\nFor frame recognition, there are two main approaches: the inductive approach[16], where one can extract the frames after reading the article, and the deductive approach[38], where a predefined list of frames exists and the goal is to interpret if any of them appears in the article. In the deductive case, there are generic frames and subject-specific frames, and the way to detect them typically involves reading and identifying one frame at a time, or through answers to yes/no questions that represent the frames. Semetko et al.[52]used 5 types of generic frames (attribution of responsibility, human interest, conflict, morality, and economic consequences) based on previous literature, and they defined a list of 20 yes/no questions to detect frames in articles. For instance, the questions about morality are the following: \"Does the story contain any moral message? Does the story make reference to morality, God, and other religious tenets? Does the story offer specific social prescriptions about how to behave?\", and so on for each of the frame types. This categorization of frames has been used in various topics such as climate change[18][19], vaccine hesitance[13], or immigration[34].\nWe now compare the two approaches on a common topic, such as Covid-19. Ebrahim et al.[21]followed an inductive approach in which the frames were not predefined but emerged from the text (e.g., deadly spread, stay home, what if, the cost of Covid-19) using headlines as the unit of analysis. In contrast, the deductive approach has studied very different labels. El-Behary et al.[22]followed the method of yes/no questions, but in addition to the 5 generic frames presented before, they also used blame frame and fear frame. Adiprasetio et al.[1]and Rodelo[50]used the 5 generic frames with yes/no questions, while CatalÃ¡n-Matamoros et al.[14]used the 5 frames and read the headline and subheadline to decide the main frame. Table1summarizes some of the the existing approaches. This previous work showed how frame labels can be different, and also that frame analysis has been done at both headline and article levels. These two approaches (inductive and deductive) that originated in journalism have since been replicated in the computing literature.\nWe decided to follow the deductive approach because a predefined list of frames allows to compare among topics, countries, previous literature, and also because they represent a fixed list of labels for machine classification models. Furthermore, the inductive approach tends to be more specific to a topic, and from the computing viewpoint, past work has tried to justify topic modeling as a technique to extract frames from articles.\nYlÃ¤-Antitila et al.[60]proposed topic modeling as a frame extraction technique. They argued that topics can be interpreted as frames if three requirements are met: frames are operationalized as connections between concepts; subject-specific data is selected; and topics are adequately validated as frames, for which they suggested a practical procedure. This approach was based on the choice of a specific topic (e.g., climate change) and the use of Latent Dirichlet Allocation (LDA) as a technique to extract a number of subtopics. In a second phase, a qualitative study of the top 10 words of each subtopic was performed, and the different subtopics were eliminated or grouped, reducing the number and establishing a tentative description. In a third phase, the top 10 articles belonging to that frame/topic were taken, and if the description of the topic fitted at least 8 of the 10 articles, that topic/frame remained. The frames found in this article were: green growth, emission cuts, negotiations and treaties, environmental risk, cost of carbon emissions, Chinese emissions, economics of energy production, climate change, environmental activism, North-South burden sharing, state leaders negotiating, and citizen participation.\nFrom Entman's definition of frame[23], it seems that the deductive approach is more refined than the inductive approach (which seems to resemble the detection of sub-themes.) For example, with regard to climate change, there are stories on how people have been affected by climate change from an emotional point of view, thus personalizing the problem. In this case, we could categorize the corresponding frame as human interest, as the writer of the article is selecting \"some aspects of a perceived reality and make them more salient\". The language subtleties with which news articles are presented cannot be captured with basic topic modeling.\nIsoaho et al.[30]held the position that while the benefits of scale and scope in topic modeling were clear, there were also a number of problems, namely that topic outputs do not correspond to the methodological definition of frames, and thus topic modeling remained an incomplete method for frame analysis. Topic modeling, in the practice of journalistic research, is a useful technique to deal with the large datasets that are available, yet is often not enough to do more thorough analyses[31]. In our work, we clearly notice that frame analysis is not topic modeling. For example, two documents could be about the same topic, say Covid-19 vaccination, but one article could emphasize the number of deaths after vaccination, while the other emphasized the role of the vaccine as a solution to the epidemic.\nWe also consider that the larger the number of possible frame types, the more likely it is to end up doing topic modeling instead of frame analysis. Using a deductive approach, Dallas et al.[12]created a dataset with articles about polemic topics such as immigration, same sex marriage, or smoking, and they defined 15 types of frames: \"economic, capacity and resources, morality, fairness and equality, legality, constitutionality and jurisprudence, policy prescription and evaluation, crime and punishment, security and defense, health and safety, quality of life, cultural identity, political, external regulation and reputation, other\". In this case, they authors did not use a list of questions. Instead, for each article, annotators were asked to identify any of the 15 framing dimensions present in the article and to label text blurbs that cued them (based on the definitions of each of the frame dimensions) and decide the main frame of each article. In our case, we followed the idea of detecting the main frame by reading the text instead of answering questions, but instead of using the 15 frames proposed in[12], we used the 5 generic frames proposed in[52].\nA final decision in our work was the type of text to analyze, whether headlines or whole article. For this decision, the chosen classification method was also going to be important. For example, Khanehzar et al.[33]used traditional approaches such as SVMs as baseline, and demonstrated the improvement in frame classification with the use of pre-trained languages models such as BERT, RoBERTa and XLNet, following a fine-tuning approach, setting as input text a maximum of 256 tokens (although the maximum number of input tokens in these models is 512 tokens.) Liu et al.[37]classified news headlines about the gun problem in the United States, arguing for the choice of headlines as a unit of analysis based on previous journalism literature[6],[44], that advocated for the importance and influence of headlines on readers and the subsequent perception of articles. From a computational viewpoint, using headlines is also an advantage, since you avoid the 512 token limitation in BERT-based models. Therefore, we decided to work with headlines about a controversial issue, namely the Covid-19 no-vax movement.\nContinuing with the question of the methods used for classification, much work has been developed in prompt engineering, especially since the release of GPT-3. Liu et al.[36]presented a good overview of the work done on this new NLP paradigm, not only explaining the concept of prompt engineering, but also the different strategies that can be followed both in the design of prompts, [12] 15 generic frames: \"Economic\", \"Capacity and resources\", \"Morality\", \"Fairness and equality\", \"Legality, constitutionality and jurisprudence\", \"Policy prescription and evaluation\", \"Crime and punishment\", \"Security and defense\", \"Health and safety\", \"Quality of life\", \"Cultural identity\", \"Public opinion\", \"Political\", \"External regulation and reputation\", \"Other\".\nTo label frames of full articles\nReading the full article, the annotator defines the main frame 20000 articles[33]131 headlines + subheadlines the potential applications, and the challenges to face when using this approach. Prompt engineering applications include knowledge probing[46], information extraction[53], NLP reasoning[57], question answering[32], text generation[20], multi-modal learning[58], and text classification[24], the latter being the prompt-engineering use case in our work. Puri et al.[45]presented a very interesting idea that we apply to our classification task. This consists of providing the language model with natural language descriptions of classification tasks as input, and training it to generate the correct answer in natural language via a language modeling objective. It is a zero-shot learning approach, in which no examples are used to explain the task to the model. Radford et al.[48]demonstrated that language models can learn tasks without any explicit supervision. We have followed this approach to find an alternative way to do frame analysis.\nAs mentioned before, the emergence of giant models like GPT-3, BLOOM, and ChatGPT are a very active research topic. To the best of our knowledge, on one hand our work extends the computational analysis of news related to the covid-19 no-vax movement, which illustrates the influence of the press on the ways societies think about relevant issues[40],[59], and on the other hand it adds to the literature of human-machine interaction, regarding the design of GPT-3 prompts for classification tasks[39],[2].\n3 DATA: EUROPEAN COVID-19 NEWS DATASET\nWe used part of the European Covid-19 News dataset collected in our recent work[3]. This dataset contains 51320 articles on Covid-19 vaccination from 19 newspapers from 5 different countries: Italy, France, Spain, Switzerland and UK. The articles cover a time period of 22 months, from January 2020 to October 2021. All content was translated into English to be able to work in a common language. The dataset was used for various analyses, such as name entity recognition, sentiment analysis, and subtopic modeling, to understand how Covid-19 vaccination was reported in Europe through the print media (in digital format.) The subtopic modeling analysis revealed a subsample of articles on the no-vax movement, which is the one we have used in this paper. We took the headlines of the articles associated with the no-vax movement, selecting all articles containing any of the keywords in Table2in the headline or in the main text. This corresponds to a total of 1786 headlines.\nTable2: Keywords used to identify no-vax articles Keywords NO VAX TOPIC \"anti-vaxxers\", \"anti-vaccine\", \"anti-vaxx\", \"anti-corona\", \"no-vax\", \"no vax\", \"anti-vaccin\"\nIn Table3, we show the number of headlines per country and newspaper. France is the country with the most no-vax articles in the corpus, with 523 articles, followed by Italy with 508. However, note that there are 6 newspapers from France, while only 2 from Italy. Corriere della Sera is the newspaper that dealt most frequently with the subject (429 articles), while The Telegraph is the second one (206 articles). The total number of articles normalized by the number of newspapers per country is also shown in the last column of the Table . Using these normalized values, the ranking is Italy, UK, France, Switzerland, and Spain.\n4 METHODOLOGY 4.1 Human labeling of news frames\nTo carry out the labeling of the frames in our corpus of headlines, we first designed a codebook, which contained the definitions of each of the frame types and a couple of examples of each type, as well as a definition of the corpus subject matter and definitions of the concept of frame analysis, so that the annotators could understand the task to be performed. The codebook follows the proposed by[52]with 5 generic frames (attribution of responsibility, human interest, conflict, morality, and economic consequences) plus one additional 'no-frame' category. Two researchers were engaged to annotate a sample of the collected newspaper articles following a three-phase training procedure.\nIn the first phase, annotators had to read the codebook and get familiar with the task. In the second phase, they were asked to identify the main frame in the same subset of 50 headlines. At the end of the second phase, the intercoder reliability (ICR) was 0.58 between the 2 annotators. We analyzed those cases where there were discrepancies, and observed that in some cases, there was not a unique main frame, because both annotators had valid arguments to select one of the frames. In other cases, the discrepancies were due to slight misunderstanding of the definitions. In the third phase, the annotators coded again 50 headlines, and the ICR increased to was 0.66. We realized that the possibility of having two frames remained. They discussed the cases in which they had disagreed, and if the other person's arguments were considered valid, it could be said that there were two frames. After this three-phase training procedure, annotators were ready to annotate the dataset independently. We divided the dataset into two equal parts, and each person annotated 893 headlines.\n4.2 Fine-tuning GPT-3.5 and BERT-based models\nWith the annotated dataset, we investigated two NLP approaches: the first one involves fine-tuning a pre-trained model; the second one is prompt engineering. Pre-trained language models have been In the first approach, a model with a fixed architecture is pretrained as a language model (LM), predicting the likelihood of the observed textual data. This can be done due to the availability of large, raw text data needed to train LMs. This learning process can produce general purpose features of the modeled language. The learning process produces robust, general-purpose features of the language being modeled. The above pre-trained LM is then adapted to different downstream tasks, by introducing additional parameters and adjusting them using task-specific objective functions. In this approach, the focus was primarily on goal engineering, designing the training targets used in both the pre-training and the fine-tuning stages[36].\nWe present an example to illustrate the idea. Imagine that the task is sentiment analysis, and we have a dataset with sentences and their associated sentiment, and a pre-trained model, which is a saved neural network trained with a much larger dataset. For that pre-trained model to address the target task, we unfreeze a few of the top layers of the saved model base and jointly train both the newly-added classifier layers and the last layers of the base model. This allows to \"fine-tune\" the higher-order feature representations in the base model to make them more relevant for the sentiment analysis task. In this way, instead of having to obtain a very large dataset with target labels to train a model, we can reuse the pretrained model and use a much smaller train dataset. We use a part of our dataset as examples for the model to learn the task, while the other part of the dataset is used to evaluate model performance.\nPrevious works related to frame classification in the computing literature have used fine-tuning, BERT-based models. In our work, we have done the same as a baseline, but we aimed to go one step further and also produce results using fine-tuning of GPT-3.5.\n4.3 Prompt-engineering with GPT-3.5\nModel fine-tuning has been widely used, but with the emergence of generative models such as GPT-3, another way to approach classification tasks has appeared. The idea is to use the pre-trained model directly and convert the task to be performed into a format as close as possible to the tasks for which it has been pre-trained. That is, if the model has been pre-trained from next word prediction as in the case of GPT-3, classification can be done by defining a prompt, where the input to the model is an incomplete sentence, and the model must complete it with a word or several words, just as it has been trained. This avoids having to use part of the already labeled dataset to teach the task to be performed to the model, and a previous labeling is not needed[36].\nIn this approach, instead of adapting pre-trained LMs to downstream tasks via objective engineering, downstream tasks are reformulated to look more like those solved during the original LM training with the help of a textual prompt. For example, when recognizing the emotion of a social media post, \"I missed the bus today. \", we may continue with a prompt \"I felt so _\", and ask the LM to fill the blank with an emotion-bearing word. Or if we choose the prompt \"English: I missed the bus today. French: _\"), an LM may be able to fill in the blank with a French translation. In this way, by selecting the appropriate prompts, we can influence the model behavior so that the pre-trained LM itself can be used to predict the desired output, even without any additional task-specific training[36].\nWe use this emerging NLP approach to classify frames at headline level. We are not aware of previous uses of this strategy to classify frames as we propose here. The idea is the following. Prompt engineering consists of giving a prompt to the model, and understands that prompt as an incomplete sentence. To do prompt engineering with our dataset, we needed to define an appropriate prompt that would produce the headline frames as output. We defined several experiments with the Playground of GPT-3, in order to find the best prompt for our task. In our initial experiments, we followed existing approaches in prompt engineering to do sentiment analysis, where the individual answer was an adjective, and this adjective was matched with a sentiment. In a similar fashion, we decided to build a thesaurus of adjectives that define each of the frames. For instance, the human interest frame could be 'interesting', 'emotional', 'personal', 'human'. The conflict frame could be: 'conflictive', 'bellicose', 'troublesome', 'rowdy', 'quarrelsome', 'troublemaker', 'agitator', etc. After the list of adjectives was defined, we needed to define the prompt in order to get, as an answer, one of the adjectives in our thesaurus to match them with the frame. We used the GPT-3 playground using the headline as input and asking for the frame as output, but the strategy did not work. In our final experiment, instead of giving the headline as input, we gave the definitions of each type of frame plus the headline, and we asked the model to choose between the different types of frames as output. In this way, the output of the model was directly one of the frames, and we avoided the step of matching adjectives with frames. An example is shown in Figure2. After testing with the GPT-3 playground and varying different hyper-parameters to assess performance, we set the temperature to 0, since the higher the temperature the more random the response. Furthermore, the Top-p parameter was set to 1, as it would likely get a set of the most likely words for the model to choose from. The maximum number of tokens was set to 2; in this way, the model is asked to choose between one of the responses. As a model, we used the one with the best performance at the time of experimental design, which was TEXT-DAVINCI-003, recognized as GPT 3.5.\n5 RESULTS: HUMAN LABELING OF FRAMES IN NO-VAX NEWS HEADLINES (RQ1)\nIn this section, we present and discuss the results of the analysis related to our first RQ. Figure3shows the distribution of frames per country at headline level, with human interest and no-frame being the predominant ones. Attribution of responsibility is the third one except in Switzerland, where the corresponding frame is conflict. Finally, morality and economic are the least represented in the dataset for every country.\nFigure 3: Non-normalized distribution of frames per country\nThe monthly distribution of frames aggregated for all countries is shown in Fig.4. We can see two big peaks, the first one in January 2021 and the second one in August 2021. In all countries, the vaccination process started at the end of December 2020, so it makes sense that the no-vax movement started to be more predominant in the news in January 2021. Human interest is the most predominant frame. Manual inspection shows that this is because the headlines are about personal cases of people who are pro-or anti-vaccine. Attribution of responsibility is also present. Manual inspection indicates that local politicians and health authorities had to make decisions about who could be vaccinated at the beginning of the process. The second peak at the end of summer 2021 coincided with the health pass (also called Covid passport in some countries), and we can observe a peak in the curve corresponding to the conflict frame, reflecting the demonstrations against the measure of mandatory health passes taken by country governments.\nIn Figure5, we compare the sentiment per frame and per country, to understand if there were any major differences. The sentiment analysis labels were obtained using BERT-sent from the Hugging Face package[47], used in our previous work (please refer to our original analysis in[3]for details.) We normalized the results between 0 and 1 to compare frames between countries. We see that the sentiment is predominantly neutral (in blue). Examining in more  Regarding the results of the annotation process, the fact that the distribution of the 6 frame types is relatively similar between countries suggests that the anti-vaccine movement issue was treated in a similar way in these countries. The fact that human interest is the most dominant frame indicates that this issue was treated from a more human and emotional approach, with headlines about personal experiences, celebrities giving their opinion about vaccination, and politicians defending vaccine policies. Moreover, the reason for many headlines being classified as no-frame is partly due to how data was selected. We chose articles that contained words related to no-vax, either in the headline or in the article. This resulted in many headlines not containing anything specific related to no-vax, while the no-vax content was actually included in the main text of the corresponding articles.\nIt is worth mentioning that prior to obtaining the results, we had expected that attribution of responsibility would be among the most prominent frames, since governments took many measures such as mandatory health pass requirements to access certain sites; we had also expected that the conflict frame would be prominent, since there were many demonstrations in Europe. In reality, however, these frames categories were not reflected as frequently at the headline level.\nRegarding the analysis at the temporal level, it is clear that certain events were captured by the press, such as the start of vaccination or the mandatory vaccination passport.\nFinally, the sentiment analysis of the different frames shows that the predominant tone in all of them is neutral or negative, with very similar trends between countries. This association between sentiment analysis and frames has been discussed in previous literature[11][43].\n6 RESULTS: GPT-3.5 FOR FRAME CLASSIFICATION OF HEADLINES (RQ2)\nHere, we present and discuss the results related to our second RQ.\n6.1 Fine-tuning GPT-3.5\nTable4shows the results of the 6-class classification task using 5-cross validation. Three models were used: GPT-3.5 and two BERTbased models. We observe that, on average, GPT-3.5 performs better than the BERT-based models. This is somehow expected as GPT-3.5 is a much larger model. Overall, in the case of fine-tuning, the best performance for the six-class frame classification task is 72% accuracy, which is promising, with an improvement over previous models based on BERT. Yet, it should be noted that the performance differences are modest (2% improvement between GPT-3.5 and RoBERTa). On the other hand, BERT is open-source, while GPT-3 has an economic cost as the use of the model is not free, which monetarily limits the number of experiments that can be performed with it, as well as the different configurations one can explore to improve performance. This is important because much of the improvement in performance requires empirical explorations of model parameters More specifically, the cost of an experiment for each of the folds has a cost of 4 dollars (at the time of writing this paper.) This represents a limitation in practice.\nFurthermore, GPT-3 has a significant carbon footprint. Similarly, for prompt engineering (discussed in the next subsection), choosing the right prompt (i.e., the words that best define the task so that the model is able to perform adequately) is also based on trial and error. This also has an impact on carbon footprint. In connection with this topic, Strubell et al.[55]argue that improvements in the accuracy of models depend on the availability of large computational resources, which involve large economic and environmental costs. A criticism has been made as 'the rich get richer', in the sense that not all research groups have sufficient infrastructure resources and access to funding needed to use these models and improve their performance. Also in relation to this analysis, the work of Bender et al.[4]evaluates the costs and risks of the use of large language models, stating that researchers should be aware of the impact that these models have on the environment, and assess whether the benefits outweigh the risks. The work in[4]provides a very telling example, where people living in the Maldives or Sudan are affected by floods and pay the environmental price of training English LLMs, when similar models have not been produced for languages like Dhivehi or Sudanese Arab. In short, there is a need to establish ways to use this technological development responsibly, and it all starts with being aware of the risks it presents.\n6.2 Prompt-engineering with GPT-3.5\nFor each headline, we got the frame that the model considered the most likely, and we compared these GPT-3.5 inferences with the frames labeled by the annotators. The agreement between model and annotator was of 49%. Analyzing the results, and specifically looking at the cases where the annotator and GPT-3.5 disagreed, we discovered that according to the frame definitions, the model in some cases proposed a frame that indeed made sense. This observation, together with our previous experience in the annotation process, where headlines could have more than one valid frame, led us to design a second post-hoc experiment. We took all the headlines where each of the two annotators had disagreed with GPT-3.5, and we asked the annotators to state whether they would agree (or not) with each GPT-inferred label for a given headline. It is important to emphasize that the annotators did not know the origin of that label, i.e., they did not know if it was the label they had originally assigned, or if it was a random one. In this way, we could quantify how GPT-3.5 worked according to valid arguments provided by the annotators. In this post-hoc experiment, the model agreed in 76% of cases with the annotators.\nLooking at the results of the classification models, the 49% accuracy of the prompt-engineering approach can be considered low, yet we consider that it is a valid avenue for further investigation, as in the second post-hoc analysis, we found that the model agrees with human annotators in 76% of the cases. Clearly, framing involves aspects of subjectivity[42]. Much of what we do as people has a subjective component, influenced by how we feel or how we express opinions.\nNews reading is never fully objective, and the annotators engaged in the frame classification task, influenced by their personal state of mind, experience, and culture, may perceive information differently. Monarch affirms that \"for simple tasks, like binary labels on objective tasks, the statistics are fairly straightforward to decide which is the 'correct' label when different annotators disagree. But for subjective tasks, or even objective tasks with continuous data, there are no simple heuristics for deciding what the correct label should be\"[42].\nSubjectivity is involved in both the generation and perception of information: the assumption that there is only one frame is complicated by the point of view of the reader. In the case of news, the information sender (the journalist) has an intention, but the receiver (the reader) plays a role and is influenced by it. In psychology, this is known as the lens model of interpersonal communication, where the sender has certain objectives, but the receiver can interpret or re-interpret what the sender wants to say, with more or less accuracy[26].\nFollowing this discussion on subjectivity, the question arose as to what would happen if, instead of headlines, we used the complete article as a source of analysis. We wondered if longer text could make the frame labeling task clearer than when using headlines. Yet another possible hypothesis is that having to read longer texts could lead to the same subject being presented from different angles. Please recall that in the existing literature discussed in Section 2, both headlines and full articles have been used from frame analysis (see Table1.) This remains as an issue for future work.\n7 CONCLUSIONS\nIn this paper, we first presented an analysis of human-generated news frames on the covid-19 no-vax movement in Europe, and then studied different approaches using large language models for automatic inference of frames. We conclude by answering the two research questions we posed: RQ1: What are the main frames in the news headlines about the covid-19 anti-vaccine movement in 5 European countries? After annotating the headlines, we found that of the 1786 headlines, the predominant frame is human interest (45.3% of cases), which presents a news item with an emotional angle, putting a face to a problem or situation. We also found that a substantial proportion of headlines were annotated as not presenting any frame (40.2% of cases). Finally, the other frame types are found more infrequently.\nRQ2: Can prompt engineering be used for classification of headlines according to frames? We first used fine-tuning of a number of language models, and found that GPT-3.5 produced classification accuracy of 72% on a six-frame classification task. This represented a modest 2% improvement over BERT-based models, at a significantly larger environmental cost. We then presented a new way of classifying frames using prompts. At the headline level, inferences made with GPT-3.5 reached 49% of agreement with human-generated frame labels. In many cases, the GPT-3.5 model inferred frame types that were considered as valid choices by human annotators, and in an post-doc experiment, the human-machine agreement reached 76%. These results have opened several new directions for future work.\n",
        "resume": "Identifying the frames of news is important to understand the articles' vision, intention, message to be conveyed, and which aspects of the news are emphasized. Framing is a widely studied concept in journalism, and has emerged as a new topic in computing, with the potential to automate processes and facilitate the work of journalism professionals. In this paper, we study this issue with articles related to the Covid-19 anti-vaccine movement. First, to understand the perspectives used to treat this theme, we developed a protocol for human labeling of frames for 1786 headlines of No-Vax movement articles of European newspapers from 5 countries. Headlines are key units in the written press, and worth of analysis as many people only read headlines (or use them to guide their decision for further reading.) Second, considering advances in Natural Language Processing (NLP) with large language models, we investigated two approaches for frame inference of news headlines: first with a GPT-3.5 fine-tuning approach, and second with GPT-3.5 prompt-engineering. Our work contributes to the study and analysis of the performance that these models have to facilitate journalistic tasks like classification of frames, while understanding whether the models are able to replicate human perception in the identification of these frames.",
        "authors": [
            "David Alonso",
            "Del Barrio",
            "Daniel Gatica-Perez"
        ],
        "keywords": [
            "Covid-19 no-vax",
            "news framing",
            "GPT-3",
            "prompt-engineering",
            "transformers",
            "large language models"
        ],
        "institutions": [
            "Daniel Gatica-Perez Idiap Research Institute",
            "Idiap Research Institute"
        ],
        "refrences": [
            "Justito Adiprasetio, Annissa Winda Larasati. Pandemic crisis in online media: Quantitative framing analysis on Detik. com's coverage of Covid-19 Jurnal Ilmu Sosial Dan Ilmu Politik 2020. 2020, 24, 153-170.",
            "Neel Alex, Eli Lifland, Lewis Tunstall, Abhishek Thakur, Pegah Maham, Jess Riedel, Emmie Hine, Carolyn Ashurst, Paul Sedille, Alexis Carlier. RAFT: A real-world few-shot text classification benchmark 2021. 2021, arXiv preprint, arXiv:2109.14076.",
            "David Alonso, Del Barrio, Daniel Gatica-Perez. How Did Europe's Press Cover Covid-19 Vaccination News? A Five-Country Analysis 2022. 2022, 10.1145/3512732.3533588, 35-43.",
            "Emily M Bender, Timnit Gebru, Angelina Mcmillan-Major, Shmargaret Shmitchell. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 2021. 2021, 610-623.",
            "Santosh Kumar, Nikhil Kumar. Artificial intelligence in journalism: A boon or bane? Optimization in machine learning and applications Springer 2020, 155-167.",
            "Erik Bleich, Hannah Stonebraker, Hasher Nisar, Rana Abdelhamid. Media portrayals of minorities: Muslims in British newspaper headlines, 2001-2012 Journal of Ethnic and Migration Studies 2015. 2015, 41, 942-962.",
            "Michael Bommarito, Daniel Martin Katz. GPT Takes the Bar Exam 2022, 10.48550/ARXIV.2212.14402.",
            "Meredith Broussard, Nicholas Diakopoulos, Andrea L Guzman, Rediet Abebe, Michel Dupagne, Ching-Hua Chuan. Artificial intelligence and journalism Journalism & Mass Communication Quarterly 2019. 2019, 96, 673-695.",
            "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell. Language models are few-shot learners Advances in neural information processing systems 2020. 2020, 33, 1877-1901.",
            "BjÃ¶rn Burscher, Daan Odijk, Rens Vliegenthart, Maarten De Rijke, Claes H De Vreese. Teaching the computer to code frames in news: Comparing two supervised machine learning approaches to frame analysis Communication Methods and Measures 2014. 2014, 8, 190-206.",
            "Bjorn Burscher, Rens Vliegenthart, Claes H De Vreese. Frames beyond words: Applying cluster and sentiment analysis to news coverage of the nuclear power issue Social Science Computer Review 2016. 2016, 34, 530-545.",
            "Dallas Card, Amber Boydstun, Justin Gross, Philip Resnik, Noah Smith. The Media Frames Corpus: Annotations of Frames Across Issues 2015. 01 2015, 10.3115/v1/P15-2072, 438-444.",
            "Daniel Catalan, Carlos ElÃ­as. Vaccine hesitancy in the age of coronavirus and fake news: analysis of journalistic sources in the Spanish quality press International Journal of Environmental Research and Public Health 2020. 2020, 17.",
            "Daniel CatalÃ¡n, Carmen PeÃ±afiel-Saiz. Media and mistrust of vaccines: a content analysis of press headlines Revista latina de comunicaciÃ³n social 2019. 2019, 74, 786-802.",
            "Mark Coddington. Clarifying journalism's quantitative turn: A typology for evaluating data journalism, computational journalism, and computer-assisted reporting Digital journalism 2015. 2015, 3, 331-348.",
            "D Stephen. The oppositional framing of bloggers Doing News Framing Analysis Routledge 2010, 151-172.",
            "Robert Dale. GPT-3: What's it good for? Natural Language Engineering 2021. 2021, 27, 113-118.",
            "Astrid Dirikx, Dave Gelders. To frame is to explain: A deductive frame-analysis of Dutch and French climate change coverage during the annual UN Conferences of the Parties Public Understanding of Science 2010. 2010, 19, 732-742.",
            "Astrid Dirikx, Dave Gelders. To frame is to explain: A deductive frameanalysis of Dutch and French climate change coverage during the annual UN Conferences of the Parties Public understanding of science 2010. 2010, 19, 732-742.",
            "Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, Graham Neubig. Gsum: A general framework for guided neural abstractive summarization 2020. 2020, arXiv preprint, arXiv:2010.08014.",
            "Sumayya Ebrahim. The corona chronicles: Framing analysis of online news headlines of the COVID-19 pandemic in Italy USA and South Africa. Health SA Gesondheid (Online) 2022. 2022, 27, 1-8.",
            "Hend Abdelgaber, Ahmed El-Behary. A Feverish Spring: A Comparative Analysis of COVID-19 News Framing in Sweden, the UK, and Egypt 2021. 2021.",
            "Framing: Towards clarification of a fractured paradigm. McQuail's reader in mass communication theory 1993. 1993, 390.",
            "Tianyu Gao, Adam Fisch, Danqi Chen. Making pre-trained language models better few-shot learners 2020. 2020, arXiv preprint, arXiv:2012.15723.",
            "Piyush Ghasiya, Koji Okamura. Investigating COVID-19 news across four nations: a topic modeling and sentiment analysis approach Ieee Access 2021. 2021, 9, 36645-36656.",
            "Robert Gifford. A Lens-Mapping Framework for Understanding the Encoding and Decoding of Interpersonal Dispositions in Nonverbal Behavior Journal of Personality and Social Psychology 1994. 02 1994, 66, 398-412.",
            "Quentin Grail, Julien Perez, Eric Gaussier. Globalizing BERT-based transformer architectures for long document summarization Proceedings of the 16th Conference of the European Chapter the Association for Computational Linguistics 2021, 1792-1810.",
            "Anushka Gupta, Diksha Chugh, Rahul Katarya. Automated news summarization using transformers Sustainable Advanced Computing Springer 2022, 249-259.",
            "Alfred Hermida, Mary Lynn. Finding the data unicorn: A hierarchy of hybridity in data and computational journalism Digital Journalism 2017. 2017, 5, 159-176.",
            "Karoliina Isoaho, Daria Gritsenko, Eetu MÃ¤kelÃ¤. Topic modeling and text analysis for qualitative policy research Policy Studies Journal 2021. 2021, 49, 300-324.",
            "Carina Jacobi, Wouter Van Atteveldt, Kasper Welbers. Quantitative analysis of large amounts of journalistic texts using topic modelling Digital journalism 2016. 2016, 4, 89-106.",
            "Zhengbao Jiang, Frank F Xu, Jun Araki, Graham Neubig. How can we know what language models know? Transactions of the Association for Computational Linguistics 2020. 2020, 8, 423-438.",
            "Shima Khanehzar, Andrew Turpin, Gosia MikoÅajczak. Modeling Political Framing Across Policy Issues and Contexts 2019, In ALTA.",
            "Jeesun Kim, Wayne Wanta. News framing of the US immigration debate during election years: Focus on generic frames The Communication Review 2018. 2018, 21, 89-115.",
            "Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar. Holistic evaluation of language models 2022. 2022, arXiv preprint, arXiv:2211.09110.",
            "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing 2021. 2021, 10.48550/ARXIV.2107.13586.",
            "Siyi Liu, Lei Guo, Kate Mays, Margrit Betke, Derry Tanti. Detecting frames in news headlines and its application to analyzing news framing trends surrounding US gun violence Proceedings of the 23rd conference on computational natural language learning (CoNLL) 2019.",
            "JÃ¶rg Matthes, Matthias Kohring. The Content Analysis of Media Frames: Toward Improving Reliability and Validity Journal of Communication 2008. 06 2008, 58.",
            "Selina Meyer, David Elsweiler, Bernd Ludwig, Marcos Fernandez-Pichel, David E Losada. Do We Still Need Human Assessors? Prompt-Based GPT-3 User Simulation in Conversational AI Proceedings of the 4th Conference on Conversational User Interfaces 2022, 1-6.",
            "Social computing for verifying social media content in breaking news Symeon Papadopoulos, and Yiannis Kompatsiaris 2018. 2018, 22, 83-89.",
            "Marko MilosavljeviÄ, Igor VobiÄ. Our task is to demystify fears': Analysing newsroom management of automation in journalism Journalism 2021. 2021, 22, 2203-2221.",
            "R Monarch. Human-in-the-Loop Machine Learning: Active Learning and Annotation for Human-centered AI 2021.",
            "Tom Nicholls, D Pepper. Computational identification of media frames: Strengths, weaknesses, and opportunities 2021. 2021, 38, 159-181.",
            "Zhongdang Pan, Gerald M Kosicki. Framing analysis: An approach to news discourse Political communication 1993. 1993, 10, 55-75.",
            "Raul Puri, Bryan Catanzaro. Zero-shot text classification with generative language models 2019. 2019, arXiv preprint, arXiv:1912.10165.",
            "Guanghui Qin, Jason Eisner. Learning how to ask: Querying lms with mixtures of soft prompts 2021. 2021, arXiv preprint, arXiv:2104.06599.",
            "Rabindra Lamsal. Sentiment Analysis of English Tweets with BERTsent 2021.",
            "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever. Language models are unsupervised multitask learners OpenAI blog 2019. 2019, 1.",
            "Nishant Rai, Deepika Kumar, Naman Kaushik, Chandan Raj, Ahad Ali. Fake News Classification using transformer based enhanced LSTM and BERT International Journal of Cognitive Computing in Engineering 2022. 2022, 3, 98-105.",
            "Frida V Rodelo. Framing of the Covid-19 pandemic and its organizational predictors Cuadernos. info 2021. 2021, 50, 91-112.",
            "Le Teven, Angela Scao, Christopher Fan, Ellie Akiki, Suzana Pavlick, Daniel IliÄ, Roman Hesslow, Alexandra CastagnÃ©, FranÃ§ois Sasha Luccioni, Matthias Yvon. Bloom: A 176b-parameter open-access multilingual language model 2022. 2022, arXiv preprint, arXiv:2211.05100.",
            "Holli Semetko, Patti Valkenburg. Framing European Politics: A Content Analysis of Press and Television News Journal of Communication 2000. 06 2000, 50, 93-109.",
            "Richard Shin, Sam Christopher H Lin, Charles Thomson, Subhro Chen, Emmanouil Roy, Adam Antonios Platanios, Dan Pauls, Jason Klein, Benjamin Eisner. Constrained language models yield few-shot semantic parsers 2021. 2021, arXiv preprint, arXiv:2104.08768.",
            "Efstathios Sidiropoulos, Andreas Veglis. Computer Supported Collaborative Work trends on Media Organizations: Mixing Qualitative and Quantitative Approaches Studies in Media and Communication 2017. 2017, 5, 04.",
            "Emma Strubell, Ananya Ganesh, Andrew Mccallum. Energy and policy considerations for deep learning in NLP 2019. 2019, arXiv preprint, arXiv:1906.02243.",
            "Alex Tamkin, Miles Brundage, Jack Clark, Deep Ganguli. Understanding the capabilities, limitations, and societal impact of large language models 2021. 2021, arXiv preprint, arXiv:2102.02503.",
            "H Trieu, Quoc V Trinh. A simple method for commonsense reasoning 2018. 2018, arXiv preprint, arXiv:1806.02847.",
            "Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, Oriol Eslami, Felix Vinyals. Multimodal few-shot learning with frozen language models Advances in Neural Information Processing Systems 2021. 2021, 34, 200-212.",
            "A Sandra, Prashant Vannoy. The social influence model of technology adoption Commun. ACM 2010. 2010, 53, 149-153.",
            "Tuukka YlÃ¤-Anttila, Veikko Eranti, Anna Kukkonen. Topic modeling for frame analysis: A study of media debates on climate change in India and USA Global Media and Communication 2022. 2022, 18, 91-112."
        ],
        "created_at": "2024-02-01T13:52:46.721582+00:00",
        "updated_at": "2024-02-01T13:53:09.650847+00:00"
    },
    {
        "id": 6,
        "title": "A Prototype Implementation of an Orthographic Software Modeling Environment",
        "body": "1. INTRODUCTION\nOrthographic Software Modeling (OSM) is based on three fundamental hypotheses -(a) that it is feasible to integrate the many different kinds of artifacts used in contemporary software engineering methods within a single coherent methodology in which they are treated as views, (b) that it is feasible to create an efficient and scalable way of supporting these views by generating them dynamically, on-the-fly, from a Single Underlying Model (SUM) using model-based transformations and (c) that it is feasible to provide an intuitive metaphor for navigating around these many views by adapting the orthographic projection technique underpinning the CAD tools used in other engineering disciplines. As shown in Figure1, the main advantages of using the idea of orthographic projection to define the views used to visualize and described a system are that they (a) can be organized according to a simple and easy-to-understand metaphor and (b) collectively represent all the properties of a system with minimal overlap and redundancy. In practice this translates into a set of \"dimensions\", each containing well defined choices (or so called \"dimension elements\") that can be used to select individuals views.\nAs shown in Figure2, the main advantage of making the artifacts used to describe a software system views of a SUM is that the number of pairwise coherence relationships that have to be maintained is reduced and new views can be introduced by simply defining their relationship to the SUM. Moreover, the importance of this advantage grows quickly as the size of the system and the complexity of the deployed development methodology increase. Another important advantage is that the dominance of one particular kind of view over the development process (e.g. code) at the expense of other kinds of views (e.g. graphical models) is reduced so that any appropriate type of views can be used to enrich the underlying description of the system, depending on the needs and skills of the stakeholder involved. This makes it possible to subsume all view types under the same, overarch-SUM SUM / View Centric Environment Artifact / Tools Centric Environment ing development process and methodology (e.g. agile-driven, focusing on small development cycles, or model-driven development, based on transformations between abstraction levels). Although the details of how the views are created from the SUM and how the SUM is updated from the views are not central to the approach, a natural implementation is to use the visualization and transformation technologies offered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the University of Mannheim we have been developing a prototype OSM modeling environment based on an enhanced version of the KobrA method for model-driven, component-oriented development, KobrA 2.0[1]. This was chosen as a basis for the prototype, known as the Open, Adaptable, Orthographic Modeling Environment (nAOMi)[13]because its views were designed with the precise goals of being (a) genuine projections of a subject containing carefully selected subsets of information about that subject, (b) minimalistic in the sense that they should overlap to the smallest extent possible and contain the minimum necessary models elements, and (c) selectable via a set of independent \"dimensions\" which reflect different fundamental concerns of development (i.e. abstraction levels, composition or variants). In other words, KobrA already provided one of the \"most orthogonal\" sets of views for visualizing software systems of any contemporary method. More details about the actual views and dimensions defined in KobrA are presented in the following sections. More information on OSM can be found in[2]and[3].\nnAOMi is implemented as an Eclipse plugin using the Eclipse Modeling Framework (EMF) as the underlying modeling platform and UML 2.0 tools[4]to generate and edit views. The KobrA 2.0 metamodel on which the current version of nAOMi is based is a specialization of the UML metamodel composed of three separate packages -one for the SUM, one for the views and one for the transformations (Figure3). The UML was chosen as the base language because of its maturity and widespread acceptance, making the environment usable to the largest possible body of developers. UML elements not needed in KobrA 2.0 are excluded using OCL constraints while new elements or properties are introduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on the structure of the KobrA 2.0 metamodel and how it is used to drive nAOMi. The three following sections each focus on one of the three main components of the metamodel -the SUM, the views and the transformations . This is followed by a brief overview of the OSM navigation paradigm in Section 5 before a small example of the approach is presented in Section 6. Section 7 then concludes the paper with related and future work.\n2. SUM PACKAGE\nFigure4depicts the internal structure of the SUM package which is based on the UML metamodel. There are three main subpackages, two containing the structural and behavioral constructs respectively, and one containing the constraints that ensure that the metaclasses are used according to the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains some of the most fundamental elements of the KobrA metamodel, such as Class and ComponentClass. The internal structure of this package is illustrated in Figure5. Com-ponentClass represents objects with complex and reusable behaviors, while Class captures simple \"data type\" objects that have only very simple or non-reusable behaviors. The modeler has to decide whether it is necessary to model a specific part of the system as a ComponentClass and include state charts and activity diagrams, or whether it is sufficient to use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Communications so it also has the isActive attribute. This makes it possible to model whether its instances are active or passive. Active objects, which can be used to model threads and processes([8]p. 438), start to execute their behavior as soon as they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-brA, this behavior may be specified in the form of UML State Diagrams (defining acceptable operation invocation sequences), and in the form of Activities (defining algorithms of operations). UML Interaction elements (in sequence diagrams) can be derived from the activity elements and thus are not included in the SUM. As KobrA aims to facilitate automatic checking of allowed sequences of operation calls, Protocol State Machines are supported instead of general state machines. Since the latter include a large variety of elements not needed for specifying acceptable operation se-quences or automatic checking, OCL constraints are used to prohibit the use of unwanted features. For example, since KobrA has no concept of roles for components, the use of role also needs to be prohibited. The part association refers to owned properties of components whose attribute isComposite is true. As KobrA uses associations like nests and creates for components, part, required and provided are not needed. Connectors (i.e. delegation and assembly) are not used in KobrA either so ownedConnector is excluded.\n3. VIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure6. Again, since most of the views defined in KobrA 2.0 are based on UML diagrams, the view metamodels have similar elements to the SUM metamodel. The big difference to the SUM is that there are no restrictions on the use of the view metamodel elements. For instance, views for a particular purpose such as supporting model checkers can be supported by adding elements unrelated to the UML.\nThe substructure of the Views package reflects the types and organization of the KobrA views according to the view \"dimensions\" supported in nAOMi (cf. example inSection 6). At the top level, the Views package is thus decomposed into the Specification and Realization options of the encapsulation dimension. These, in turn are both decomposed into the Structural, Behavioral and Operational options of the Projection dimension. Finally, with the exception of the behavioral option, these are also all subdivided into the Service and Type options of the granularity dimension. This dimension, with its two options, is an addition to the original version of KobrA.\nThe Service view shows the direct, publicly visible relationships of the subject ComponentClass to other Compo-nentClasses, while the Type view shows the publicly visible relationships of the subject to simple Classes. As with the SUM, constraints have been defined to control what can go into each view and when they are well formed. For every view, a constraint enumerates all allowed elements (not shown in this paper).\nIn the following, some of the other constraints for the Service view are elaborated. Since this view is a black-box view, the internals of ComponentClasses (nestedClassifier ) are not shown.\ncontext ComponentClass --no nested classifiers , no protocol inv : nestedClassifier -> union ( protocol ) -> isEmpty () Classes are only allowed if they are generalizations of Com-ponentClasses, (or any of its superclasses, since a Compo-nentClass may inherit from a class as shown in the constraints with context Class. The following invariants ensure that only publicly visible attributes and operations are in this view, for both classes and ComponentClasses (which inherit from Class). Only operation signatures are shown in this view, so pre-, post-and bodyconditions, as well as activities are omitted, which is reflected in the last constraint.\ncontext Operation --only the signature of the Operation is shown , not its behavior ( role name \" method \" refers to the Activities of the operation ) , or dependencies inv : method -> union ( precondition ) -> union ( body ) -> union ( postcondition ) -> isEmpty ()\n4. TRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for specifying the transformations between the SUM and the views in both directions. Part of the package's contents are shown in Figure7. The Abstraction concept (which is in fact a dependency reused from the UML but with additional constraints) plays the key role in relating elements from the SUM to elements of a view. Abstraction is actually mapped to ExpressionInOcl. When appearing in transformations, the equals sign links elements in the SUM to the respective elements in the view, and vice versa. For instance, equality of the general meta-association of a Generalization in a transformation invariant means that, when following general, there must be an element in the SUM and in the view for which similar transformation expressions are specified.\nIn the case of KobrA 2.0, which has many projections that just select a subset of elements using one-to-one abstractions, this allows concise declarative TransformationExpressions. Together with the view constraints, a CASE tool can be implemented which uses a transformation language of the implementor's choice, for instance the Atlas Transformation Language (ATL)[11]or QVT[9]. The role names se and ve are short for SumElement and ViewElement, respectively. These roles subset the client and supplier roles from the UML. SUM elements are translated into UML elements with stereotypes, so that the views are easy to manage for developers familiar with the UML. The bidirectional mappings between stereotyped view elements and non-stereotyped SUM elements are expressed in the constraints of the Association-Abstraction, a subclass of the Abstraction from the AllViews package. This is also an example of a transformation which is reused in other views. Figure8shows the main elements involved in the transformation of the black box structural view for Component-Classes. The first transformation constraint is on the view and declares the starting point for the transformation. It states that the subject ComponentClass and its generalizations (using a SUM utility function, superClosure) are in the view.\nThe following transformation rules illustrate how to create the output (i.e. view) elements from the input (i.e. SUM) elements, such as the publicly visible attributes and operations of the ComponentClass and the acquired ComponentClasses. The first constraint for ComponentClassAbstraction states that references to potential general classes (and Component-Classes) of ComponentClasses are mirrored in the view. In addition, ComponentClasses will be shown with the corresponding stereotypes. The ComponentClass owns various types of associations, so in this view only the acquires associations are selected (whose transformation rules are covered in the common transformation packages).For classes and ComponentClasses, only publicly visible attributes and operations appear in the view. Class invariants are also copied. Classes that may appear in this view (e.g. as generalizations of ComponentClasses) may have a powertype (role name powertypeExtent) which will be displayed.\nThe last transformation statement copies the class references of operations. As with all views, the transformation rules, the common transformation statements (which also cover operations) and the view constraints serve as a specification for the implementation of a view. Individual CASE tools can use different implementation techniques as long as they conform to the semantics of these rules and constraints.  For the black box type view, only publicly visible attributes and operations of classes (as opposed to Compo-nentClasses) used by the subject can be seen. This is specified in the first rule which defines owned members of the view and thus serves as the starting point of the transformation. cbbTypes is a utility function defined in the SUM which computes the black box types by selecting the types of the subject's public attributes and parameter types of its public operations.\nClass invariants and potential powertypes and connections to the classes in this view are shown as well. There may also be Enumerations, for which the EnumerationLiterals are displayed.\nThe transformation rules for this view are almost the same as the realization transformation constraints from the package Transformation::Realization::Structural::Class::Type. The differences are the select(visibility=#public) statements for operations and attributes. s t r i n g I n S i g n a t u r e\n5. NAVIGATION\nMost of today's tools use some combination of trees to organize the content of models as well as the views used to visualize a software system or component. In an any environment incorporating a number of different tools there is invariably a large number of different trees storing a heterogeneous mix of artifacts including model elements (e.g. classes, instances, associations), diagrams (e.g. class diagrams, state diagrams) and other artifact types (source code, XML files, configuration files ). To work with all the views in a traditional development environment, therefore, engineers typically have to learn about the organization structures of all the incorporated tools.\nIn contrast to conventional paradigms for organizing and navigating the many views used to visualize a system, OSM employs the metaphor of a multi-dimensional cube. More specifically, as illustrated in Figure9, OSM regards dimension of the underlying methodology as representing a different dimension of the cube, and each independently variable aspect of that dimension is a selectable dimension element. Selecting a view thus simply corresponds to selecting a single cell within the cube. In general, three types of dimensions are supported: static dimensions in which the number of selectable elements (i.e. coordinates) is fixed, dynamic dimensions in which the number of elements is dynamic (i.e. derived from the SUM), and mixed dimensions which have both static and dynamic elements.\nTo support the OSM dimension based navigation metaphor for KobrA, we defined the seven dimensions indicated on the left hand side of Figure10which is a sceenshot of nAOMI. The Abstraction dimension (not expanded here), which has three static dimension elements, PIM (platform independent model), PSM (platform specific model) and Code, captures the model-driven development concern of KobrA. The version dimension captures the state of the modeled system at specific points in time. The Component dimension, which has dynamic dimension elements defined by instances of the class ComponentClass in the SUM, captures the componentbased development concern of KobrA.\nThe Encapsulation dimension, which has two fixed elements, supports the distinction between Specification (black box) and Realization (white box) views of components, while the Projection dimension with the fixed elements Structural, Operational and Behavioral covers the different information types. The Granularity dimension provides a finer grained distinction between views describing the types used by components (Type granularity) and views describing the required and provided interfaces (Service granularity). The Operation dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the choices that can be made in each dimensions are completely independent. However, this is very difficult to achieve in software engineering. The approach still works if the views are not completely orthogonal, but dependencies then occur between different choices in different dimensions, so that the decisions made in one dimensions may affect choices possible in another dimension. This is best handled by giving dimensions a precedence ranking determined by the order in which they appear (the top being the highest). When an element in a dimension is selected, the tool automatically makes default selections for dimensions of lower precedence (i.e. dimensions lower down) and disables selections that would navigate to cells (i.e. views) which are not (yet) defined by the method at hand.\n6. SHOPPING CART EXAMPLE\nTo show how a software system can be specified using nAOMi, this section presents a case study based on a shopping cart system. A ShoppingCart component collects and manages the products selected by users and supports payment via a credit card. Figure10illustrates a structural view of the component.\nIn the dimension navigator on the left hand side, PIM was chosen for the \"Abstraction Level\" (not expanded in the screenshot). The second dimension is the state of the software system at a certain point in time. The picture shows that the latest available version was chosen. As with every choice in a dimension, it may influence the options in lower ranked dimensions. The component under consideration is the ShoppingCart, for which a black box view is selected in the next dimension. After the user selects the structural projection option and the service level granularity, the tool automatically chooses the option for all operations in the last dimension, as there is no editor registered for the other options.\nThe component under development is presented with the stereotype subject and its relationship to other components and classes is shown in the view, which corresponds to a cell of the multi-dimensional navigation cube, and is generated on-the-fly from the SUM when it is selected. The classes Product and CreditCard can be used as data types in the operations of the component.\nFigure11illustrates the operational view in which an operation can be formalized using pre-and postconditions. The precondition corresponds to the assumes clause in and the postcondition corresponds to the result clause. As in the UML, the precondition of an operation must be true when the operation is invoked and the postcondition must be true when the operation is finished. The operation addProduct in Figure11must be in state CollectingProducts or Empty when invoked. This is also visible in the behavioral view, since there are only two transitions with the operation ad-dProduct. Both leads to the state CollectingProducts which is also a postcondition of the operation. The second postcondition is that the cost attribute of the component must be increased by the price of the added product. The pre-and postcondition can be expressed using the OCL. The properties of the component, states and operation parameters can be used to formalise the constraints like as in this example.\nFigure12shows the publicly visible behaviour of the Shop-pingCart component with states and transitions. The conditional transitions map to operations of the component. Like every view, this view is also synchronized with the SUM so that it is guaranteed that its operations, states and properties are consistent with those in the structural view. Although the operational view seems to be similar to the behavioral view because of the overlapping information within them, there are significant differences. The focus of the operational view is on a precise formal definition of an operation of a component. The operations can be enriched by preand postconditions which can be defined using complex OCL statements, that formalize the complete behavior of an operation. The additional information in the OCL statements can be used for code generation and documentation.\n7. CONCLUSION\nAt the beginning of the paper we identified three fundamental hypothesis upon which the notion of OSM is based -(a) that it is feasible to integrate the many different kinds of artifacts used in contemporary software engineering methods within a single coherent methodology in which they are treated as views, (b) that it is feasible to create an efficient and scalable way of supporting these views by generating them dynamically, on-the-fly, from a Single Underlying Model (SUM) using model-based transformations and (c) that it is feasible to provide an intuitive metaphor for navigating around these many views by adapting the orthographic projection technique underpinning the CAD tools used in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper represents the first step towards demonstrating the validity of these hypotheses and showing that OSM is a viable approach to software engineering. Of the three hypotheses, (a) and (c) are most convincingly demonstrated by the prototype, since it shows that it is indeed possible to support all the views of the KobrA method within a single navigation metaphor. The prototype tool does not demonstrate the validity of hypothesis (b) to the same extent as the others due to its small size. Although it demonstrates the feasibility of generating views from the SUM and vice-versa, the question of whether such an approach scales up to large environments is still open.\nAlthough nOAMi is the only tool developed with the specific aim of supporting KobrA-based OSM, several other tools and methods have similar properties or aims. For example, Glinz et al.[10]describe a tool with a fisheye zooming algorithm which lets the user view a model with varying amounts of detail depending on the context. It has to be investigated whether it is possible to combine the fisheye zooming concept with the dimension-based navigation paradigm. While the KobrA 2.0 implementation of nAOMi heavily uses UML diagrams for developers, Glinz et al. use custom diagram types, e.g. for structural and behavioral views.\nAn approach which also emphasizes the description of formal consistency rules (correspondences) between views is RM-ODP[5][6]. However, this approach does not explicitly mention the notion of a SUM and thus implies that consistency rules should be defined in a pairwise fashion between individual pairs of views. ArchiMate[7], which complements TOGAF[12], is an enterprise architecture modeling language which offers two orthogonal \"dimensions\" for modeling, (business, architecture, and technology) layers and (informational, behavioral and structural ) aspects and also suggests two more dimensions, purpose and abstraction level. However, as many of these views span multiple choices of a single \"dimension\", the intuitive dimension-based navigation metaphor of OSM can not be easily applied. There are also more general approaches for view-based modeling but they are less specific in terms of consistency rules between views and provide little guidance on how to manage and navigate views, for example the Zachman Framework[14].\nRegarding the practical use of OSM environments in the future, the biggest challenge is developing appropriate SUM metamodels which can accommodate all the types of views and services that software engineers are accustomed to today. For this first prototypical SUM-based environment supporting the OSM approach we had a method at our disposal (KobrA) that already defined a full set of orthogonal UMLbased views. This allowed us to model the required SUM and view metamodels by simply adapting the UML metamodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the metamodels fulfilled the two core requirements of SUM-based environments -(1) being minimalistic and (2) redundancy free. If SUM-based software engineering environments are to take off, and to be introduced into existing, heterogeneous environments, more sophisticated ways of integrating existing metamodels into a single unified metamodel will be required.\n",
        "resume": "Orthographic Software Modeling (OSM) is a view-centric software engineering approach that aims to leverage the orthographic projection metaphor used in the visualization of physical objects to visualize software systems. Although the general concept of OSM does not prescribe specific sets of views, a concrete OSM environment has to be specific about the particular views to be used in a particular project. At the University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views defined by the KobrA 2.0 method, a version of KobrA adapted for OSM. In this paper we provide an overview of the KobrA 2.0 metamodel underpinning nAOMi and give a small example of its use to model a software system.",
        "authors": [
            "Colin Atkinson",
            "Dietmar Stoll",
            "Christian Tunjic",
            "Jacques Robin"
        ],
        "keywords": [
            "D.1.7 [Programming Techniques]: Visual Programming"
        ],
        "institutions": [
            "Universidade Federal de Pernambuco",
            "University of Mannheim"
        ],
        "refrences": [
            "C Atkinson, J Bayer, C Bunse, E Kamsties, O Laitenberger, R Laqua, D Muthig, B Paech, J WÃ¼st, J Zettel. Component-Based Product Line Engineering with UML Addison Wesley November 2001, 1st edition.",
            "C Atkinson, D Stoll, P Bostan. Orthographic Software Modeling: A Practical Approach to View-Based Development Evaluation of Novel Approaches to Software Engineering Springer 2010, 69, 206-219.",
            "C Atkinson, D Stoll, C Tunjic. Orthographic Service Modeling Proceedings of 15th IEEE EDOC Conference Workshops (EDOCW) 2011.",
            "Eclipse Foundation. UML2Tools 2013.",
            "/ Iso, Itu-T ; Rm-Odp Iec, Itu-T Rec. The Reference Model of Open Distributed Processing 1998, 901-X.904 / ISO/IEC 10746.",
            "J I J Jose, Raul Romero, A Vallecillo. Realizing Correspondences in MultiViewpoint Specifications Proceedings of the Thirteenth IEEE International EDOC Conference 1 -4 September 2009. September 2009.",
            "M Lankhorst. Enterprise Architecture at Work Springer 2009.",
            "OMG Unified Modeling Language (OMG UML), Superstructure, V2.1.2 November 2007.",
            "Meta Object Facility (MOF) 2.0 Query/View/Transformation April 2008.",
            "C Seybold, M Glinz, S Meier, N Merlo-Schett. An effective layout adaptation technique for a graphical modeling tool Proceedings of the 2003 International Conference on Software Engineering 2003.",
            "The Atlas Transformation Language (ATL). Official Website 2013.",
            "TOGAF Version 9 -The Open Group Architecture Framework Feb 2009.",
            "nAOMi -opeN, Adaptable, Orthographic Modeling EnvIronment .",
            "J A Zachman. The Zachman Framework: A Primer for Enterprise Engineering and Manufacturing 2009."
        ],
        "created_at": "2024-02-01T13:38:13.534529+00:00",
        "updated_at": "2024-02-01T13:38:20.873058+00:00"
    },
    {
        "id": 5,
        "title": "Towards a Quantum Software Modeling Language",
        "body": "1 INTRODUCTION\nQuantum computation rose to prominence after the discovery of quantum algorithms[5,7]that can efficiently perform tasks that are intractable classically. These discoveries propelled research and interest in quantum computation. Today, there exists prototype quantum hardware with computational capabilities beyond that of any classical machine[1]. Further applications of quantum theory to computation have also been made in several areas of theory of computing, such as models of computation[6], data structures[8], and cryptography[2].\nQuantum computation has, until today, been studied almost exclusively 'in the small.' A general understanding of quantum computation, or, quantum programming 'in the large' is yet to be developed. Here we aim to set the foundations of a general framework for studying, developing, and conveying quantum programs. We aim to do so by developing a universal modeling language for quantum software. Rather than develop such a language from scratch, we have decided to start from the well-known Unified Modeling Language (UML)[3], and introduce a minimum set of extensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which we can build, allows us to convey our original extensions much more succinctly. Our extension set can, however, be applied with little or no modification to any other modeling language.\n2 Q-UML\nBefore discussing in depth the extensions we are introducing, we make a few fundamental observations on which we base the guiding principles for our extension set.\nOur first observation is about the nature of quantum computation. The central difference between quantum and classical computation is in how it achieves its goals. Quantum computers have access to quantum algorithms[7], and quantum data-structures[8], that are unavailable to classical computers-hence their performance advantage. Algorithms and data-structures are, however, implementation details. Algorithms are an essential design choice while programming in the small. However, they are more often than not completely ignored in large-scale software architectural design. For instance, UML diagrams seldom portray algorithms and data-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces nothing to computation that needs to be captured in a software design diagram. This is not the case, and the reason for this is our second observation. Quantum computation changes the very nature of information itself. Quantum information is much richer than classical information. It is also much more challenging to store, transmit, and receive. If a module (class, object, etc.) needs to store, transmit or receive quantum information, then this is an important design consideration-which needs to be included in any effective software design.\nA third observation here is that the classical vs. quantum nature of the information used by a module is an important consideration both when discussing its internal implementation and its interface. Furthermore, these two are separate and independent considerations.\nA classical module, implementing some classical behavior, would have no need, or capability, to communicate quantum data. A quantum module may or may not have to; i.e. a module's quantum behavior may be completely part of its internal implementation and not appear as part of its interface. For instance, take a module implementing Shor's algorithm. Shor's algorithm uses quantum effects to efficiently factor a large integer into its prime factors. The implementation of this module must necessarily be quantum. Both the input (the large integer) and the output (the prime factors), consist of classical information. And hence, the interface of such a module can be strictly classical.\nMore generally, we can conceive of quantum software modules that have all classical inputs and outputs (like the above example), all quantum inputs and outputs, or a mix of both. A quantum software design must address, for each individual interface element, whether it is classical input/output, or if it is quantum. In short, whether a module communicates classically or via quantum information, and whether its internal implementation requires quantum hardware are important considerations that need to be captured in a design document.\nThe importance of such labelling should be clear. Quantum data can only be stored and transmitted with special hardware designed to do so. More importantly, from an abstract, device-independent, strictly software perspective: quantum and classical information are not interchangeable. Classical information is clone-able and admits fanout operations, while quantum information (in general) does not. On the other hand, quantum information has a much larger state-space.\nFinally, it is true that quantum information is strictly a super-set of classical information-and hence a quantum module can communicate any classical information it desires using a quantum interface element. We argue, however, that using a quantum interface element and messaging when classical would suffice is bad quantum software design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software modeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes use of quantum information, either as part of its internal state/implementation, or as part of its interface, this must be clearly established in a design document. (3) (Quantum Supremacy): A module that has at least one quantum element is to be considered a quantum software module, otherwise it is a classical module. Quantum and classical modules should be clearly labelled as such. (4) (Quantum Aggregation): Any module that is composed of one or more quantum modules will itself be considered a quantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical modules can communicate with each other as long as their interfaces are compatible, i.e. the quantum module has classical inputs and/or outputs that can interface with the classical module. We will argue in Sec. 2.3 how these extensions are not only necessary, but also sufficient in order to design and represent quantum software. First, in the following two sections we put these principles into practice as a set of concrete extensions to UML.\n2.1 Class Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning in a very small amount of space. As such, it makes sense to use a graphical way to represent quantum software elements. We chose to do this by use of bold text to denote quantum elements, and double lines to denote a quantum relationship or quantum communication. For attributes, the name will be bold if it is represented using quantum information. For methods, we use the following convention. If any of the inputs are quantum, these are bold. If the output or datatype of the method is quantum, then the datatype should also be bold. For backwards compatibility with regular UML, whenever the input or output datatypes of a method are omitted, these will be assumed to be classical in nature. If a class/object has any quantum attributes or methods then it itself is considered quantum, and its name shall also be bold.\nRelationships between classes will use double-lines whenever the relationship is quantum in nature. For inheritance, if the superclass is quantum then the subclass, and the inheritance relationship, will also be quantum. (the converse is not necessarily true however). In the case of aggregation and composition, if a class/object being aggregated/composed is quantum, then the class/object to which it is aggregated/composed into, as well as that relationship will also be quantum. Association relationships do not have any special rules, beyond the need of a quantum class/object to have a classical interface if it is to associate with classical classes/objects. Fig.1showcases a Q-UML diagram that exemplifies the above rules.\n2.2 Sequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic relationship between modules in a software program. As we did before for static relationships, we extend the existing language in order to allow us to differentiate between classical and quantum messages. As previously discussed, this is essential information. Quantum information behaves differently from classical information; it can store/portray different data; it admits different operations; and, it requires different hardware to store, send, and receive. Like before, we make use of bold text to markup quantum modules, and double lines to portray quantum messages. Fig.2shows a Q-UML sequence diagram. Note how even though the relationship between Shorfactor and ShorOrder is quantum, the messaging between them is not. This illustrates an important point. A module is marked as quantum if it uses quantum resources in any form, either directly as part of its internal implementation or as part of an aggregated module. If a sub-module (in UML a composed class or object) is quantum, then the encompassing module must also be marked as quantum. In a static (e.g. class) diagram, the quantum composition relationships inform us-especially in the case of a seemingly classical module that does not in itself use quantum resources-which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder and QFT_n. The module QFT_n operates on a quantum state. Hence, both 'set' messages are quantum. Likewise, the return messages Ï and Ï are quantum states. However, the request to perform a quantum Fourier transform (QFT) or a QFT inverse operation can (and therefore should) be communicated classically. This diagram showcases the level of granularity available to us using these diagrams with the proposed extensions.\n2.3 Discussion\nWe have proposed a minimal series of extensions to existing software modeling languages. We exemplify our additions in UML, but these extensions are easily applicable to any other modeling language, or be used as the basis for a new modeling language.\nWe've argued the necessity of each of the extensions in previous sections. We can argue as well, that these extensions are not only necessary, but also sufficient to fully model quantum software. To make this argument, we appeal to the fact that all quantum computation is simulable using classical computation albeit with an efficiency loss. Other than their use of quantum information and algorithms, quantum computers are indistinct from classical ones. Hence, from a high-level design perspective, the only information element that needs to be considered when developing quantum software is when quantum (rather than classical) information is being used.\nThe one remaining information element we have not discussed is algorithm efficiency. If quantum computation is to be used, it will most likely be due to the efficient algorithms at its disposal. That said, algorithm efficiency is not a solely quantum consideration. UML itself does not inherently have language elements for algorithm efficiency (beyond user-defined notes). It does, however, have several extensions used and proposed for this purpose(see e.g.[4]). Other modeling languages may also have definite algorithm efficiency elements. We argue that it is best to use existing language elements when they are available.\n",
        "resume": "We set down the principles behind a modeling language for quantum software. We present a minimal set of extensions to the wellknown Unified Modeling Language (UML) that allows it to effectively model quantum software. These extensions are separate and independent of UML as a whole. As such they can be used to extend any other software modeling language, or as a basis for a completely new language. We argue that these extensions are both necessary and sufficient to model, abstractly, any piece of quantum software. Finally, we provide a small set of examples that showcase the effectiveness of the extension set.",
        "authors": [
            "Carlos A PÃ©rez-Delgado",
            "Hector G Perez-Gonzalez"
        ],
        "keywords": [
            "CCS CONCEPTS",
            "Design",
            "Unified Modeling Language (UML)",
            "Software design engineering"
        ],
        "institutions": [
            "Universidad AutÃ³noma de San Luis PotosÃ­ San Luis PotosÃ­",
            "University of Kent Canterbury"
        ],
        "refrences": [
            "Frank Arute. Quantum supremacy using a programmable superconducting processor Nature 2019. 2019, 574, 505-510.",
            "H Charles, Gilles Bennett. Quantum cryptography: public key distribution and coin tossing Theor. Comput. Sci 2014. 2014, 560, 7-11.",
            "Grady Booch, James Rumbaugh, Ivar Jacobson. Unified Modeling Language User Guide, The Addison-Wesley Professional 2005, nd Edition.",
            "C Canevet, S Gilmore, J Hillston, M Prowse, P Stevens. Performance modelling with the Unified Modelling Language and stochastic process algebras IEE Proceedings -Computers and Digital Techniques 2003. March 2003, 150, 2, 107-120.",
            "K Lov. A Fast Quantum Mechanical Algorithm for Database Search Proceedings of the Twenty-eighth Annual ACM Symposium on Theory of Computing (STOC '96) ACM 1996, 212-219.",
            "Carlos A PÃ©rez-Delgado, Donny Cheung. Local unitary quantum cellular automata Phys. Rev. A 2007. Sep 2007, 76, 32320-32323.",
            "W Peter. Algorithms for quantum computation: Discrete logarithms and factoring Proceedings 35th annual symposium on foundations of computer science Ieee 1994, 124-134.",
            "Liming Zhao, Carlos A PÃ©rez-Delgado, Joseph F Fitzsimons. Fast graph operations in quantum computation Phys. Rev. A 2016. Mar 2016, 93, 32314-32317."
        ],
        "created_at": "2024-02-01T13:37:42.913816+00:00",
        "updated_at": "2024-02-01T13:37:48.409614+00:00"
    },
    {
        "id": 4,
        "title": "How to Teach Software Modeling",
        "body": "1. INTRODUCTION\nSoftware engineering education at universities faces a common problem; that is regular students do not usually have experience of developing software for practical use and thus are not motivated for software engineering aiming at high quality software production by a project team or a persistent organization. Software projects conducted by students simulating real scale software development may help enhance students' motivation, although it requires a lot of efforts to prepare such projects and manage them.\nAnother way of solving this problem is to teach those who already have real experience in industry. In our case, there are currently five Ph. D. students under the author's supervision who are working at companies as well as doing research in our lab. As a by-product, interactions between the part-time students and the other regular students stimulate each other, particularly enlightening the regular students to practical software issues. However, too much emphasis on practicality may bring negligence to science and technology and may generate anti-intellectualism. A good balance between the scientific aspect and the practical aspect of software engineering should always be pursued.\nIn our view, teaching various software modeling techniques is a good way to achieve balanced software engineering education. It is needless to say that model is a key concept and modeling is an essential skill in software engineering. There are a variety of modeling techniques; some are intuitive and quite accessible to novices, while some are highly sophisticated and attract theory oriented students and researchers.\nIn this paper, we would like to show that it is effective to teach multiple modeling techniques from a unified viewpoint. It is based on our experience of teaching software engineering courses at several universities in Japan. Recently, the author published a textbook on software engineering, specifically focused on software modeling (unfortunately, it is written in Japanese)[1]. The book covers the whole area of software engineering, including design, testing and evolution but the modeling part has a role of attracting interests of intelligent students, who may not have much experience in developing real scale software systems. It also gives a consistent viewpoint penetrating through various techniques employed in different stages of software engineering.\n2. MODELING TECHNIQUES\nIn software engineering, models are used for various purposes, e.g. life cycle model, process model, project model, product model, quality model, domain model, requirements model, design model, object model, data model, etc. In the following, we basically focus on requirements and design models but most of the discussions will hold for other kinds of models.\nTeaching modeling is almost equal to teaching abstraction. Models are constructed through capturing the crucial properties and structure of the target, abstracting away irrelevant details. Thus, learning how to model is a good training for mastering abstraction.\n2.1 Graph Representation of Models\nMany software models are represented with diagrams. Wide acceptance of UML symbolizes the trend that diagrams are often preferred to textual languages. Among many types of diagrams, graph structured diagrams are by far the most widely used. The reasons may be as follows.\n1. A most fundamental way for human mind to understand the world is by regarding it as consisting of a set of conceptual units and a set of relations between them. Conceptual units can be naturally illustrated with boxes or circles or whatever closed figures and relations can be illustrated with lines or arrows connecting such figures, corresponding to vertices and edges of graphs, respectively.\n2. It is easy to draw graph structured diagrams by hand or with drawing tools.\n3. Concepts and algorithms of the graph theory are available and often useful in analyzing models represented by graphs.\nA typical example is reasoning on transitive relations by tracing along paths of graphs. Also, the concept of subgraph is highly useful in decomposing higher-level models or clustering lower-level models.\nAccordingly, a number of models share the same structure of graphs. Table1shows graph structures of some typical models.\n2.2 Commonality and Difference between Models\nIt is pedagogical to let students notice the common structure shared by a number of models. However, the apparent resemblance often causes confusion. Such confusion can be observed not only in software modeling graphs but in many diagrams found in daily newspapers, magazines, reports, proposals and other documents. It is often the case that one vertex denotes a type of things and another denotes quite a different type on the same diagram or one type of edges co-exist with edges with different meaning. Thus, it is important to make students consciously aware the differences between different models. We often experience that when we let students draw data flow diagrams who appear to have understood the data flow model perfectly, the diagrams turn out to be something like control flow graphs.\nTo show the difference, it is instructive to categorize models represented by graphs. Basically, there are two categories. Static models and dynamic models may not be easily confused but confusion between different dynamic models are often observed, e.g. data flow and control flow or state transition and activity transition. Since graphs are intuitively understandable, their semantics are apt to be understood ambiguously or misunderstood.\n3. UML\nUML diagrams can also be viewed in terms of graph structures. Table2shows graph structures of five UML diagrams. It is usually not desirable to teach UML per se. UML is a collection of miscellaneous diagrams and its specification is continuously changing. For the pedagogical purpose, UML had better be regarded as a catalogue of analysis and design know-how collected around diagrammatic representations. Diagrams should be selected according to the policy of how to teach modeling methods.\nEach UML diagram contains overly rich constructs, which sometimes blur the essential property of the model. For example, the activity diagram is essentially a control flow diagram but it also includes a notation for data flow description. From the stance of emphasizing differences between various models, it is not appropriate to include such ad hoc constructs. By the same token, the collaboration diagram (, renamed to \"communication diagram\" in UML 2) is explained to have the equivalent semantics as the sequence diagram. But if that is the case, significance of the collaboration diagram is considerably limited. The author prefers to regard it as showing collaboration relations between objects, integrating a set of different sequence diagrams.\n4. CONCLUSION\nSoftware modeling is important by itself but teaching modeling in the software engineering course has at least two additional meanings. One is to give a bird's-eye view to the whole software engineering through the standpoint of modeling technology. The other is to attract interest of good students who may not have much experience in developing a real-scale software but possess intelligence and will to attack complexity of modern software construction.\n",
        "resume": "To enhance motivation of students to study software engineering, some way of finding balance between the scientific aspect and the practical aspect of software engineering is required. In this paper, we claim that teaching multiple software modeling techniques from a unified viewpoint is a good way of obtaining the balance and attracting the students' interest as well.",
        "authors": [
            "Tetsuo Tamai"
        ],
        "keywords": [
            "software engineering education",
            "UML"
        ],
        "institutions": [
            "The University of Tokyo Graduate School of Arts and Sciences"
        ],
        "refrences": [
            "T Tamai. Foundations of Software Engineering. Iwanami Shoten 2004, in Japanese."
        ],
        "created_at": "2024-02-01T13:37:25.721205+00:00",
        "updated_at": "2024-02-01T13:37:28.395030+00:00"
    },
    {
        "id": 3,
        "title": "ModelGame: A Quality Model for Gamified Software Modeling Learning",
        "body": "1 INTRODUCTION\nGamification has been adopted in software development tasks in recent years. This adoption seeks, for example, to improve the engagement of developers while creating UML models or writing code. Empirical studies[7,9,14]report that UML models suffer from incompleteness and inconsistency problems. Lange[14]reinforces that these defects bring potential risks that can cause misinterpretation and communication failure, representing a risk to software quality. Thus, finding formats that favor student learning and consequently in generating increasingly effective UML models can become one of the main challenges faced by instructors that include UML (Unified Modeling Language) as part of software modeling content.\nSome studies[3,12,25]sought to understand how to apply gamification in software modeling teaching using some elements such as points, emblems and levels. However, instructors and researchers still find limitations when applying, evaluating, and measuring the use of this tool in the learning of software modeling students and, consequently, in the models developed by them, since in the current literature there is no \"frame of reference\" that guides them. This study conjectures that gamification mechanics can improve learner engagement while learning software modeling, mitigating such problems concerning UML models. The current literature lacks studies that explore gamification and model quality in the context of software modeling learning.\nThis article, therefore, introduces ModelGame, which is a quality model to support software modeling learning in a gamified way. It serves as a reference framework so that instructors can obtain a parameterized way to evaluate UML models created by learners. The quality of UML models can be improved by applying gamified activities and providing guidelines aware of quality issues. A reference framework would help to (1) establish parameters for evaluating UML models created by learners; (2) provide guidelines to improve the quality of these artifacts;(3)to analyze which elements of gamification could be included in each of the phases of modeling using UML; (4) identify intrinsic and extrinsic aspects of students during the modeling stages, to improve the models;(5)to compare validated theories about the inclusion of gamification in software modeling teaching, taking into account the types of learning and methodologies used; and (6) contributing to the identification of gamification use objectives in modeling activities.\nA qualitative questionnaire was answered by 19 instructors who teach software modeling at higher education institutions. The results show that (1) 94.7% recognize that the proposed model can improve the quality of UML models, indicating that they would adopt it in their learning practices; and (2) 47.4% do not use any gamification mechanics in their classes. These results are encouraging, showing the potential for applying and improving the teaching and learning of software modeling.\nThe remainder of the paper is organized as follows. Section 2 presents the main concepts discussed throughout the article. Section 3 discusses the related work, highlighting research opportunities. Section 4 introduces the proposed quality model. Section 5 presents how the quality model was evaluated. Section 6 points out some threats to validity. Finally, Section 7 presents some concluding remarks and future work.\n2 BACKGROUND\nThis section presents the essential concepts for understanding this work, including gamification and software engineering teaching (Section 2.1), and software modeling and model quality (Section 2.2).\n2.1 Gamification and Software Engineering Teaching\nGamification aims to use game elements in the context of not game[5], bringing all positive aspects they provide as a way to encourage and engage \"players, \" thereby broadening their motivations.\nWerbach[23]classifies gamification into three dimensions: Dynamics, Mechanics, and Components. Dynamicsinclude all game aspects related to the emotional responses of \"players\" (e.g., relationship, progression, and narrative).Mechanics offer elements that promote the action of a game -usually elaborated via a rule-based development -, so that the player can interact with such elements, e.g., challenges, feedback, and rewards. Components represent the aesthetic elements of gamification, whose goal is to present visual aspects with which players can perform the interaction, for example, points, scores, and emblems (badges).\nKnowing that the teaching of Software Engineering should involve students to experience the professional practices of the area so that they can understand which practices and techniques are useful in several different situations[2]. The challenges of teaching new software engineers are not limited to learning programming, but also include paying attention to detail, considering the quality of created models, established schedule and defined budgets[1]. In addition to understanding the technical challenges, these future professionals must be up to date with nontechnical issues, including teamwork, communication and management.\nTo meet these new demands of the current context, the format with exhibition classes is no longer considered enough and may even become demotivating and ineffective in learning students. In this sense, gamification has been increasingly used in the teaching of software engineering as a way to promote behavioral and psychological changes[11]providing an environment that favors communication, cooperation, feedback, reward, achievement and other recurring elements that are capable of improving performance, efficiency and engagement in educational activities , and can enhance, for example, the learning of software modeling.\n2.2 Software Modeling and Model Quality\nSoftware modeling encompasses the set of principles, concepts, and practices that lead to the development of a high-quality system or product. The principles of this activity establish a philosophy that guides the entire software development process.\nIn this scenario, UML models play a crucial role in software development tasks, for example, documenting project decisions, understanding development details, promoting better communication between teams, and generating greater efficiency in software development[19]. However, these models suffer problems of inconsistency and incompleteness[10,18], as well as end up being overlooked within the modeling process, as pointed out in some empirical studies in the literature[14,15]. Class and sequence diagrams, for example, present inconsistencies when sequence diagram objects are not found in the class diagram, consequently developers end up living with inconsistencies throughout the development process.\nA research challenge still open is how to evaluate these diagrams, both in industry and in the teaching process, in terms of quality, such as syntactic and semantic, for example.\n3 RELATED WORK\nThe selection of related works was carried out following two steps:\n(1) search in digital repositories, such as Google Scholar and Scopus (Elsevier) of articles related to gamification, quality modeling, and modeling learning; and (2) filter selected articles considering the alignment of such works with the objective of the work (Section 4). After selecting the works, they were analyzed (Section 3.1) and compared (Section 3.2), seeking to identify research opportunities.\n3.1 Analysis of Related Works\nPorto et al. (2021)[4]. This work performed a systematic mapping with the objective of characterizing how gamification has been adopted in noneducational contexts of software engineering activities. The main results of this study show that gamification provided benefits for activities such as requirements specification, development, testing, project management, and support process. In addition, he pointed out that the number of publications and new research initiatives has increased over the years, many positive results have been achieved in software engineering activities. Nevertheless, the study reinforced that gamification can still be explored for other tasks in this area, as empirical evidence is very limited.\nMarin (2021)[17]. It performed the application of gamification on some topics of a software engineering course to engage students and increase their motivation and argued that, with due motivation, students can better exercise the topics and obtain more solid knowledge. There were five games related to risk management, BPMN modeling, Scrum process, design and inspection of class diagrams, and cosmic functional size measurement to assist in the learning process of the software engineering course. This study also presented the lessons learned about the application of gamification and serious games in software engineering, including limitations or disadvantages.\nJurgelaitis et al. (2018)[12]. This work conducted a research to investigate how gamification could be inserted into an Information Systems Modeling course, which covers a range of topics on UML. As a result, an implementation of the gamified system modeling course in the Moodle environment was presented, using additional plugins for the use of the necessary gamified elements. The study showed good results and obtained a positive acceptance by the participating students.\nRodrigues et al. (2018)[22]. They investigated the use of games and game elements in software engineering education, through a research that had the participation of 88 instructors of this discipline. The results showed that most instructors are aware of these educational approaches, however, the games were adopted by only 21 participants and game elements were adopted only by 19. Games are most often used to cover \"Software Process\" and \"Project Management\". The most commonly used game elements are points, quizzes, and challenges. The results also show that the main reasons for not adopting the resources are the lack of knowledge, information about games relevant to the engineering of teaching software, and the lack of time to plan and include these approaches in the classroom.\nCosentino et al. (2017)[3]. They present a model-based approach to learning modeling in a gamified way. The approach includes a new language to model the gamification process itself and an environment where it can be incorporated into current modeling tools to allow instructors and students to design and use a complete modeling framework, including gamification elements. In addition, the approach also had as a proposal to provide support to collect and analyze gamification data, thus facilitating monitoring activities.\nYohannis (2016)[25]. This research presents an exploration of game design as an approach to strengthening the student's mastery in software modeling by developing their abstraction skills. It brought together concepts of gamification development, such as the lens of atoms of intrinsic skill and principles of pedagogical design of various theories and models of learning. The research follows the Design Science Research Methodology and explores the best practices of Model Oriented Engineering. As a result, a modeling game design framework and generation structure and a series of produced games are presented.\nPedreira et al. (2015)[21]. They developed a systematic mapping of gamification in Software Engineering based on 29 studies. The mapping revealed that software implementation is the area in which most studies focus, followed by software requirements, few others in different areas, such as project planning and software testing, and even to a lesser extent in activities involving software modeling. However, the highlight of this work was to highlight that gamification in software engineering is still at a very early stage and the evidence on its impact in this field remains inconclusive.\n3.2 Comparative Analysis and Opportunities\nFive Comparison Criteria (CC) were defined selecting the most relevant variables to assist in the process of identifying similarities and differences between the proposed work and the selected articles. This comparison is crucial to make the process of identifying research opportunities using objective rather than subjective criteria. The criteria are described below:\nâ¢ Context (CC01): Works that explore the use of gamification in software modeling teaching/learning. â¢ Participant profile (CC02): Studies that collected data from participants for screening and profile characterization.\nâ¢ Applicability of Gamification in UML (CC03): Studies that evaluated how gamification can contribute to UML models. â¢ Model creation (CC04): Studies that have developed a model to improve factors that imply the non-adoption of UML. â¢ Instructor participation (CC05): Studies that collected qualitative data through the participation of software modeling instructors.\nTable1shows the comparison of the selected works, confronting this work. Some gaps and research opportunities are observed: (1) only the proposed work was the only one to fully meet all comparison criteria; (2) although most of them targeted the application of gamification in software modeling teaching, they were not directed to the use of UML;(3)no study has developed a model to evaluate the learning and improvement of UML models developed by students; and (4) most of them did not have the participation of instructors to identify the difficulties and opportunities in the application of gamification in the teaching of software modeling. Thus, the next Section presents a quality model to explore these identified opportunities.\nRelated Work\nComparison Criterion CC1 CC2 CC3 CC4 CC5 Proposed Work Porto et al (2021)[4]Marin (2021)[17]Jurgelaitis et al (2018)[12]Rodrigues et al (2018)[22]Cosentino et al (2017)[3]Yohannis (2016)[25]Pedreira et al (2015)[21]Completely Meets Partially Meets Does not attend\n4.1 Generic Analytical Framework\nFigure1presents the generic analytical framework for improving the quality of the models and serves as the basis for the creation of an evaluation scheme. The arrows (\"links\"), labeled as Evaluation and Gamified Modeling, represent the questions that the evidence must answer; dotted lines represent associations; rectangles represent the Models (rounded corners) or the quality states (square corners) by which these bindings are measured. Ellipses represent the adverse effects that can be generated from the evaluation and use of gamification. The numbers refer to the key questions and are connected with the concepts and relationships of the abstract syntax of the Quality Model (presented in Section 4.2), as follows: (1) Are there tools that assist instructors in evaluating the models developed by students, thus reducing the poor quality and incompleteness of these artifacts? (2) What is the prevalence of characteristics that cause models to be at risk? (3) Are there notions of quality to evaluate the models as a way to define parameters when performing their correction? (4) Applying the use of gamification in models that need intervention would be a way to identify factors that could generate models with high quality levels? (5Fact is that it is not enough just to include this \"toolbox\" in the UML learning process, it is necessary to provide the instructor with a model (guide) that can serve as a reference to evaluate the quality of diagrams elaborated through gamified activities. For example, the instructor could create models predefining inconsistencies by making use of these questions raised to evaluate the models created by the students. The set of questions serves as the starting point for this evaluation. Knowing that the adaptation of the gamification approach requires a significant effort[20], in this study we present The ModelGame as a way to identify factors that contribute to the quality of these artifacts and, consequently, to the students' learning.\n4.2 Abstract Syntax\nFollowing the specification pattern of the UML metamodel, Figure2presents the abstract syntax of the proposed Quality Model for gamified software modeling learning (ModelGame). It identifies the main concepts and relationships. The numbers represent the notions of quality that are discussed in Section 4.3. The following are detailed each of these concepts and relationships.\nDomain. The first concept presented in this study is the domain, which corresponds to a specific context of the application to be developed to solve the problem. In this process, the design template represents the solution given to the domain. Association\nâ¢ contextualizes:\nChallenges[*]\nEach contextualise refers to the domain that will serve as the basis for the challenges launched.\nChallenges. This concept represents the phase in which the problem is contextualized (domain-based), as well as what will be the missions, phases, scenarios, and other elements presented to the players, in this case the students, who must use the principles of software engineering to perform the modeling and reach the final goal. Association\nâ¢ influences: Design Model[*]\nEach influence represents that the proposed challenge interfered in aspects of the design model, causing the user to seek to make a continuous improvement.\nModeling Language. Software modeling is an important step for development to happen in a way that adheres to the requirements established by the requester, for this, there is the modeling language, which offers a standardized way to document and design software. Through the use of modeling languages, it is possible to achieve a high level of understanding about the software in question, improving the communication between all those involved in the process, thus avoiding implementation errors. It points out that software engineers use these languages to communicate design decisions and verify the feasibility of implementing the intended design. The UML was consolidated as the Modeling Language in the paradigm of object orientation, in which it is possible through visual notation generated from the diagrams-presented later in this study as Design Models-to perform the representation of various perspectives of the system. Association User. This concept corresponds to the individual who performs the interpretation of the developed design models, whose objective is to be able to understand the domain in question. In the gamified context, the user has the role of player and it is he who performs the whole process, being able to perform the interpretation of existing models or even creating new ones. The user can also identify and resolve inconsistencies that arise from compositions between models.\nAssociation â¢ creates: Design Model[1.\n. *] Represents the process in which the user creates a design template, which can be one or more.\nâ¢ interprets: Design Model[1.. *] In this association, the user performs the interpretation of the design template. When interpreting the model, paths for the resolution of inconsistencies can be identified.\nâ¢ detects: Inconsistency [*]\nRepresents the user's discovery of design model inconsistencies, for example, those that are generated from identifying conflicts, whether a class is abstract or not.\nâ¢ resolves: Inconsistency [*] Each resolves equates to the resolution representation of the inconsistencies by the user that happens after he analyzes and determines the best alternative to perform this action.\nâ¢ uses: Modeling Tools [*] Determines that the user can use modeling tools to generate/update design models.\nAssociation\nâ¢ Without a directed relationship.\nModeling Tool. This concept represents the applications that are used to carry out the construction of design models. There are several tools available, online and desktop, and it is up to the user to choose the one that will best meet their needs and adapt to the context in question, that is, they work in any domain that is being considered.\nDesign Model. The design model refers to a visual notation (diagram) to represent static and dynamic aspects. These models are built according to a specific objective or task and tend to facilitate the logical interpretation of the software in several aspects. The most popular diagrams are Use Cases and Classes, the first being static and representing a set of actions generated from functional requirements (use cases) and presenting the interactions generated with external users (actors). The second is a static diagram and makes the representation of the logical structure of the software involving the classes, their attributes, methods, and relationships between them[19]. Association\nâ¢ describes: Domain[1]Each describes makes the representation of a specific domain and means that every design model must describe it.\nInconsistency. It corresponds to the defects found in the models developed by users. They may occur because of the nonidentification and correction of possible conflicts and even an erroneous interpretation. Association\nâ¢ affects: Design Model[*]\nThis association indicates that with each occurrence of the affect, a problem is presented harming the quality of the design model.\nPoints. This concept represents one of the most used game mechanics in software engineering and functions as a quantitative reward for each action developed, in which it is possible to regulate the number of rewarded points of the player, defined here as user, based on the importance of each action. Through this concept, it is possible to stimulate competition, collaboration, and creativity among users, stimulating learning. Points appear as a derivation of the association affects, since when each inconsistency error is identified or not, the user will receive a score and the association describes, because the points will also be applied when making connections between the model and the domain.\nProgress. The concept of progress emerges as a factor that makes the user able to perceive its evolution in the process, in this case, software modeling. Progress emerges as a derivation of the association interprets, making the user know when they have performed a correct interpretation of the proposed design model or what still needs to be improved.\nFeedback. Feedback has the role of making the user realize that the proposed goal can be achieved and follow its evolution, including analyzing how to change or creating new strategies to achieve the goal. This concept emerges as a derivation between the associations it creates, causing the user to receive a return to the model creation process.\n4.3 Quality Notions\nAs discussed in Section 2, gamification can bring important elements for learning software modeling and, therefore, the objective of this section is to produce the notions of quality of the model of this study. The ModelGame is composed of ten counts, four of which are proposed in this study -scope, use, motivational and engagement -extracted from the main benefits that the gamification elements presented in Figure2can bring to the models. The others are adaptations of previous works[6,14,15], they are, syntactic, semantic, social, effort, detection and resolution.\nScope Quality(1). It seeks to determine how much the proposed challenge is contextualized with the design model, as well as the definition of the domain, problem, competencies, concepts, behaviors and attitudes that will be developed throughout the process.\nSyntactic Quality (2). This notion makes the representation of the process of correction of the design models that are produced by the modeling language, because if it is not used correctly, inconsistencies will arise. It is important to insert this notion of quality into our study, since during the process of developing the models, users may come across the composition of two class diagrams, for example.\nSemantic Quality(3). It is necessary to verify that the design model and the problem domain match, so this notion performs this type of analysis. Communication problems may occur between users if the semantic elements of the model are affected.\nSocial Quality(4). Design models are used to communicate between members of a team to inform all established decisions about software development[8]. If divergent interpretations occur, this communication will be greatly impaired.\nQuality of Effort(5). This notion refers to the production challenges of the model that will be generated, including factors such as time and cost.(6). To produce design templates, users can use unusual tools such as paper, whiteboard, and more. However, most of the time they choose to use formal tools (CASES) and can be online or desktop. This notion corresponds to the level of ease and applicability of the models elaborated when making use of these tools, it is also important to contribute to communication between users through collaboration-related functionalities.\nQuality of Use\nDetection Quality(7). This notion is referenced to the process of locating inconsistencies, since when users arise, they should perform traceability of them quickly. If the detection is complicated, it could hinder the process of correcting the models.\nResolution Quality(8). It corresponds to the level of quality related to the effort that users take to look for alternatives to solve the identified problem.\nMotivational Quality(9). This notion refers to the motivational factors involved during the learning and development of design models, which can be intrinsic and extrinsic. Elements of gamification such as points, feedback and progress bring the user a degree of satisfaction in continuing their discovery and transformations throughout the process.\nQuality of Engagement(10). The user in tracking their progress can feel committed to the objective in question, and this notion represents the measurement of the level of commitment of them during the development of design models.\n5 EVALUATION\nThis section describes the methodology followed to evaluate the proposed quality model. This methodology follows well-established empirical guidelines[24]. Section 5.1 details the objective and research questions (RQ). Section 5.2 presents the questionnaire formulated to evaluate the proposed quality model. Section 5.3 explains the context and selection of participants. Section 5.4 describes the presentation of the Model. Section 5.5 presents the analysis of the collected data.\n5.1 Objective and Research Questions\nThe objective (O) of this study is twofold: (O1) Introduce Model-Game as a tool for teaching Software Modeling; and (O2) Analyze the applicability of the quality model regarding the improvement of UML models.\nTo analyze the different facets of the objectives, two Research Questions (RQ) have been formulated:\nâ¢ RQ1: How do instructors evaluate the use of gamification in software modeling? â¢ RQ2: What is the acceptance of ModelGame by software modeling instructors?\n5.2 Questionnaire\nData was collected through an online questionnaire created through Google Forms1following well-established guidelines described in[24]. This strategy was chosen because the questionnaire could be applied quickly and easily collect data from individuals in geographically diverse locations. The questions of the questionnaire were concerned with examining the research gaps of previous studies and apprehending the structures of the previously developed questionnaire.\nPart 1: Participant profile. The first part of the questionnaire consisted of collecting data that are related to the characteristics and opinions of the participants. The creation of the participant profile through this data is important to make the selection of possible users of ModelGame. Without this profile, participants with an inadequate profile may generate inconsistent assessments.\nParticipants were asked to provide more general information, such as age, education level, academic background. Information about the time of experience in teaching was also considered, including teaching software modeling and level of knowledge about UML models.\nPart 2: TAM questionnaire. The second part addressed questions about the usability and acceptance of the technique, aiming to explore q3. To this end, this part of our questionnaire is based on the technology acceptance model (TAM)[16]. This part contained nine questions, which were answered through the Likert Scale, including Totally Agree, Partially Agree, Neutral, Partially Disagree, and Totally Disagree. The questions formulated (Q) dealt with several topics, including perceived ease of use (Q1-3), perceived utility (Q4-7), attitude towards use (Q8), and behavioral intention to use (Q9).\n5.3 Selection of participants\nThe participants were selected based on the following criteria: instructors and/or professionals working in the teaching of software modeling in higher education institutions in Brazil. Using this criterion, we sought to select participants with academic training and practical experience in teaching. This finite set of all possible participants represents the target population[13]. This population represents those people who are in a position to answer the questions formulated and to whom the results of the survey apply[13]. In all, 19 people (n) answered the questionnaire. The participants were invited via e-mail to participate in the study and each of them previously received the explanation/training about the model proposed through the researcher and there was no doubt, they could leave for the next step that consisted of completing the TAM questionnaire. We discussed the experimental process in the next section.\n5.4 Experimental Process\nFigure3presents the experimental process used in this study, which is composed of three phases discussed below:\nPhase 1: Presentation. It has an activity, presentation, in which the researcher explained to the participants through a video detail about the quality model. This process took place individually and in a standard way, where space was also made available for participants to answer possible doubts about the proposed study and model, lasting an average of 20 minutes.\nPhase 2: Application of the TAM questionnaire. It has two activities, the first being Collect demographic data. The participants answered a list of questions (input) so that we could collect their characteristics and opinions about the ModelGame. The demographic data collected (output) became the result of this activity.\nThe second activity Apply TAM questionnaire (input). Participants received a list of questions about the perception of ease of use, perceived utility, attitudes, and intention of behavior, in relation to the ModelGame. Qualitative data (output) were generated, regarding the usability and acceptance of the Model under the perspective of professionals who teach software modeling. This questionnaire followed the guidelines of the TAM[16].\nPhase 3: Analysis and result report. It has two activities. The first, Analyze data sought to perform a thorough analysis of the data collected through the questionnaire and the researcher's perception regarding the participants' doubts during the presentation stage. For this, the collected data were analyzed separately, as well as confronted, aiming to perform a triangulation of them. Subsequently, there was an Evaluation data, as a way to understand in a more depth the context, the perceptions of the participants in relation to the proposed model as well as its applicability.3describes the profile data, reporting the characteristics and opinions of the participants. These data were collected from May 18 to June 5, 2021. In total, we had 19 participants. Our participants are between 20 and 49 years old, most of them have a degree in Computer Science (52.6%), Information Systems (26.3%) or Systems Analysis (21.1%) and are specialists (36.8%), masters (36.8%) and doctors (15.8%). About the working time in teaching, the majority (42.1%) they have been teaching for more than 8 years and teach disciplines related to software modeling, including software engineering, systems analysis and software projects. A total of 47.4% have a full level of knowledge about UML and almost half of them (47.4%) has not yet used gamification in the teaching of software modeling. Therefore, we consider\nPerceived usefulness\nThe model would make it easier to understand which elements of gamification can be used in modeling . 12 5 2 0 0 Using the quality model would help increase productivity. 9 8 2 0 0 The model would provide an understanding of how to mitigate the incompleteness of UML diagrams.   We consider the percentage of instructors who have not yet used gamification in their classes to be high and this may be tied to factors such as lack of knowledge, information about the tool, and even time to plan and include these approaches[22]. Although they were based on software modeling teaching context, previous studies[3,4,12,17,25]they did not count on the participation of instructors and we understand that this participation is fundamental to understand the perceptions of these professionals since they will be at the forefront of the use of gamification.\nThe ModelGame proposed in this study could help them insert gamification into their classes, according to the software modeling learning design[25], based on the assumption that for this, it is necessary to develop a better understanding of the tasks, activities, skills and operations that the different elements of gamification can offer and how they can correspond to the desired learning outcomes by developing a more concrete and motivating presentation that can involve students and facilitate deep learning with UML.\n5.5.3 RQ2:\nWhat is the acceptance of the ModelGame by software modeling instructors? Using the TAM questionnaire, we tried to evaluate the ease of use, perceived usefulness, attitude, and behavioral intention to use the Quality Model. Table2shows the data obtained. Our data obtained show that no one disagreed that the ModelGame is easy to use, learn, and master. On the contrary, almost 90% of participants find the model easy to use (42.1% totally agree and 47.4% partially agrees and 10.5% neutral), learn (52.6% fully agree and 47.4% partially agree) and master (31.6% fully agree, 63.2% partially agree and 5.3% partially disagree).\nThe results are also favorable considering the perception of utility. Most participants realized that the ModelGame would make it easier to understand which elements of gamification can be used in each of the phases of modeling using UML(63.3% totally agree, 26.3% partially agree and 10.5% neutral), increase productivity (47.4% fully agree, 42.1% partially agree and 10.5% neutral), and the use of the quality model would provide an understanding of how to mitigate the incompleteness of UML diagrams (26.3% agree totalmen 42.1% partially agree, 26.3% neutral and 5.3% partially disagree). Still in the useful aspect, we tried to know if the quality model would help to compare validated theories about the inclusion of gamification in software modeling teaching (68.4% totally agree, 21.1% partially agree and 10.5% neutral).\nConsidering the attitude towards use, participants believe that using the ModelGame is a good idea (68.4% totally agree, 26.3% partially agree and 5.3% neutral), just as they are confident and would use the Model in software modeling classes (52.6% totally agree, 36.8% partially agree and 10.5% neutral). These findings show the potential for acceptance by people with profiles similar to those of participants. The results are encouraging and show the potential to use the proposed approach in the educational scenario.\n6 THREATS TO VALIDITY\nThis section discusses the possible threats to the validity of the study.\nInternal validity. The main point affecting the internal validity of our study concerns the total time used for the exploratory phase. To mitigate this threat, we performed the video recording of a pilot explaining the operating details and objectives of the ModelGame. In relation to the methods used, the threats related to internal validity relate to how we extract the perceptions of the discussions and whether they represent the perceptions of teachers about the use of the Model. We try to reduce this threat by applying the TAM questionnaire.\nExternal validity. We identified threats related to external validity, such as the number of participants who never applied the use of gamification. This study was limited to 19 participants (teachers) from various educational institutions, of which 9 (47.4%) never used any element of gamification in their classes, this factor can interfere in the data, since the model intends to evaluate the quality of UML diagrams from gamified activities.\nConclusion validity. Threats related to the validity of the conclusion are related to treatment and outcome. We try to make the reduction by combining quantitative and qualitative data through different resources. These data were obtained through audio and questionnaires. We analyze this data to answer the research questions.\n7 CONCLUSIONS AND FUTURE WORK\nThis study proposed an initial quality model (ModelGame) that serves as a reference framework for instructors for qualitative evaluations of UML models developed from gamified activities, the application of an empirical study with 19 participants was carried out to understand their vision in relation to gamification and the acceptance of the proposed Model. It was identified that most have not yet used gamification in their classes, but agree that their use can contribute to the quality of the models developed by the students and were open to using the model. Our findings can enhance the adoption of new teaching practices through gamification, resulting in the improvement of software modeling learning using UML, and consequently the creation of models developed by students. These approaches can stimulate students' immersion in the design of systems as future professionals during learning.\nFinally, we hope to carry out in the future a series of experimental studies to analyze each stage of application of the ModelGame and that this work represents a first step to better support the application of empirical studies on models of evaluation of the use of gamification in software modeling. We also hope that the questions described throughout the article will encourage other researchers to extend our study to different modeling languages and teaching methodologies.\n",
        "resume": "Gamification has been adopted in software development tasks in recent years. This adoption seeks, for example, to improve the engagement of developers while creating UML models or writing code. Empirical studies report that UML models suffer from incompleteness and inconsistency problems. This study conjectures that gamification mechanics can improve learner engagement while learning software modeling, mitigating such problems concerning UML models. The current literature lacks studies that explore gamification and UML model quality in the context of software modeling learning. This article, therefore, proposes ModelGame, which is a quality model to support software modeling learning in a gamified way. It serves as a reference framework so that instructors can obtain a parameterized way to evaluate UML models created by learners. The quality of UML models can be improved by applying gamified activities and providing guidelines aware of quality issues. A qualitative questionnaire was answered by 19 instructors who teach software modeling at higher education institutions. The results show that (1) 94.7% recognize that the proposed model can improve the quality of UML models, indicating that they would adopt the ModelGame in their learning practices; and (2) 47.4% do not use any gamification mechanics in their classes. The results are encouraging, showing the potential for applying and improving the teaching and learning of software modeling.",
        "authors": [
            "Ed Wilson JÃºnior",
            "Kleinner Farias"
        ],
        "keywords": [
            "Model design",
            "learning model",
            "Gamification"
        ],
        "institutions": [
            "Universidade do Vale do Rio dos Sinos SÃ£o Leopoldo"
        ],
        "refrences": [
            "Rick Adcock, Edward Alef, Bruce Amato, Mark Ardis, Larry Bernstein, Barry Boehm, Pierre Bourque, John Brackett, Murray Cantor, Lillian Cassel. Curriculum guidelines for graduate degree programs in software engineering ACM 2009.",
            "Mark Ardis, David Budgen, Gregory W Hislop, Jeff Offutt, Mark Sebern, Willem Visser. SE 2014: Curriculum guidelines for undergraduate degree programs in software engineering Computer 2015. 2015, 48, 106-109.",
            "SÃ©bastien Valerio Cosentino, Jordi GÃ©rard, Sagrera Cabot. A modelbased approach to gamify the learning of modeling CEUR Workshop Proceedings 2017.",
            "Daniel De, Paula Porto, Gabriela Martins De. Fabiano Cutigi Ferrari, and Sandra Camargo Pinto Ferraz Fabbri. 2021. Initiatives and challenges of using gamification in software engineering: A Systematic Mapping Journal of Systems and Software 2021, 173.",
            "Sebastian Deterding, Miguel Sicart, Lennart Nacke, Kenton O' Hara, Dan Dixon. Gamification. using game-design elements in non-gaming contexts CHI'11 extended abstracts on human factors in computing systems 2011, 2425-2428.",
            "Ana FernÃ¡ndez-Saez. A systematic literature review on the quality of UML models J. Data. Manage 2012. 2012, 22, 46-70.",
            "Kleinner Farias. Evaluating the impact of aspects on inconsistency detection effort: a controlled experiment International Conference on Model Driven Engineering Languages and Systems Springer 2012, 219-234.",
            "Kleinner Frias. Towards a quality model for model composition effort 29th Annual ACM Symposium on Applied Computing 2014, 1181-1183.",
            "Kleinner Farias. Evaluating the effort of composing design models: a controlled experiment Software & Systems Modeling 2015. 2015, 14, 1349-1365.",
            "Kleinner Farias. UML2Merge: a UML extension for model merging IET Software 2019. 2019, 13, 575-586.",
            "Juho Hamari, Jonna Koivisto, Harri Sarsa. Does gamification work?a literature review of empirical studies on gamification 2014 47th Hawaii international conference on system sciences Ieee 2014, 3025-3034.",
            "Mantas Jurgelaitis, Vaidotas Drungilas, Lina ÄeponienÄ. Gamified Moodle course for teaching UML Baltic journal of modern computing 2018. 2018, 6, 119-127.",
            "A Barbara, Shari L Kitchenham. Personal opinion surveys Guide to advanced empirical software engineering Springer 2008, 63-92.",
            "Christian Franz, Josef Lange. Assessing and Improving the Quality of Modeling: A series of Empirical Studies about the UML 2007. 2007.",
            "Guttorm Odd Ivar Lindland, Arne Sindre. Understanding quality in conceptual modeling IEEE software 1994. 1994, 11, 42-49.",
            "Nikola MaranguniÄ, Andrina GraniÄ. Technology acceptance model: a literature review from 1986 to 2013 Universal access in the information society 2015. 2015, 14, 81-95.",
            "Beatriz MarÃ­n. Lessons Learned About Gamification in Software Engineering Education Latin American Women and Research Contributions to the IT Field. IGI Global 2021, 174-197.",
            "Kleinner Oliveira, Alessandro Garcia, Jon Whittle. On the quantitative assessment of class model compositions: An exploratory study. 1th ESMDE at MODELS 2008. 2008.",
            "UML: Infrastructure specification 2017.",
            "Sofia Ouhbi, Nuno Pombo. Software Engineering Education: Challenges and Perspectives IEEE Global Engineering Education Conference 2020, 202-209.",
            "Oscar Pedreira, FÃ©lix GarcÃ­a, Nieves Brisaboa, Mario Piattini. Gamification in software engineering-A systematic mapping Information and software technology 2015. 2015, 57, 157-168.",
            "Pedro Rodrigues, Mauricio Souza, Eduardo Figueiredo. Games and gamification in software engineering education: A survey with educators 2018 IEEE Frontiers in Education Conference (FIE) IEEE 2018, 1-9.",
            "Kevin Werbach, Dan Hunter. For the win: How game thinking can revolutionize your business Wharton digital press 2012.",
            "Claes Wohlin, Per Runeson, Martin HÃ¶st, Magnus C Ohlsson, BjÃ¶rn Regnell, Anders WesslÃ©n. Experimentation in software engineering Springer Science & Business Media 2012.",
            "Alfa Yohannis. Gamification of Software Modelling Learning DS@ MoDELS 2016."
        ],
        "created_at": "2024-02-01T13:36:42.884974+00:00",
        "updated_at": "2024-02-01T13:36:56.106532+00:00"
    },
    {
        "id": 2,
        "title": "Semantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model",
        "body": "1 INTRODUCTION\nOver the past few years, a clear surge of both the amount of spammers as well as spam emails. This is likely due to a fact that the investment necessary for engaging in the spamming industry is relatively low. As a result of this, we currently have a system that identifies every email as suspicious, which has caused major expenditures in the investment of defense systems[12]. Emails are used for online crimes like fraud, hacking, phishing, E-mail bombing, bullying, and spamming.[16]. Algorithms that are based on machine learning (ML) are now the most effective and often used approach to the recognition of spam. Phishing, which is defined as a fraudulent attempt to acquire private information by masquerading as a trustworthy party in electronic communication, has rapidly advanced past use of simple techniques and the tactic of casting a wide net; instead, spear phishing uses a variety of sophisticated techniques to target a single high-value individual. Other researchers used NB, Decision Trees, and SVM to compare the performance of supervised ML algorithms for spam identification[6]. Spam emails clog up recipients' inboxes with unsolicited communications, which frustrate them and push them into the attacker's planned traps[7]. As a result, spam messages unquestionably pose a risk to both email users and the Internet community. In addition, Users may occasionally read the entire text of an unsolicited message that is delivered to the target users' inboxes without realizing that the message is junk and then choosing to avoid it. Building a framework for email spam detection is the aim of this project. In this approach, we combine the Word-Embedding Network with the CNN layer, Bi-LSTM, and GRU (BiLSTM+GRU). CNN layers are used to speed up training time before the Bi-LSTM network, and more advanced textual characteristics are extracted with the use of this network in comparison to the straight LSTM network, in less time. Gated recurrent neural networks (GRUs) are then added because they train more quickly and perform better for language modeling. To evaluate and investigate various machine learning algorithms for predicting email spam, and develop a hybrid classification algorithm to filter email spam before employing an ensemble classification algorithm to forecast it. To put an innovative technique into practice and compare it to the current method in terms of various metrics. Ensemble learning, a successful machine learning paradigm, combines a group of learners rather than a single learner to forecast unknown target attributes. Bagging, boosting, voting, and stacking are the four main types of ensemble learning techniques. To increase performance, an integrated method and the combining of two or three algorithms are also suggested. Extraction of text-based features takes a long time. Furthermore, it can be challenging to extract all of the crucial information from a short text. Over the span associated with this research, we utilize Bidirectional Large Short-Term Memories (Bi-LSTM) in conjunction with Convolutional Neural Networks (CNN) to come up with an innovative method to the detection of spam. Bagging and boosting approaches were widely preferred in this study. Contribution and paper organization is as follows: section 1.1 describes literature study, section 1.2 describe motivation for this research work, section 2 sketches procedure of details implementation, Section 3 present experimental setup, dataset description and evaluation metrics, and section 4 summarizing outcomes of the experiment.\n1.1 Related Work\nEmail is indeed the second most frequently utilized Internet application as well as the third most common method of cyberbullying, claims one study. Cybercriminals exploit it in a number of ways, including as sending obscene or abusive messages, adding viruses to emails, snatching the private information of victims, and exposing it to a broad audience. Spam letters made up 53.95% of all email traffic in March 2020. We examine three main types of unlawful emails in our study. First are fake emails, which are sent to manipulate recipients to submit sensitive information. The second as being cyberbullying's use of harassing emails to threaten individuals. Suspicious emails that describe illegal activities belong to the third category. Many researchers have earlier contributed massively to this subject. The researcher claims there is some proof that suspicious emails were sent before to the events of 9/11.[14]. When it comes to data labeling, there are also convinced rule-based approaches and technologies ( like VADER) that are used, even though their efficiency of the are together is adversely affected. A hidden layer, which itself is essential for vectorization, is the top layer of the model. We use oversampling methods for this minority class because of the absence of data. Sampling techniques can help with multicollinearity, but they have an impact on simulation results. Oversampling causes data to be randomly repeated, which affects test data because dividing data may result in duplicates. Undersampling may result in the loss of some strong information. In order to advance email research, it is crucial to provide datasets on criminal activity. P.Garg et al. (2021)[5], which revealed that spam in an email was detected in 70 percent of business emails, spam was established as an obstacle for email administrators. Recognizing spam and getting rid of it were the primary concerns, as spam can be offensive, may lead to other internet sites being tricked, which can offer harmful data, and can feature those who are not particular with their content using NLP. To select the best-trained model, each mail transmission protocol requires precise and effective email classification, a machine learning comparison is done. Our study has suggested that innovative deep learning outperforms learning algorithms like SVM and RF. Current studies on the classification of emails use a variety of machine learning (ML) techniques, with a few of them focusing on the study of the sentiments consisted of within email databases. The lack of datasets is a significant obstacle to email classification. There are few publicly accessible E-mail datasets, thus researchers must use these datasets to test their hypotheses or gather data on their own. Authors[15]describe supplied two-phased outlier detection models to enhance the IIOT network's dependability. Artificial Neural Network, SVM, Gaussian NB, and RF (random forest) ensemble techniques were performed to forecast class labels, and the outputs were input into a classifying unit to increase accuracy. A method for content-based phishing detection was presented by the authors in[2], to classify phishing emails, they employed RF. They categorize spam and phishing emails. They enhanced phishing email classifiers with more accurate predictions by extracting features. They showed some effective Machine learning spam filtering techniques. When the PCA method is used, it will lower the number of features in the dataset. The collected features go through the PCA algorithm to reduce the number of features. The PCA method is used to make a straightforward representation of the information which illustrates the amount of variability there is in the data. The authors of[20]presented the Fuzzy C-means method for classifying spam email. To stop spam, they implemented a membership threshold value. A methodology to identify unlabeled data was put forth by the authors of[1]and applied motive analysis to the Enron data collection. They divided the data into categories that were favorable, negative, and neutral. They grouped the data using k-means clustering, an unsupervised ML technique and then classified it using the supervised ML techniques SVM and NB. Hina, Maryam, and colleagues (2021) implemented Sefaced: Deep learning-based semantic analysis and categorization of e-mail data using a forensic technique. For multiclass email classification, SeFACED employs a Gated Recurrent Neural Network (GRU) based on Long Short-Term Memory (LSTM). Different random weight initializations affect LSTMs[9]. Zhang, Yan, et al.(2019) Experiments on three-way game-theoretic rough set (GTRS) email spam filtering show that it is feasible to significantly boost coverage without decreasing accuracy[23]. According to Xia et al.[22], SMS spam has been identified using machine learning model such as naive bayes , vector-space modeling, support vector machines (SVM), long selective memory machines (LSTM), and convolutional neural networks including every instance of a method for categorizing data. Elshoush, Huwaida, et al. (2019) Using adaboost and stochastic gradient descent (sgd) algorithms for e-mail filtering with R and orange software spam[3]. Orange software was used to create the classifications, which included Adaboost and SGD. The majority of researchers focused on text-based email spam classification methods because image-based spam can be filtered in the early stages of pre-processing. There are widely used word bag (BoW) model, which believes that documents are merely unordered collections of words, is the foundation for these techniques. Kumaresan[11]explains SVM with a cuckoo search algorithm was used to extract textual features for spam detection. Renuka and Visalakshi made use of svm[17]spam email identification, followed by selecting features using Latent Semantic Indexing (LSI). Here we have used labeled dataset to train the hybrid classifier. We used TF-IDF for feature extraction[20]and Textual features for spam detection were extracted using SVM and a cuckoo search algorithm.[4]for filtering out the spam email. Combining the integrated strategy to the pure SVM and NB methods, overall accuracy is really improved. Moreover, accurate detection for spam email has been proposed using the Negative Selection Algorithm (NSA) and Particle Swarm Optimization's (PSO) algorithm. PSO is used in this instance to improve the effectiveness of the classifier.\n1.2 Motivation and Novelty\nEmail is most common form of communication between people in this digital age. Many users have been victims of spam emails, and their personal information has been compromised. The email Classification technique is employed to identify and filter junk mail, junk, and virus-infected emails prior to reach a user's inbox. Existing email classification methods result in irrelevant emails and/or the loss of valuable information. Keeping these constraints in mind, the following contributions are made in this paper:\nâ¢ Text-based\n2 PROPOSED SYSTEM ARCHITECTURE AND MODEL\nE-mail is a valuable tool for communicating with other users. Email allows the sender to efficiently forward millions of advertisements at no cost. Unfortunately, this scheme is now being used in a variety of organizations. As a result, a massive amount of redundant emails is known as spam or junk mail, many people are confused about the emails in their E-Mailboxes. Each learning sequence is given forward as well as backward to two different LSTM networks that are attached to the same outputs layer in order for bidirectional Lstms to function. This indicates that the Bi-LSTM has detailed sequential information about all points before and following each point in a specific sequence. In other words, we concatenate the outputs from both the forward and the backward LSTM at each time step rather than just encoding the sequence in the forward direction. Each word's encoded form now comprehends the words that come before and after it. This is a problem for the Internet community. The diagram depicts various stages that aid in the prediction of email spam:\nBecause real-world data is messy and contains unnecessary information and duplication, data preprocessing is critical in natural language processing (NLP). The major preprocessing steps are depicted below.\n2.1 NLP Tokenization\nTokenization of documents into words follows predefined rules. The tokenization step is carried out in Python with spacy library.\n2.2 Stop Words Removal\nStop words appear infrequently or frequently in the document, but they are less significant in terms of importance. As a result, these are removed to improve data processing.\n2.3 Text Normalization\nA word's lexicon form or order may differ. Thus, they must all be changed to their root word to be correctly analyzed. Lemmatization and stemming are the two methods that can be used for normalization. When a word's final few characters are removed to create a shorter form, even if that form has no meaning, the procedure is known as stemming. lemmatization[21]is a mixture of corpusbased an rule-based methods, and it retains the context of a term while changing it back to its root.\n2.4 Feature Extraction\nfeature extraction which transforms the initial text into its features so that it may be used for modeling after being cleaned up and normalized. Before predicting them, we use a specific way to give weights to specific terms in our document. While it is simple for a computer to process numbers, we choose to represent individual words numerically. In such cases, we choose word embeddings. IDF is the count of documents containing the term divided by the total number of documents, and occurrence is the amount of instances a word appears in a document. We derive characteristics based on equations. 1,2,3,4,5, and 6. We use equations to derive properties.\nð ð ð¼ð ð = ð¡ ð * 1 ð ð(1)\nð ð ð¼ð ð = ð¡ ð * Inverse(ð ð )(2)\nð ð ð¼ð ð (ð¡, ð, ð·) = ð ð (ð¡, ð).ð¼ð ð (ð¡, ð·)\nð ð¼ð ð (ð¡, ð) = log ð |ððð·ð¡ðð· |(3)\nA word2vec neural network-based approach is the method that is utilized for this goal as the tool. The following equation, referred to as 5, shows how word2vec handles word context through the use of probability-accurate measurements. Here letter D stands for the paired-wise display of a set of words, while the letters w and c0 or c1 represent paired word context that originated from a larger collection of set D.\nð (ð· = 1 | ð¤, ð 11:ð ) = 1 1 + ð -(ð¤â¢ð 1 1+ð¤â¢ð 1 2+...+ð¤â¢ð 1 ð ) (5) ð (ð· = 1 | ð¤, ð 1:ð ) = 1 1 + ð -(ð¤â¢ð0) (6)\n2.5 Word-Embeddings\nWord-Embedding helps to improve on the typical \"bag-of-words\" worldview, which requires a massive sparse feature vector to score every word individually to represent this same entire vocabulary. This perception is sparse because the vocabulary is large, and each word or document is defined by a massive vector. Using a word map-based dictionary, word embedding needs to be converted terms (words) into real value feature vectors. There are two basic issues with standard feature engineering techniques for deep learning. Data is represented using sparse vectors, and the second is that some of the meanings of words are not taken into consideration. Similar phrases will have values in embedding vectors that are almost real-valued. The Input length in our proposed study is set to 700 for our suggested model. If the texts seemed to be integer encoded with value systems between 10 and 20, the vocabulary distance would be 11. Our data is encoded as integers, and the input and output dimensions are both set to 50,000. The embedding layer outcome will be used in successive layers and for BiLSTM and GRU layers.\n2.6 Machine Learning Model\nWithin the scope of the research, we are using the subsequent machine learning techniques, to examine and compare the overall efficacy of our suggested Bi-LSTM strategy: Support Vector Machine, Gaussian NB, Logistic Regression, K -nearest neighbors, and Random Forest (RF).\n2.7 Convolution Network\nThe popular RNN model generally performs well but takes too long to train the model incorporating the textual sequential data. When a layer is added after the RNN layer, the model's learning duration is considerably decreased. Higher-level feature extraction is another benefit.[19]additionally possible using the convolutional layer. In essence, the convolution layer looks for combinations of the various words or paragraphs in the document that involve the filters. We use features with 128 dimensions and a size 10 for each. For this task, the Relu activation function is utilized. After that, the one-dimensional largest pooling layers with a pooling size of 4 are put on the data in order to obtain higher-level features.\n2.8 BiLSTM Network with GRU\nRecurrent Neural Network (RNN) technique of text sentiment analysis is particularly well-liked and frequently applied. Recurrent neural networks (RNN) surpass conventional neural networks. because it can remember the information from earlier time steps thanks to its memory. A state vector is combined with an RNN's data to create a new state vector. The resulting state vector uses the present to recollect past knowledge. The RNN is straightforward and is based on the following equations:\nâ ð¡ = tanh (ð ââ â ð¡ -1 + ð ðâ ð¥ ð¡ )(7\n)\nð¦ ð¡ = ð â ð¦ â ð¡(8)\nThe vanilla RNN[18]is not very good at remembering previous sequences. In addition to that, RNN struggles with diminishing gradient descent. A kind of RNN is a long short-term recall network (LSTM), solves a vanishing gradient descent problem and learns long-term dependencies[10]. LSTM was actually created to address the problem of long-term reliance. LSTM has the unique ability to recall. The cell state is the LSTM model's central concept. With only a small amount of linear interaction, the cell state follows the sequence essentially unmodified from beginning to end. gate of an LSTM is also significant. Under the command of these gates, information is safely inserted to or eliminated from the cell stated.\nThe following equations are used by the LSTM model to update each cell:\nð ð¡ = ð ð ð â¢ [â ð¡ -1 , ð¥ ð¡ ] + ð ð(9)\nIn this case, Xt denotes input, and ht is the hidden state at the t time step. The following is the revised cell state Ct:\nð t = ð (ð ð [â ð¡ -1 , ð¥ ð¡ ] + ð ð ) (10\n)\nð¶ ð = tanh (ð ð [â ð¡ -1 , ð¥ ð¡ ] + ð ðð¡ ) (11\n)\nð¶ ð¡ = ð ð¡ * ð¶ ð¡ -1 + ð ð¡ * ð¶ ð(12)\nHere, we may compute the output and hidden state at t time steps using the point-wise multiplication operator *.\nð ð¡ = ð (ð ð â¢ [â ð¡ -1 , ð¥ ð¡ ] + ð ð )(13)\nâ ð¡ = ð ð¡ * tanh (ð¶ ð¡ )(14)\nDue to the reality it only considers all prior contexts from the present one, LSTM does have a few drawbacks. As a result of this, it may accept data from preceding time steps through LSTM as well as RNN. Therefore, in order to avoid this issue, further improvements are carried out with the help of a bidirectional recurrent neural network(Bi-RNN). BiRNN[13]can handle two pieces of information from both the front and the back. Bi-LSTM is created by combining the Bi-RNN and LSTM. As a result, operating LSTM has advantages such as cell state storage so that BiRNN have way to acknowledge from the context before and after. As a consequence of this, it provides the Bi-LSTM with the advantages of an LSTM with feedback for the next layer. Remembering long-term dependencies is a significant new benefit of Bi-LSTM. The output, which is a feature vector, will be based on the call state. Finally, we forecast the probability of email content as Normal, Fraudulent, Harassment, and Suspicious Emails using as an input to the softmax activation function, which is a weighted sum of the dense layer's outputs. To regulate the information flow, GRU employs the point-wise multiplying function and logistic sigmoid activation.\nThe GRU has hidden states of storage memory and does not have distinct memory cells or units for state control. The W, U, and b vectors, which stand for weights, gates, and biases, respectively, are crucial variables that must be calculated during the creation of the GRU model. For training reasons, the pre-trained word embedding known as the Glove vector is used. They made it clear that GRU is the superior model when there is a large amount of training data for textual groups and word embedding is available. BiLSTM, CNN, and GRU is required so as to compensate for the deletion of the document's long-term and short-term connections. In our case, the embedding dimension, maximum sequence length, and lexicon size were used to start the LSTM embedding layer in three separate LSTM models. The input vector was modified to make it appropriate for such a Conv1D layer, prior situations' sequences are returned by LSTM layer. The \"return sequences\" of the LSTM layer must be set to False when the subsequent state is free of the gated architecture. Quantity of learning parameters must be taken into consideration. A 350-unit LSTM layer was set -up, and different LSTM unit combinations were tested. More importantly, because it has more parts, the model made with BiLSTM will take longer to train. Bidirectional LSTM is the name of a particular kind of recurrent neural network that is primarily used for the processing of natural languages. (BiLSTM). It is able to use data from both sides, and, in contrast to regular LSTM, it enables input flow in both directions. It is an effective instrument for demonstrating the logical relationships between words and phrases, and this involves both the forward and backward directions of the sequence. In conclusion, BiLSTM works by adding one extra layer of LSTM, causing the information flow to travel in the other direction. It only denotes that the input sequence runs in reverse at the next LSTM layer. Multiple operations, including averaging, summation, multiplication, and concatenation, are then applied to the results of the two LSTM layers. The gated design of Bi-LSTM and GRU networks solves the disappearing gradient and exploding problems. A good way to handle more long sequences is to use Bi-LSMT and GRU together. GRU works well with datasets that don't have text. In two to three rounds, the complicated CNN+BiLSTM+GRU model learns the long sequence of email text well. We have used word embedding, cnn, bidirectional lstm and gru networks as our three building blocks to separate email messages based on their sentiment and text's sequential features. Also, we succinctly demonstrate below why these blocks help identify email spam:\nâ¢ First, We have used the Sequence -to -sequence Lstm as the current block in the networks since it can retrieve both the previous and next sequences from the current. More so than a straightforward LSTM network, it can also recognize and extract text sentiment and sequential properties. â¢ Second, we extract the more complex and advanced characteristics for Bi-LSTM network using Convolutional Network block, which is the network's second block after the Bi-LSTM block. Bi-LSTM takes a long time to extract text-based features, hence one of the reasons for using this block is to reduce the network's overall training time.\n3 EXPERIMENTAL EVALUATION 3.1 Experimental Setup\nWe divided the information into training and testing groups of 80/20. We divided the remaining 20% of the 80 percent training data into test data for the model. Construct, compute, and evaluate the efficacy of the suggested method using the Pythonic packages Keras, as TensorFlow and Scikit learn.\n3.2 Dataset Description\nEmail spam detection is the foundation of this research project. The dataset includes normal emails from the Enron corpora, deceptive emails from phished email corpora, harassment emails chosen from hate speech, and the offensive dataset. Only the content of the email body is used for analysis; all header information, including sender, topic, CC, and BCC, are eliminated. Word2vector, TF-IDF, and Word Embedding are used to extract characteristics from the email message and classify them. This dataset[8]is publicly available. The presented model is implemented using Python, and several metrics, including accuracy, precision, and recall, are used to examine the outcomes.\n3.3 Evaluation Metrics and Results\nClassifier performance is assessed Using metrics such as accuracy, precision, and recall. Four terms make up a confusion matrix that is used to calculate these metrics.\nâ¢ True positives (TP) are positive values that have been accurately assigned the positive label.1where six different classifiers are Gaussian NB, Random Forest, KNN, SVM, LSTM, and Propose Ensemble Hybrid Model (CNN+BiLSTM+GRU) have been used in this work. In the CNN, Bi-LSTM, and GRU architectures which enable sequence prediction, CNN strands for feature extraction on data input which are combined with LSTM. It requires less time training and a higher expandable model. Any bottlenecks are created by predictions and the increasing number of distinct units of information. This model is useful for dealing with issue-related classifications that consist of two or more than two classes. So suggested Ensemble model, out of these six classifiers, produces more accurate findings.    In this Proposed ensemble hybrid model's train accuracy is 98.7% Validation accuracy is 97.32% and LSTM has train accuracy of 97.41% and validation accuracy is 95.2%. So based on figures 3 and 5 indicate the validation loss for LSTM and the proposed ensemble hybrid model to be 0.93 and 0.84, respectively, and figures 2 and 4 show the validation accuracy to be 95.2% and 97.3%, respectively. LSTM and the proposed hybrid model used ensemble artificial intelligence, with the proposed hybrid model outperforming the LSTM. We decide on dense architecture as the final model for identifying the text messages as spam or nonspam based on loss, accuracy, and the aforementioned charts. The loss and accuracy over epochs are more stable than LSTM, and the Proposed classifier has a straightforward structure.\n4 CONCLUSION\nThe model is composed of four networks Word-Embeddings, CNN, Bi-LSTM, and GRU. We may train the model more quickly by using the convolutional layer first, followed by the word-embedding layer, and then the BiLSTM network. The Bidirectional LSTM network also has higher-level properties that we can extract. We have used a bidirectional LSTM(BiLSTM)and GRU network to memorize a sentence's contextual meaning and sequential structure, which improves the model's performance accuracy to roughly 97.32 percent.\n",
        "resume": "The emergence of novel types of communication, such as email, has been brought on by the development of the internet, which radically concentrated the way in that individuals communicate socially and with one another. It is now establishing itself as a crucial aspect of the communication network which has been adopted by a variety of commercial enterprises such as retail outlets. So in this research paper, we have built a unique spam-detection methodology based on email-body sentiment analysis. The proposed hybrid model is put into practice and preprocessing the data, extracting the properties, and categorizing data are all steps in the process. To examine the emotive and sequential aspects of texts, we use word embedding and a bi-directional LSTM network. this model frequently shortens the training period, then utilizes the Convolution Layer to extract text features at a higher level for the BiLSTM network. Our model performs better than previous versions, with an accuracy rate of 97-98%. In addition, we show that our model beats not just some well-known machine learning classifiers but also cutting-edge methods for identifying spam communications, demonstrating its superiority on its own. Suggested Ensemble model's results are examined in terms of recall, accuracy, and precision",
        "authors": [
            "Shivangi Sachan",
            "Khushbu Doulani",
            "Mainak Adhikari"
        ],
        "keywords": [
            "Dataset",
            "KNN",
            "Gaussian Naive Bayes",
            "LSTM",
            "SVM",
            "Bidirectional LSTM",
            "GRU",
            "Word-Embeddings",
            "CNN"
        ],
        "institutions": [
            "Department of CSE IIIT Lucknow Lucknow",
            "Department of CSE IIIT Lucknow UP",
            "Vardhaman College of Engineering Hyderabad"
        ],
        "refrences": [
            "Rayan Salah, Hag Ali, Neamat El Gayar. Sentiment analysis using unlabeled email data 2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE) IEEE 2019, 328-333.",
            "Ali Shafigh, Navid Khalilzadeh. Proposed efficient algorithm to filter spam using machine learning techniques Pacific Science Review A: Natural Science and Engineering 2016. 2016, 18, 145-149.",
            "T Huwaida, Esraa A Elshoush. Using adaboost and stochastic gradient descent (sgd) algorithms with R and orange software for filtering e-mail spam 11th Computer Science and Electronic Engineering (CEEC) IEEE 2019. 2019, 41-46.",
            "Weimiao Feng, Jianguo Sun, Liguo Zhang. A support vector machine based naive Bayes algorithm for spam filtering 2016 IEEE 35th International Performance Computing and Communications Conference (IPCCC) IEEE 2016, Cuiling Cao, and Qing Yang, 1-8.",
            "Pranjul Garg, Nancy Girdhar. A Systematic Review on Spam Filtering Techniques based on Natural Language Processing Framework 2021 11th International Conference on Cloud Computing, Data Science & Engineering (Confluence) IEEE 2021, 30-35.",
            "Adam Kavon, Henry N Pontell. Phishing evolves: Analyzing the enduring cybercrime Victims & Offenders 2021. 2021, 16, 316-342.",
            "Radicati Group. Email Statistics Report 2015. 2015-2019. August 13 (2015. 2019.",
            "Maryam Hina, Mohsin Ali. Sefaced: Semantic-based forensic analysis and classification of e-mail data using deep learning IEEE Access 2021. 2021, 9, 98398-98411.",
            "Maryam Hina, Mohsin Ali, Abdul Rehman Javed, Fahad Ghabban, Liaqat Ali Khan, Zunera Jalil. Sefaced: Semantic-based forensic analysis and classification of e-mail data using deep learning IEEE Access 2021. 2021, 9, 98398-98411.",
            "Weicong Kong, Yang Zhao, Youwei Dong, David J Jia, Yan Hill, Yuan Xu. Short-term residential load forecasting based on LSTM recurrent neural network IEEE transactions on smart grid 2017. 2017, 10, 841-851.",
            "T Kumaresan, C Palanisamy. E-mail spam classification using S-cuckoo search and support vector machine International Journal of Bio-Inspired Computation 2017. 2017, 9, 142-156.",
            "Mehdi E Nuha H Marza, Hussein A Manaa. Classification of spam emails using deep learning 2021 1st Babylon International Conference on Information Technology and Science (BICITS) IEEE 2021, 63-68.",
            "Tomas Mikolov, Geoffrey Zweig. Context dependent recurrent neural network language model 2012 IEEE Spoken Language Technology Workshop (SLT) IEEE 2012, 234-239.",
            "Sarwat Nizamani, Nasrullah Memon, Mathies Glasdam, Dong Duong Nguyen. Detection of fraudulent emails by employing advanced feature abundance Egyptian Informatics Journal 2014. 2014, 15, 169-174.",
            "I Priya, Thippa Reddy Sumaiya Thaseen, Mohamed K Gadekallu, Emad Aboudaif, Nasr Abouel. Robust attack detection approach for IIoT using ensemble classifier 2021. 2021, arXiv preprint, arXiv:2102.01515.",
            "Justinas Rastenis, Simona RamanauskaitÄ, Justinas JanuleviÄius. Antanas Äenys, Asta SlotkienÄ, and KÄstutis Pakrijauskas Applied Sciences 2020. 2020, 10, 7, E-mail-based phishing attack taxonomy.",
            "D Karthika, P Renuka. Latent semantic indexing based SVM model for email spam classification 2014. 2014.",
            "Shuvendu Roy, Sk Imran Hossain. Sequence modeling for intelligent typing assistant with Bangla and English keyboard 2018 International Conference on Innovation in Engineering and Technology (ICIET) IEEE 2018, 1-6.",
            "Tara N Sainath, Oriol Vinyals, Andrew Senior, HaÅim Sak. Convolutional, long short-term memory, fully connected deep neural networks 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP) Ieee 2015, 4580-4584.",
            "Anuj Kumar Singh, Shashi Bhushan, Sonakshi Vij. Filtering spam messages and mails using fuzzy C means algorithm 2019 4th International Conference on Internet of Things: Smart Innovation and Usages IEEE 2019, IoT-SIU, 1-5.",
            "Kristina Toutanova, Colin Cherry. A global model for joint lemmatization and part-of-speech prediction Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP 2009, 486-494.",
            "Tian Xia. A constant time complexity spam detection algorithm for boosting throughput on rule-based filtering systems IEEE Access 2020. 2020, 8, 82653-82661.",
            "Yan Zhang, Pengfei Liu, Jingtao Yao. Three-way email spam filtering with game-theoretic rough sets 2019 International conference on computing, networking and communications (ICNC) IEEE 2019. 15 April 2023, Received, 552-556."
        ],
        "created_at": "2024-02-01T13:35:46.189194+00:00",
        "updated_at": "2024-02-01T13:36:03.860105+00:00"
    },
    {
        "id": 1,
        "title": "AI Model for Computer games based on Case Based Reasoning and AI Planning",
        "body": "1. Introduction\nThe goal of this effort is to explore a model for design and implementation of an AI agent for turn based games. This model provides for building more capable computer opponents that rely on strategies that closely resemble human approach in solving problems opposed to classical computational centric heuristics in game AI. In this manner the computational resources can be focused on more sensible strategies for the game play.\nWith the advancement in computer hardware increasingly more computing power is left for executing AI algorithms in games. In the past AI in games was mainly a cheating set of instructions that simulated the increasing difficulty in the game environment so that the player had the illusion of real counterpart. Improvement in available memory and processing power allows implementation of more intelligent algorithms for building the game environment as well as direct interaction with the human players.\nIn this particular research the emphasis is put on the interaction between the AI agent and a computer player in the realm of the game rules. It is particularly focused on turn based games that have the elements of uncertainty like dice or concealed information. At the beginning a description of Game AI algorithms are given; such as Game Trees and Minimax. The following section describes an approach of using AI Planning to improve building Game Trees in games with imperfect information where Game Trees tend to be very large with high growth ratio. Section 4 discusses another approach that provides a significant reduction to the number of considered moves in order to find the favorable strategy of the AI player. This approach uses AI Planning techniques and Case Base Reasoning (CBR) to plan for different scenarios in predetermined strategies which would be analogous to human player experience in the particular game. The CBR database illustrates a set of past experiences for the AI problem and the AI Planning illustrates the procedure to deal with the given situation in the game. In the next two sections implementations and evaluations of both approaches are given. The AI Planning approach is implemented with the Tic-tac-toe game and the combined AI Planning and CBR approach is implemented with a model for the Monopoly game. The last part contains conclusions and future work ideas.\n2. Game Trees and Minimax\nGame Trees are common model for evaluating how different combinations of moves from the player and his opponents will affect the future position of the player and eventually the end result of the game. An algorithm that decides on the next move by evaluating the results from the built Game Tree is minimax[1]. Minimax assumes that the player at hand will always choose the best possible move for him, in other words the player will try to select the move that maximizes the result of the evaluation function over the game state. So basically the player at hand needs to choose the best move overall while taking into account that the next player(s) will try to do the same thing. Minimax tries to maximize the minimum gain. Minimax can be applied to multiple Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. DIMEA'08, September 10-12, 2008, Athens, Greece. Copyright 2008 ACM 978-1-60558-248-1/08/09... $5.00 levels of nodes on the game tree, where the leaves bring the final known (or considered) game state.\nThe minimax theorem states:\nFor every two-person, zero-sum game there is a mixed strategy for each player, such that the expected payoff for both is the same value V when the players use these strategies. Furthermore, V is the best payoff each can expect to receive from a play of the game; that is, these mixed strategies are the optimal strategies for the two players.\nThis theorem was established by John von Neumann, who is quoted as saying \"As far as I can see, there could be no theory of games â¦ without that theorem â¦ I thought there was nothing worth publishing until the Minimax Theorem was proved\"[2].\nA simple example of minimax can be observed by building a game tree of the tic-tac-toe game. The tic-tac-toe game is a simple game which can end by the first player wining, the second player wining or a tie. There are nine positions for each of the players in which at each turn the player puts X or O sign. If the player has three adjacent signs in a row, column or the two diagonals he or she wins. This game has limited number of position and it is well suited for building the whole game tree. The leaves of this tree will be final positions in the game. A heuristics evaluation function will also need to be written to evaluate the value of each node along the way.\n3. AI Planning for building Game Trees\n3.1.1 AI Planning\nAI Planning also referred as Automated Planning and\nScheduling is a branch of Artificial Intelligence that focuses on finding strategies or sequences of actions that reach a predefined goal[3]. Typical execution of AI Planning algorithms is by intelligent agents, autonomous robots and unmanned vehicles. Opposed to classical control or classification AI Planning results with complex solutions that are derived from multidimensional space. AI Planning algorithms are also common in the video game development. They solve broad range of problems from path finding to action planning. A typical planner takes three inputs: a description of the initial state of the world, a description of the desired goal, and a set of possible actions. Some efforts for incorporating planning techniques for building game trees have also shown up, similar to the approach explored in this effort. In addition Cased Based Reasoning[4]techniques are also gathering popularity in developing strategies based in prior knowledge about the problems in the games. One of the benefits from Hierarchical Task Network (HTN)[5]planning is the possibility to build Game Trees based on HTN plans; this method is described in the following section.\n3.2 Game Trees with AI Planning\nAn adaptation of the HTN planning can be used to build much smaller and more efficient game trees. This idea has already been implemented in the Bridge Baron a computer program for the game of Contact Bridge[6].\nComputer programs based on Game Tree search techniques are now as good as or better than humans in many games like Chess[7]and checkers[8], but there are some difficulties in building a game tree for games that have imperfect information and added uncertainty like card or games with dice. The main problem is the enormous number of possibilities that the player can choose from in making his move. In addition some of the moves are accompanied with probabilities based on the random elements in the games. The number of possible moves exponentially grows with each move so the depth of the search has to be very limited to accommodate for the memory limitations.\nThe basic idea behind using HTN for building game trees is that the HTN provides the means of expressing high level goals and describing strategies how to reach those goals. These goals may be decomposed in goals at lower level called sub-goals. This approach closely resembles the way a human player usually addresses a complex problem. It is also good for domains where classical search for solution is not feasible due to the vastness of the problem domain or uncertainties.\n3.2.1 Hierarchical Task Networks\nThe Hierarchical Task Network, or HTN, is an approach to automated planning in which the dependency among actions can be given in the form of networks[9][Figure1].\nA simple task network (or just a task network for short) is an acyclic digraph â«Ýâ¬ àµ áºÜ·Ç¡ â«Ü§â¬á» in which U is the node set, E is the edge set, and each node â«Ýâ¬ â«×â¬ Ü· contains a task â«Ýâ¬ à¯¨ . The edges of â«Ýâ¬ define a partial ordering of U. If the partial ordering is total, then we say that â«Ýâ¬ is totally ordered, in which case â«Ýâ¬ can be written as a sequence of tasks â«Ýâ¬ àµ â«ÝÛâ¬ à¬µ Ç¡ â«Ýâ¬ à¬¶ Ç¡ Ç¥ Ç¡ â«Ýâ¬ â«.Ûâ¬\nFigure 1: Simple Hierarchical Task Network\nA Simple Task Network (STN) method is a 4-tuple of its name, task, precondition and a task network. The name of the method lets us refer unambiguously to substitution instances of the method, without having to write the preconditions and effects explicitly. The task tells what kind of task can be applied if the preconditions are met. The preconditions specify the conditions that the current state needs to satisfy in order for the method to be applied. And the network defines the specific subtasks to accomplish in order to accomplish the task.\nA method is relevant for a task if the current state satisfies the preconditions of a method that implements that task. This task can be then substituted with the instance of the method. The substitution is basically giving the method network as a solution for the task.\nIf there is a task \"Go home\" and the distance to home is 3km [Figure2] and there exists a method walk-to and this method has a precondition that the distance is less than 5km, then a substation to the task \"Go home\" can be made with this method instance. If the distance is larger than 5km another meth to be substituted [Figure3]. An STN planning domain is a set of operatio methods M. A STN planning problem is a 4-tu state S 0 , the task network w called initial task STN domain. A plan ß¨ àµ â«Ü½Ûâ¬ à¬µ Ç¡ Ç¥ Ç¡ Ü½ â«Ûâ¬ is a soluti problem if there is a way to decompose w into Ï and each decomposition is applicable in the ap the world. The algorithm that is capable to networks into plans is called Total-forward-deco[9]or Partial-forward-decomposition (PFD). H cases where one does not want to use a forwa procedure. HTN planning is generalization of S gives the planning procedure more freedom construct the task networks.\nIn order to provide this freedom, a bookke is needed to represent constraints that the plann not yet enforced. The bookkeeping is done by unenforced constraints explicitly in the task netw\nThe HTN generalizes the definition of a STN. A task network is the pair â«Ýâ¬ àµ áºÜ·Ç¡ â«Ü¥â¬á» w task nodes and C is a set of constraints. Eac specifies a requirement that must be satisfied by a solution to a planning problem.\nThe definition of a method in HTN also definition used in STN planning. A HTN pla name, task, subtasks, and constraints. The s constraints form the task network. The HTN plan identical to STN planning domains except they u instead of STN methods.\nCompared to classical planners the prim HTN planners is their sophisticated knowledge r reasoning capabilities. They can represent and non-classical planning problems; with a good guide them, they can solve classical planning p magnitude more quickly than classical or neoc The primary disadvantage of HTN is the nee author to write not only a set of planning opera of methods.\n3.2.2 HTN Planning in building Game\nFor a HTN planning algorithm to be adap trees we need to define the domain (set of H operators) which is the domain of the game. Thi a knowledge representation of the rules of the environments and possible strategies of game pla In this domain the game rules as well as kn tackle specific task are defined. The implem Tree building with HTN is called Tign implementation uses a procedure simila decomposition, but adapted to build up a game nown strategies to mentation of Game num2[9]. This ar to forwardtree rather than a plan. The branches of the game tree rep the methods. Tignum2 applies all met state of the world to produce new continues recursively until there are n have not already been applied to th world.\nIn the task network generated by Tignu actions will occur is determined by th By listing the actions in the order network can be \"serialized\" into a gam\n4. Case Based Reasoning in 4.1 Case Based Reasoning\nCase-based reasoning (CBR) is a Artificial Intelligence (AI), both as problems and as a basis for standalone Case-based reasoning is a paradigm solving and learning that has became applied subfield of AI of recent yea intuition that problems tend to recur. I are often similar to previously en therefore, that past solutions may be of[10].\nCBR is particularly applicable to probl available, even when the domain is n for a deep domain model. Helpdesks, systems have been the most successfu to determine a fault or diagnostic attributes, or to determine whether or repair is necessary given a set of past s  lems where earlier cases are not understood well enough , diagnosis or classification ul areas of application, e.g., an illness from observed r not a certain treatment or olved cases[11].\nrom HTN ree Algorithm\nCentral tasks that all CBR methods have to deal with are[12]: \"to identify the current problem situation, find a past case similar to the new one, use that case to suggest a solution to the current problem, evaluate the proposed solution, and update the system by learning from this experience. How this is done, what part of the process that is focused, what type of problems that drives the methods, etc. varies considerably, however\".\nWhile the underlying ideas of CBR can be applied consistently across application domains, the specific implementation of the CBR methods -in particular retrieval and similarity functions-is highly customized to the application at hand.\n4.2 CBR and Games\nMany different implementations of CBR exist in games. CBR technology is nicely suited for recognizing complex situations much easier and more elegant than traditional parameter comparison or function evaluation. There are especially evident cases in real time strategies where different attack and defense of global strategies are nicely defined by CBR datasets and later used in the running games. Also intelligent bots behavior is also another typical example. Depending on the number of enemy bots the layout of the terrain and position of human players the CBR system finds the closest CBR case and employs that strategy against the human players which in prior evaluation was proved to be highly efficient.\n5. Game Trees with AI Planning -Tic-tac-toe\nIn order to show the expressive power of AI Planning in defining strategies for games, and the use of these plans to build Game Trees I implemented an algorithm that builds Game Trees for the Tic-Tac-Toe game.\nThe game tree of Tic-Tac-Toe shows 255,168 possible games of which 131,184 are won by X (the first player), 77904 are won by O and the rest 46,080 are draw[13]. All these games can be derived from building a complete Game Tree.\nEven though it is possible to build a complete game tree of Tic-tac-toe it is definitely not an optimal solution. Many of the moves in this tree would be symmetrical and also there are a many moves that would be illogical or at least a bad strategy to even consider.\nSo what strategy should X (the first player) choose in order to win the game?\nThere are few positions that lead to certain victory. These positions involve simultaneous attack on two positions so the other player could not defend, basically the only trick in Tic-Tac-Toe. There are many different arrangements of the player's tokens that give equivalent positions as these three positions. By using planning we do not need to consider all possible layouts but just consider these three similar to what a human would consider.\nThe game starts from an empty table.\nThe two relevant strategies that would lead to these positions are to take one corner or to take the center [Figure7].\nFigure 7: Tic-tac-toe Two starting moves\nThe center position as we can see in the simulation results lead to a bigger number of victorious endings but it is also a straight forward strategy with obvious defense strategy.\nAt this point we need to consider the moves of the opponent. If we take the left branch the opponent moves can be a center, a corner or a middle field. We also need to differentiate with a move to a corner adjacent with our like top left or bottom right or across the center to bottom right [Figure8].\nFigure 8: Tic-tac-toe opponent response to corner move\nIn cases one and two, we have a clear path to executing strategy 3 so we need to capture the diagonally opposite field. And as for the third case the best way to go is to capture the center and go for strategy 1 or 2 depending of the opponent's next move.\nFigure 9: Tic-tac-toe move 2 after corner opening\nThe first move leads to certain victory, O will have to go to the center and X will achieve strategy 3 [Figure9]. The second move is a possible way to strategy 3 if O makes a mistake in the next loop, so X goes to the opposite corner. For the third case since O is playing a valid strategy the only move that leaves a possible mistake from O would be to take the center and wait for O to go to the middle and then achieve strategy 1 or 3 which will be a symmetric situation to the one that we will find if we branched with the center.\nFigure 10: Tic-tac-toe opponent response to center move\nIf we go back to the second branch [Figure10], a possible way for the second player to engage is corner or middle. The first move is a valid strategy for O and can be mee corner move from X to try a mistake from O in the same as in the third case above from the pre another move would be go to the middle wh achieves strategy 1 or 2. To sum the strategies for the planning, first corner strategy for the beginning. Then for the ce the corners with the particularly the one oppo holds. If the center is empty for the second strate we go for the opposite corner. After this point w opponent or try to implement strategies 1, 2 or victory.\n5.1 Hierarchical Task Network\nTop level task is Play [Figure12]. This is a can be derived into: Win, Block, Tie or Sear Search for plan is derived to both Plan 1 and Pla Plan 4, which later leads to a call for the oppon recursive call to Play.\nTN\nThis HTN when executed will re game scenarios. By creating nodes from them with branches with the move of t tree for the Tic-tac-toe game over whi algorithm.\nThis set up with 7 plans with 3 ta for Tic-tac-toe which considers all pos player with only 457 games, 281 of w and 0 where the second opponent w reduction over the 255, 168 possible g tree. These reductions can be very use computing capabilities but also we pr that planning can be very efficient if d trees by applying reasoning very reasoning.\nFurther improvements to the gam the opponents moves are also planned all the meaningless and symmetrical m\n6. Game AI in Monopoly 6.1 Overview of the AI Imp\nThe AI agent is responsible for players in the game. The core principle a Game Tree with all the sensible move make from the current point of time minimax algorithm the agent selects t would bring the computer player mo with the highest probability. Building that would be big enough to consider is obstructed by the vastness of poss with all the possible random landings nodes of the game tree exponentially tackle this problem the AI agents discussed technologies: Case Based Re\nThe technologies are employed First the agent searches the CBR datab largest similarity with the current state associated with a playing strategy. Th that the planner needs to build plans f consecutive player moves that bring th way only moves that are part of that str being a small fraction of the overall po edges of the game tree at each level dec At each level of the game tree the of a single player. After the strateg considered the response to those strate by the opponent(s). The move of the probability distribution of the dice as player. A more general strategy needs opponent's (human player) moves sin the expertise of the opponent. This ge more plausible moves than the focused After covering all opponents t deducting a feature move of the com CBR selected plan strategy. After strategies and reaching a reasonable s into account the memory limits an probabilities that the move is possible the dice the building of the Game Tre algorithm searches the Game Tree favorable move for the AI player usi The process is repeated each time the A esult with plans for possible m each position and linking the player we create a game ich we can run the minimax arget strategies creates a tree ssible moves for the second which X wins 176 are draw wins. This is a significant ames with a complete game eful for devices with limited rove a very important point designing meaningful game similar to human player me tree are also possible if d, in other words if we drop moves of the opponent. plementation the moves of the artificial e of the AI agent is building es that all the players would e forward. Then using the the move that in the future ost favorable game position a Game Tree in this game sufficient number of moves sible moves in combination of the dice. The number of y grows at each level. To incorporates two already easoning and AI Planning.\nin the following manner. base to find the case with the e of the board. This case is he strategy consists of goal for, and the plans consist of he player to that goal. This rategy are considered, those ossible moves the number of creases immensely. e model considers the moves gies of the AI player are egies needs to be considered opponent(s) depends of the well as the strategy of the s to be implemented for the nce we cannot be aware of eneral strategy would bring d strategy of the AI player. the agent comes back to mputer player by using the creating several loops of size of a Game Tree taking nd the rapidly decreasing e due to the distribution of ee stops. Then the minimax and decides on the most ing the minimax algorithm. AI player is up.\nBuying, auctioning and trading game moves are always accompanied by return of investment calculations in making the plans. These calculations represent adaptation of the more general planning associated with the cases in the CBR database. These adaptations are necessary due to the fact that the cases do not identically correspond to the situation on the table. In addition calculating the game position value of each node of the game tree is done by heuristic functions that incorporate economic calculations of net present value, cash, and strategic layout and so on. For example railroads in monopoly are known to be strategically effective because they bring constant income even though the income can be smaller than building on other properties.\n6.2 Details on the CBR Implementation\nThe implementation of the CBR is by using the JColibri2 platform. JColibri2 is an object-oriented framework in Java for building CBR systems that is an evolution of previous work on knowledge intensive CBR[14].\nFor this implementation we need to look into three particular classes of the JColibri2 platform. The StandardCBRApplication, Connector, CBRQuery. For a JColibri2 implementation the StandardCBRApplication interface needs to be implemented.\nThe CBR cycle executed accepts an instance of CBRQuery. This class represents a CBR query to the CBR database. The description component (instance of CaseComponent) represents the description of the case that will be looked up in the database. All cases and case solutions are implementing the CaseComponent interface.\nThe JColibri2 platform connects to the CBR database via a Connector class. Each connector implements all the necessary methods for accessing the database, retrieval of cases, storing and deletion of cases. This implementation uses a custom XML structure for holding the CBR cases. Since the game will not update the CBR database only read it, a XML solution satisfies the needs. The XML file to a certain extent is similar to the XML representation of the board. We are interested in finding one CBRCase that is the most similar case to the situation in the game at the time of the search. This procedure is done in the cycle method of the CBRApplication. The JColibri2 CBR comparison is done by Nearest Neighbor (NN) search method.\nJColibri2 offers implementations for NN search algorithms of simple attributes. These implementations are called local similarities. For complex attributes like in our case global customized similarity mechanisms need to be implemented.\nThe MonopolyDescription class [Figure13] is basically a serialization of the GameState. It holds all the information about the state of the board, the players, their amount of cash etc.\nFigure 13: Class diagram of the Monopoly Case component models\nOn the other hand the MonopolySolution class holds the three particular attributes that are needed for the planning, the planning Domain, State and TaskList.\nThe game is implemented by using the Model-View-Controller software development pattern. The controller is responsible for implementing the game rules and handling all of the events in the game like roll of dice, input commands for trading, auctioning and etc from the players. The View layer is responsible for displaying the board and all of the input widgets on to the game screen, and the models are data structures representing the game state [Figure14].\n6.2.1 Complex Similarity representation in CBR\nThe similarity measurement part of the Nearest Neighbor algorithm JColibri2 is implemented by implementing the LocalSimiralrityFunction and the GlobalSimiralityFunction interface. A local similarity function is applied to simple attributes by the NN algorithm, and a global similarity function is applied to compound attributes. In the case of our implementation the attributes of the MonopolyDescription are compound attributes describing the state of the board, number of players, amount of cash for every player and etc. Since MonopolyDescription is a custom CaseComponent a global similarity function needs to be implemented to accurately find the distance between different CBR cases.\nThe similarity mechanism is inseparable core element of the CBR system. This mechanism represents how the CBR decides which strategy is best suited for the particular situation by calculating the distance or similarity to other cases in the database.\nFor the monopoly implementation we need to consider several basic strategies. Monopoly is based on investing in properties and receiving revenues from those investments. One of the basic strategies of the game is to build a set of properties that will bring constant income larger than the one of the opponents. So in time the opponents will have to declare bankruptcy. But on the other hand over investment can lead to too stretched resources with low income that will eventually drove the player to bankruptcy. To decide on these two we need a clear separation into two groups of cases in the CBR database. The first group of cases will represent a situation on the board where the player has significant income per loop formed of one or more color group properties, maybe railroads, some buildings on them and so on. It is important to note that in this case the player is better situated than his opponents so he only needs to survive long enough to win the game. In the other group of cases either the opponent is not well positioned on the board or its opponents are better situated. In this case further investments are necessary to improve the situation so the player can have a chance of winning in the long run.\nThese metrics can be owning color groups, valuing groups of railroads, evaluating the other opponents as well, and considering the amount of cash. As it is obvious in monopoly the number of streets is not as nearly as important as the combination of streets the player owns. It is also important to note that one CBR case does not hold only a single strategy in place, but its solution can have multiple different strategic goals. For example one CBR case might simultaneously say buy this land to form a color group but also trade some other unimportant property to increase cash amount.\nThe cases do not represent all possible combinations of board positions. They are only representation of typical game scenarios. The CBR Case solutions do not give exact instructions in general but rather strategic goals. For example one CBR Solution might say trade the streets that you only have one of each for the ones that you have two of that color already. Then the planner based on the situation on the board needs to decompose this high level task to a low level operations. Like offer \"Mediterranean Avenue\" for \"Reading Railroad\" and offer $50. The exact amounts and actual streets are left to the planer to evaluate.\nThe monopoly CBR database is currently in development on a monopoly clone game called Spaceopoly. The cases are architected based on human player experience and knowledge. There is a plan of making a number of slightly different strategies that differ on the style of playing and then running simulation tests that would determine the particular validity of each database as well as validity of certain segments of the strategy or even particular cases in the database.\nThe actual execution of the strategies will not differ from strategy to strategy since the plan execution is more related to the structure and rules of the game than to the actual playing strategy.\n6.3 Details on the Planning Implementation\nFor the purpose of planning this implementation uses a modification of the JSHOP2 planner. The Java Simple Hierarchical Ordered Planner 2 is a domain independent HTN planning system[15]. JSHOP2 uses ordered task decomposition in reducing the HTN to list of primitive tasks which form the plans. An ordered task decomposition planner is an HTN planner that plans for tasks in the same order that they will be executed. This reduces the complexity of reasoning by removing a great deal of uncertainty about the world, which makes it easy to incorporate substantial expressive power into the planning algorithm. In addition to the usual HTN methods and operators, the planners can make use of axioms, can do mixed symbolic/numeric conditions, and can do external function calls.\nIn order for the JSHOP2 planer to generate plans it needs tree crucial components: Domain, State and Tasks. The Domain defines all the functionalities that the particular domain offers. These are simple and complex tasks. The complex tasks also called methods create the hierarchy with the fact that they can be evaluated by simple tasks of other complex tasks. This is how a hierarchical structure of tasks is formed. The problem reduction is done by reducing the high level complex tasks to simpler until all the tasks are primitive. The list of primitive tasks forms the plan.\nThe State represents the state of the system. It is a simple database of facts that represent the state of the system. The State is necessary to determine the way the problems or tasks are reduced to their primitive level. The reduction is done by satisfying different prerequisites set in the methods; these prerequisites are defined in the state. The Tasks are high level tasks or methods defined in the Domain. The planner based on the State and the goals selects one or more high level tasks that need to be reduced to plans [Figure15].\nFigure 15: Diagram of a Planner\nThe plans then generate the game moves. The number of moves generated by the plans is just a fraction of the possible moves at that point. This reduces the game tree providing the opportunity to generate smaller and deeper game trees and making more efficient decisions in general.\n7. Conclusion\nEven though the results from the CBR database are not complete at this time partial strategies are implemented as cases and recognized during game play by the CBR system. These smaller local strategies coupled with more global higher level strategies that are particularly important at the beginning of the game would form a complete CBR database and represent a knowledge engineered style of playing of the AI player.\nThe AI Planning approach is a proven method by the tic-tactoe experiment and is suitable for implementing the strategies associated with the CBR cases. This approach in general benefits from both technologies, CBR as well as AI Planning and comprises an elegant solution. Even though AI Planning can be enough as a single technology for some simpler problems like tic-tac-toe the complexity of Monopoly would mean that the Planner would have to incorporate Core Planner Tasks Plan State large and complex domain and a very big state model. The CBR application helps reduce this complexity by focusing the planning on smaller domain of the game. Basically the CBR reduces the overall goal of the play (wining the game) to smaller more concrete goals suitable to the particular state of the game, thus reducing the need for global planning strategies and complex planning domain.\nFurthermore this symbiosis of technologies gives way for more precise and finely tuned strategies which can be difficult to include into global plan for the whole game. One simple example for the Monopoly game would be this: Sometimes it's better to stay in jail because rolling double increases the probability of landing on some field (two, four, six, eight, ten or twelve steps from the jail) that can be of great importance to the rest of the game. These and similar small local strategies can be easily recognized by similar cases in the CBR database.\nIn other words the system is flexible enough so that new strategies can be incorporated easily missing strategies can be also recognized by the distance metrics as well as wrong assumptions in the strategies can be easily recognized.\nOne other important property of the system is that is highly configurable. The game its self can be diversely different depending on the configuration of the board. Even though the platform is restricted to Monopoly type of games, changing the layout and values of the fields effectively brings completely different properties of the game. In addition the CBR database represents the entire experience of the AI Player. It can be filled with rich set of strategies or even configured with different flavors of difficulties of play, this of course coupled with the domain of the planner which can differ from a case to a case as well.\n8. Future Work\nFurther exploration of this technology would go towards complete implementation of an AI aware agent for monopoly. Initial results from the local cases with more specific strategies show CBR as a capable tool for representing expertise in playing the game. Completing the more general strategies and coupling them with the planning domain will give precise results on the benefits from this architecture.\nThere is also need for exploring the planning of strategies of opponents. This task is to some extent different because we cannot always expect the opponent to select the best move we think. In the Tic-tac-toe example all possible moves of the opponent were taken into consideration, if we used the same planner for the opponent only tie games would result from the game tree. In other words mistakes of the players also need to be considered.\nThe CBR Platform brings other functionalities well worth of exploring as well. The revision stage of the JColibri2 platform is basically capable of fine tuning strategies or even developing new strategies for the games. A well written underlying AI planning model with a capable feedback of the game tree evaluation back to the CBR revision capability can be an interesting concept in automatic experience acquisition for the AI model.\nThere are also many other fields were combined CBR and planning approach can be incorporated into a problem solution. This combination is analogous in a big extent to a human way of reasoning. People in addition to logic of reasoning in situations with lack of information rely to planning strategies and prior experience, exactly the intuition behind CBR -AI Planning architecture.\n",
        "resume": "Making efficient AI models for games with imperfect information can be a particular challenge. Considering the large number of possible moves and the incorporated uncertainties building game trees for these games becomes very difficult due to the exponential growth of the number of nodes at each level. This effort is focused on presenting a method of combined Case Based Reasoning (CBR) with AI Planning which drastically reduces the size of game trees. Instead of looking at all possible combinations we can focus only on the moves that lead us to specific strategies in effect discarding meaningless moves. These strategies are selected by finding similarities to cases in the CBR database. The strategies are formed by a set of desired goals. The AI planning is responsible for creating a plan to reach these goals. The plan is basically a set of moves that brings the player to this goal. By following these steps and not regarding the vast number of other possible moves the model develops Game Trees which grows slower so they can be built with more feature moves restricted by the same amount of memory.",
        "authors": [
            "Vlado Menkovski",
            "Dimitrios Metafas"
        ],
        "keywords": [
            "Performance Game AI",
            "Case Based Reasoning",
            "AI Planning",
            "Game Trees"
        ],
        "institutions": [
            "Athens Information Technology"
        ],
        "refrences": [
            "Von Neumann. J: Zur theorie der gesellschaftsspiele Math. Annalen 1928, 100, 295-320.",
            "Automated Planning.  April 23. 2008.",
            "Antonio Sanchez-Ruiz. Game AI for a Turn-based Strategy Game with Plan Adaptation and Ontology-based retrieval .",
            "K Erol, J Hendler, D Nau. Semantics for hierarchical task-network planning UMIACS 1994, Technical Report, TR-94- 31.",
            "S J J Smith, Dana S Nau, T A Throp. A Planning approach decrarer play in contract bridge Computational Intelligence 1996, 12.",
            "One Jump Ahead: Challenging Human Supremacy in Checkers J.Schaeffer. s.l Springer-Verlag 1997.",
            "How Deep Blue works 1997. April 23. 2008.",
            "Malik Ghallab, Dana Nau, Paolo Traverso. Automated Planning theory and practice Morgan Kaufmann Publishers May 2004.",
            "Applying case-based reasoning: techniques for enterprise systems Morgan Kaufmann Publishers Inc 1998.",
            "A Plaza. Aamodt and E. Case-based reasoning: Foundational issues, methodological. AI Communications 1994.",
            "Tic-tac-toe. Wikipedia April 23. 2008.",
            "B DÃ­az-Agudo, P A GonzÃ¡lez-Calero. An architecture for knowledge intensive CBR systems Springer-Verlag 2000, Advances in Case-Based Reasoning -(EWCBR'00).",
            "Okhtay Ilghami, Dana S Nau. A General Approach to Synthesize Problem-Specific Planners 2003."
        ],
        "created_at": "2024-02-01T13:33:33.181298+00:00",
        "updated_at": "2024-02-01T13:34:42.037043+00:00"
    }
]
